
## **Pipeline de Dados**
### **O que é uma Pipeline de Dados?**
É um meio de mover dados do local de origem para um destino. Durante esse caminho, os dados são transformados e otimizados para chegar em um estado onde possam ser analisados e usados para desenvolver insights de negócios.

Normalmente, o pipeline carrega os dados brutos em uma **tabela de preparação** (Staging Area), onde serão transformados, limpos, etc. Após esse processo, os dados são inseridos no destino.

**Resumidamente, uma pipeline de dados passa por três etapas principais:**
1. **Origem:** Onde os dados são coletados.
2. **Processamento:** Onde os dados são transformados, alterados e preparados.
3. **Destino:** Onde os dados serão armazenados ou utilizados.

---

### **Pipeline de Dados vs Pipeline ETL**
Os sistemas de **ETL** são um **tipo de pipeline**, mas ETL é apenas um subprocesso dentro de uma pipeline de dados. Antigamente, o processo era bem menos complexo, e o termo **ETL** era mais utilizado.  

✅ Dizer que um **Pipeline ETL** é um **Pipeline de Dados** é correto.  
❌ Mas dizer que um **Pipeline de Dados** é **apenas** um Pipeline ETL está errado!  

Um Pipeline de Dados realiza diversas outras funções além do ETL.

---

### **Como iniciar um projeto de Pipeline de Dados?**

A melhor forma de começar é pela **compreensão dos requisitos de negócio** e o que se espera do uso dos dados no dia a dia.

### **Principal função do Engenheiro de Dados**:
- Auxiliar a empresa a alcançar seus requisitos de negócios.
- Ajudar a empresa a gerar lucro e reduzir custos.

A **arquitetura da Pipeline de Dados** define como os componentes irão se comportar dentro da plataforma de dados.

### **PoC (Prova de Conceito)**
É um laboratório para simular cenários, validar requisitos de negócio, testar ferramentas e auxiliar em previsões de custos.

---