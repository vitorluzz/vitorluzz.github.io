{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfe0 Home","text":""},{"location":"#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>\ud83c\udde7\ud83c\uddf7:</p> <p>Ol\u00e1, me chamo Jo\u00e3o Vitor Luz, estudante de An\u00e1lise e Desenvolvimento de Sistemas, apaixonado por tecnologia e atualmente atuando na \u00e1rea de BI &amp; Analytics.</p> <p>Aqui \u00e9 um reposit\u00f3rio pessoal onde irei guardar anota\u00e7\u00f5es de estudos e informa\u00e7\u00f5es relevantes sobre a minha \u00e1rea de atua\u00e7\u00e3o que \u00e9 o ecossistema de dados, afim do meu desenvolvimento profissional e tamb\u00e9m ajudar as pessoas que assim como eu, est\u00e3o come\u00e7ando na \u00e1rea de dados!</p> <p>Caso queira, entre em contato pelas redes sociais dispon\u00edveis aqui e vamos estreitar contato!</p> <p> \ud83c\uddfa\ud83c\uddf8:</p> <p>Hello, my name is Jo\u00e3o Vitor Luz, a Systems Analysis and Development student, passionate about technology, and currently working in the BI &amp; Analytics field.</p> <p>This is a personal repository where I will store study notes and relevant information about my field of expertise, which is the data ecosystem, aiming at my professional development and also helping people who, like me, are starting in the data field!</p> <p>If you'd like, feel free to reach out through the social media links available here, and let's connect!</p>"},{"location":"agrupandodados/","title":"Agrupamento de Dados com GroupBy","text":""},{"location":"agrupandodados/#agrupamento-de-dados-em-df-com-group-by","title":"Agrupamento de dados em DF com Group By","text":"<p>Primeiro: Filtramos os dados extraindo 3 colunas: Segmento, Regi\u00e3o e Valor Venda.</p> <p>Em seguida: Agrupamos por duas colunas: Segmento e Regi\u00e3o.</p> <p>Ent\u00e3o: Calculamos a m\u00e9dia da coluna que ficou de fora do groupby</p> <pre><code>python\n\ndf3[ ['Segmento', 'Regiao', 'Valor_Venda'] ].groupby(['Segmento', 'Regiao']).mean()\n</code></pre> <p>out:</p> Valor_Venda Segmento Regiao Consumer Central 207.946728 East 238.875539 South 233.390180 West 217.033955 Corporate Central 234.763466 East 228.516929 South 238.992025 West 235.265911 Home Office Central 208.248046 East 253.911805 South 272.996329 West 239.442692 <p>Ele nos retorna: Esse segmento, nas regi\u00f5es, tem essa m\u00e9dia POR REGI\u00c3O!</p> <p></p>"},{"location":"agrupandodados/#agregacao-multipla-com-group-by","title":"Agrega\u00e7\u00e3o M\u00faltipla com Group By","text":"<p>Retornando: A m\u00e9dia, o Desvio Padr\u00e3o e a Contagem das linhas!</p> <pre><code>python\n\ndf3[ ['Segmento', 'Regiao', 'Valor_Venda'] ].groupby(['Segmento', 'Regiao']).agg(\n    M\u00e9dia=('Valor_Venda', 'mean'),\n    Desvio_Padr\u00e3o=('Valor_Venda', 'std'),\n    Contagem=('Valor_Venda', 'count'))\n</code></pre> <p>out:</p> M\u00e9dia Desvio_Padr\u00e3o Contagem Segmento Regiao Consumer Central 207.946728 587.906523 1212 East 238.875539 633.371169 1469 South 233.390180 559.346824 838 West 217.033955 551.997547 1672 Corporate Central 234.763466 818.947521 673 East 228.516929 530.001654 877 South 238.992025 586.176947 510 West 235.265911 471.288764 960 Home Office Central 208.248046 371.009180 438 East 253.911805 722.777318 502 South 272.996329 1404.798466 272 West 239.442692 529.242737 571 <p></p>"},{"location":"analiseestatisticanumpy/","title":"An\u00e1lise Estat\u00edstica","text":"<p>\u3164</p>"},{"location":"analiseestatisticanumpy/#analise-estatistica-basica-com-numpy","title":"An\u00e1lise Estat\u00edstica B\u00e1sica com NumPy","text":""},{"location":"analiseestatisticanumpy/#media","title":"M\u00e9dia","text":"<pre><code>python\n\narr14 = np.array([15,23,63,94,75])\n</code></pre> <p>Calculando a m\u00e9dia de um conjunto de valores</p> <pre><code>python\n\nnp.mean(arr14)\n</code></pre> <pre><code>out: 54.0\n</code></pre> <p>\u3164</p>"},{"location":"analiseestatisticanumpy/#calcular-desvio-padrao-standard-deviation","title":"Calcular Desvio Padr\u00e3o (Standard Deviation)","text":"<p>O desvio padr\u00e3o \u00e9 uma medida estat\u00edstica de dispers\u00e3o que indica quanto os valores de um conjunto de dados se afastam da m\u00e9dia. Ele \u00e9 calculado como a raiz quadrada da vari\u00e2ncia que \u00e9 a m\u00e9dia dos quadrados das diferen\u00e7as entre cada valor e a m\u00e9dia. Com isso, conseguimos calcular a variabilidade dos dados em torno da m\u00e9dia, se os valores estiverem pr\u00f3ximos da m\u00e9dia, o desvio padr\u00e3o ser\u00e1 baixo, por\u00e9m se estiverem distantes, o desvio ser\u00e1 alto. ** Muito utilizado em an\u00e1lise de dados! **</p> <pre><code>python\n\n# Desvio padr\u00e3o \nnp.std(arr14)\n</code></pre> <pre><code>out: 30.34468652004828\n</code></pre> <p>\u3164</p>"},{"location":"analiseestatisticanumpy/#variancia","title":"Vari\u00e2ncia","text":"<p>A vari\u00e2ncia \u00e9 uma medida estat\u00edstica que quantifica a dispers\u00e3o dos valores em um conjunto de dados em rela\u00e7\u00e3o \u00e0 m\u00e9dia. Ela \u00e9 calculada como a m\u00e9dia dos quadrados das diferen\u00e7as entre cada valor e a m\u00e9dia.</p> <pre><code>python\n\nnp.var(arr14)\n</code></pre> <pre><code>out: 920.8\n</code></pre> <p>A vari\u00e2ncia e o desvio padr\u00e3o s\u00e3o medidas de dispers\u00e3o dos dados. A vari\u00e2ncia \u00e9 uma medida quadr\u00e1tica que pode ser usada para calcular outras estat\u00edsticas, mas seus valores costumam ser elevados, dificultando a interpreta\u00e7\u00e3o. O desvio padr\u00e3o, que \u00e9 a raiz quadrada da vari\u00e2ncia, tem a mesma unidade dos dados, facilitando a an\u00e1lise. O desvio padr\u00e3o \u00e9 mais utilizado por ser mais intuitivo, mas a escolha entre ele e a vari\u00e2ncia depende do contexto da an\u00e1lise.</p> <p>\u3164</p>"},{"location":"armazenamentodados/","title":"\ud83d\udcbe Armazenamento de Dados","text":""},{"location":"armazenamentodados/#armazenamento-de-dados-por-que-e-importante","title":"Armazenamento de Dados: Por que \u00e9 importante?","text":"<p>Hoje temos muitas alternativas para armazenamento de dados. Saber qual a melhor op\u00e7\u00e3o e ter maestria para construir o melhor layout de armazenamento \u00e9 essencial.</p> <p>A escolha do armazenamento depende de fatores como: - Quantos sistemas ir\u00e3o acessar esse armazenamento? - Em qual frequ\u00eancia? - Qual o volume de dados lidos? - Qual a l\u00f3gica aplicada nesse sistema?</p>"},{"location":"armazenamentodados/#sql-vs-nosql-vs-armazenamento-de-arquivos","title":"SQL vs NoSQL vs Armazenamento de Arquivos","text":"<ul> <li>SQL: Estruturado, ideal para dados organizados.</li> <li>NoSQL: Ideal para Big Data e dados n\u00e3o tabulares.</li> <li>Armazenamento de Arquivos: Para v\u00eddeos, imagens e outros formatos n\u00e3o relacionais.</li> </ul>"},{"location":"armazenamentodados/#os-4vs-do-big-data","title":"Os 4Vs do Big Data","text":"<ol> <li>Volume</li> <li>Velocidade</li> <li>Variedade</li> <li>Veracidade</li> </ol>"},{"location":"armazenamentodados/#tipos-de-armazenamento-de-dados","title":"Tipos de Armazenamento de Dados","text":""},{"location":"armazenamentodados/#data-warehouse-dw","title":"Data Warehouse (DW)","text":"<p>Um banco de dados para an\u00e1lises eficientes e de grande volume de dados, normalmente usado para integrar dados de v\u00e1rias fontes.</p> <p>\ud83d\udccc Quando usar? - Grande volume de dados - Necessidade de consultas anal\u00edticas r\u00e1pidas - Integra\u00e7\u00e3o de dados de v\u00e1rias fontes - Alimenta\u00e7\u00e3o de BI e relat\u00f3rios</p> <p>Os dados armazenados no DW devem estar limpos e organizados!</p>"},{"location":"armazenamentodados/#data-lake-dl","title":"Data Lake (DL)","text":"<p>O Data Lake armazena todo tipo de dado, estruturado ou n\u00e3o.  </p> <p>Se n\u00e3o houver governan\u00e7a adequada, ele pode virar um \"p\u00e2ntano de dados\" (Data Swamp), tornando-se inutiliz\u00e1vel.</p> <p>\ud83d\udccc Quando usar? - Armazenamento e processamento de dados brutos - Grandes volumes de dados - Dados estruturados e n\u00e3o estruturados - Escalabilidade e centraliza\u00e7\u00e3o de dados</p>"},{"location":"armazenamentodados/#data-lakehouse","title":"Data Lakehouse","text":"<p>Une o melhor do Data Warehouse e do Data Lake, trazendo flexibilidade e escalabilidade.</p> <p>\ud83d\udccc Vantagens: - Boa escalabilidade e flexibilidade - Melhor desempenho de consulta - Centraliza\u00e7\u00e3o dos dados</p> <p>\ud83d\udccc Desvantagens: - Maior complexidade - Uso intensivo de recursos - Desafios de governan\u00e7a</p>"},{"location":"armazenamentodados/#data-store","title":"Data Store","text":"<p>\u00c9 um reposit\u00f3rio para armazenar e gerenciar dados, podendo ser local, em rede, distribu\u00eddo ou na nuvem.  </p> <p>\ud83d\udccc Quando usar? - Armazenamento de arquivos - Chave-valor - Pesquisa de textos - Fila de mensagens</p>"},{"location":"armazenamentodados/#formatos-de-arquivo","title":"Formatos de Arquivo","text":"<ul> <li>Parquet: Armazenamento colunar eficiente, ideal para Big Data.</li> <li>Avro/ORC: Alternativas eficientes para grandes volumes de dados.</li> <li>CSV: Simples e leve, mas sem compress\u00e3o e cabe\u00e7alhos estruturados.</li> <li>JSON: Muito utilizado em aplica\u00e7\u00f5es web.</li> </ul>"},{"location":"combinacaodf/","title":"Combina\u00e7\u00e3o de Strings","text":""},{"location":"combinacaodf/#combinacao-de-strings","title":"Combina\u00e7\u00e3o de Strings","text":"<p>Passo a coluna que quero adicionar, passando como parametro o ID_Pedido, dizendo que quero que some com a coluna Segmento e separando por '-'</p> <pre><code>python\n\ndf3['Pedido Segmento'] = df3['ID_Pedido'].str.cat(df3['Segmento'], sep = '-')\n</code></pre> <p>Visualizando as altera\u00e7\u00f5es</p> <pre><code>python\n\ndf3.head()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade Ano Pedido Segmento 0 CA-2016-152156 2016-11-08 AX-12520 Consumer United States South FUR-BO-10001798 Furniture Bush Somerset Collection Bookcase 261.9600 3.0 2016 CA-2016-152156-Consumer 1 CA-2016-152156 2016-11-08 AX-12520 Consumer United States South FUR-CH-10000454 Furniture Hon Deluxe Fabric Upholstered Stacking Chairs,... 731.9400 3.0 2016 CA-2016-152156-Consumer 2 CA-2016-138688 2016-06-12 DV-13045 Corporate United States West OFF-LA-10000240 Office Supplies Self-Adhesive Address Labels for Typewriters b... 14.6200 2.0 2016 CA-2016-138688-Corporate 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 2015 US-2015-108966-Consumer 4 US-2015-108966 2015-10-11 SO-20335 Consumer United States South OFF-ST-10000760 Office Supplies Eldon Fold 'N Roll Cart System 22.3680 2.0 2015 US-2015-108966-Consumer <p></p>"},{"location":"combinando/","title":"Combinando MTPL, SB, PD, NP na cria\u00e7\u00e3o de gr\u00e1ficos","text":""},{"location":"combinando/#matplotlib-seaborn-numpy-e-pandas-na-criacao-de-grafico-estatistico","title":"Matplotlib, Seaborn, NumPy e Pandas na cria\u00e7\u00e3o de gr\u00e1fico estat\u00edstico","text":"<p>Vamos utilizar todas as bibliotecas para criar um gr\u00e1fico de dispers\u00e3o com um modelo de regress\u00e3o</p> <p>Criando os dados a serem manipulados</p> <pre><code>python\n\n# valores rand\u00f4micos\nnp.random.seed(42)\nn = 1000\npct_smokers = 0.2\n\n# Vari\u00e1veis\nflag_fumante = np.random.rand(n) &lt; pct_smokers\nidade = np.random.normal(40,70, n)\naltura = np.random.normal(170,10,n)\npeso = np.random.normal(70,10,n)\n\n# DataFrame\ndados = pd.DataFrame({'altura': altura, 'peso': peso, 'flag_fumante': flag_fumante})\n\n# Cria os dados para a vari\u00e1vel fumante\ndados['flag_fumante'] = dados['flag_fumante'].map({True: 'Fumante', False: 'N\u00e3o Fumante'})\n</code></pre> <p>Visualizando os dados</p> <pre><code>python\n\ndados.head()\n</code></pre> <p>out:</p> altura peso flag_fumante 0 155.936825 78.745171 N\u00e3o Fumante 1 169.168944 63.502348 N\u00e3o Fumante 2 154.952796 57.967991 N\u00e3o Fumante 3 177.600560 59.579556 N\u00e3o Fumante 4 170.824398 65.127971 Fumante <p></p> <p>Criando o gr\u00e1fico de dispers\u00e3o</p> <pre><code>python\n\n# Style\nsea.set(style = 'ticks')\n\n# lmplot\nsea.lmplot(x = 'altura',\n          y = 'peso',\n          data = dados,\n          hue = 'flag_fumante',\n          palette = ['tab:blue', 'tab:orange'],\n          height = 7)\n\n# Labels e T\u00edtulo\nplt.xlabel('Altura (cm)')\nplt.ylabel('Peso (kg)')\nplt.title('Rela\u00e7\u00e3o entre altura e peso de fumantes e n\u00e3o fumantes')\n\n# Remove as bordas\nsea.despine()\n\n# Mostrando o gr\u00e1fico\nplt.show()\n</code></pre> <p></p> <p> </p> <p>Podemos criar infinidades de gr\u00e1ficos, muitos com apenas 1 linha de c\u00f3digo, se termos o conhecimento de como manipularmos, o c\u00e9u \u00e9 o limite.</p> <p>Existem milhares de formas de fazer a mesma coisa, mas, a sua capacidade de profissional que define qual a melhor ferramenta e forma de fazer com base em cada caso e demanda.</p>"},{"location":"comeconumpy/","title":"Numpy - Python","text":"<p>O NumPy (Numerical Python) \u00e9 uma biblioteca fundamental para computa\u00e7\u00e3o num\u00e9rica em Python. Ele fornece suporte para arrays multidimensionais de alta performance e fun\u00e7\u00f5es matem\u00e1ticas otimizadas para opera\u00e7\u00f5es nesses arrays. Extremamente utilizado em an\u00e1lise de dados!</p> <p>Primeiros passos Importando o numpy</p> <pre><code>python\n\n\nimport numpy as np\n</code></pre> <p>Criando uma Array NumPy a partir de uma lista python!</p> <pre><code>python\n\narr1 = np.array([10,21,32,43,48,15,76,57,89])\n</code></pre> <p>O tipo dele ser\u00e1 array numpy</p> <pre><code>python\n\ntype(arr1)\n</code></pre> <pre><code>out: numpy.ndarray\n</code></pre> <p>A fun\u00e7\u00e3o shape, nos retorna as dimens\u00f5es do objeto, Ela ir\u00e1 me retornar que ele \u00e9 um array comum, unilateral </p> <pre><code>python\n\narr1.shape\n</code></pre> <pre><code>out: (9,)\n</code></pre> <p>O array numpy nos permite criar um array de m\u00faltiplas dimens\u00f5es, diferente das listas comum, ele nos deixa ter um objeto n-dimensional. S\u00e3o muito mais eficientes que as listas de dados para armazenar e manipular grandes quantidades de dados. Eles s\u00e3o implementados em linguagem C e nos permitem muitas otimiza\u00e7\u00f5es de desempenho. </p>"},{"location":"conceitosbasicospy/","title":"\ud83d\udc0d Fundamentos da Linguagem Python","text":"<p>A linguagem Python \u00e9 uma linguagem interpretada, ou seja, precisamos de um software (interpretador) para processar o c\u00f3digo e nos retornar o resultado esperado. Diferente de linguagens compiladas, como C ou Java, o Python executa o c\u00f3digo linha por linha, tornando o desenvolvimento mais \u00e1gil e din\u00e2mico.</p>"},{"location":"conceitosbasicospy/#caracteristicas-do-python","title":"\u2728 Caracter\u00edsticas do Python","text":"<ul> <li> <p>Simplicidade e Legibilidade \ud83d\udcd6   Python possui uma sintaxe limpa e f\u00e1cil de entender, tornando o aprendizado mais acess\u00edvel para iniciantes.  </p> </li> <li> <p>Multiparadigma \ud83c\udfd7\ufe0f   Suporta programa\u00e7\u00e3o procedural, orientada a objetos e funcional.  </p> </li> <li> <p>Portabilidade \ud83c\udf0d   Python \u00e9 multiplataforma, ou seja, pode ser executado em Windows, Linux e macOS sem altera\u00e7\u00f5es no c\u00f3digo.  </p> </li> <li> <p>Bibliotecas Poderosas \ud83d\udcda   Conta com diversas bibliotecas como <code>numpy</code>, <code>pandas</code>, <code>matplotlib</code>, entre outras, facilitando o desenvolvimento de aplica\u00e7\u00f5es diversas.  </p> </li> <li> <p>Tipagem Din\u00e2mica \ud83d\udd0d   Diferente de linguagens como Java, em Python n\u00e3o \u00e9 necess\u00e1rio declarar o tipo das vari\u00e1veis explicitamente.</p> </li> </ul>"},{"location":"conceitosbasicospy/#primeiro-codigo-em-python","title":"\ud83d\udd25 Primeiro C\u00f3digo em Python","text":"<p>Para escrever um c\u00f3digo Python, basta criar um arquivo com a extens\u00e3o <code>.py</code> e executar com o interpretador.  </p> <p>Aqui est\u00e1 um exemplo de um programa simples que imprime \"Ol\u00e1, Mundo!\":  </p> <pre><code>python\n\nprint(\"Ol\u00e1, Mundo!\")\n</code></pre>"},{"location":"data_quality/","title":"\u2705 Data Quality","text":""},{"location":"data_quality/#data-quality-qualidade-dos-dados","title":"Data Quality (Qualidade dos Dados)","text":"<p>A qualidade dos dados \u00e9 essencial para garantir precis\u00e3o, consist\u00eancia e confiabilidade.  </p>"},{"location":"data_quality/#como-medir-a-qualidade-dos-dados","title":"Como Medir a Qualidade dos Dados?","text":"<p>Pode ser avaliada por: - Precis\u00e3o: A informa\u00e7\u00e3o \u00e9 ver\u00eddica? - Exatid\u00e3o: Os dados refletem a realidade? - Consist\u00eancia: Os dados s\u00e3o uniformes? - Relev\u00e2ncia: Os dados s\u00e3o \u00fateis para o neg\u00f3cio? - Cobertura: Os dados s\u00e3o suficientes? - Atualidade: Os dados est\u00e3o atualizados?  </p>"},{"location":"data_quality/#correcoes-tipicas-nos-dados","title":"Corre\u00e7\u00f5es T\u00edpicas nos Dados","text":"<ul> <li>Limpeza: Remover dados duplicados, incompletos e inconsistentes  </li> <li>Padroniza\u00e7\u00e3o: Converter os dados para um formato comum  </li> <li>Tratar Valores Ausentes: Interpola\u00e7\u00e3o ou preenchimento com valores padr\u00e3o  </li> <li>Corre\u00e7\u00e3o de Erros: Ajustes em digita\u00e7\u00e3o, espa\u00e7os desnecess\u00e1rios e caracteres especiais  </li> <li>Normaliza\u00e7\u00e3o: Transforma\u00e7\u00e3o de dados para um formato consistente  </li> <li>Valida\u00e7\u00e3o: Aplica\u00e7\u00e3o de regras de neg\u00f3cio para garantir integridade  </li> </ul>"},{"location":"data_quality/#linhagem-de-dados","title":"Linhagem de Dados","text":"<p>A linhagem de dados documenta o fluxo dos dados, desde a origem at\u00e9 o consumo final, garantindo transpar\u00eancia e rastreabilidade.  </p>"},{"location":"dataobservar/","title":"\ud83d\udd0d Data Observability","text":""},{"location":"dataobservar/#data-observability","title":"Data Observability","text":"<p>A Observabilidade dos Dados est\u00e1 relacionada \u00e0 capacidade de analisar e monitorar os sistemas que fornecem os dados.  </p>"},{"location":"dataobservar/#pilares-da-observabilidade-dos-dados","title":"\ud83c\udfd7\ufe0f Pilares da Observabilidade dos Dados","text":"<ul> <li>Freshness: Atualidade dos dados  </li> <li>Distribution: Valores dentro de um intervalo aceit\u00e1vel  </li> <li>Volume: Integridade dos dados  </li> <li>Schema: Controle de mudan\u00e7as no esquema  </li> <li>Lineage: Rastreabilidade do fluxo de dados  </li> </ul>"},{"location":"dataobservar/#por-que-data-observability-e-importante","title":"\ud83d\ude80 Por que Data Observability \u00e9 importante?","text":"<ul> <li>Redu\u00e7\u00e3o de erros e inconsist\u00eancias nos dados antes que afetem an\u00e1lises e produtos.</li> <li>Melhoria da confiabilidade dos dados, garantindo que sejam sempre atualizados e \u00edntegros.</li> <li>Diagn\u00f3stico r\u00e1pido de problemas, ajudando times de engenharia de dados a resolverem falhas mais rapidamente.</li> <li>Melhoria no desempenho dos pipelines, reduzindo tempos de inatividade e gargalos.</li> <li>A observabilidade dos dados \u00e9 essencial para qualquer organiza\u00e7\u00e3o que depende de dados para tomada de decis\u00e3o, intelig\u00eancia de neg\u00f3cios e aprendizado de m\u00e1quina. Implement\u00e1-la corretamente pode evitar preju\u00edzos e aumentar a efici\u00eancia operacional. \ud83d\ude80</li> </ul>"},{"location":"dataops/","title":"\ud83d\udee0\ufe0f Data Ops / Dev Ops","text":""},{"location":"dataops/#dataops-data-operations","title":"DataOps (Data Operations)","text":"<p>Metodologia que combina DevOps, Agile e gest\u00e3o de dados para otimizar o ciclo de vida dos dados.  </p>"},{"location":"dataops/#beneficios","title":"Benef\u00edcios:","text":"<ul> <li>Qualidade dos dados  </li> <li>Automa\u00e7\u00e3o de pipelines  </li> <li>Monitoramento cont\u00ednuo  </li> </ul>"},{"location":"dataops/#devops","title":"DevOps","text":"<p>DevOps \u00e9 uma cultura e conjunto de pr\u00e1ticas que integram desenvolvimento e opera\u00e7\u00f5es de TI para entregar software com mais efici\u00eancia.  </p>"},{"location":"dataops/#devops-na-engenharia-de-dados","title":"DevOps na Engenharia de Dados","text":"<ul> <li>Automa\u00e7\u00e3o de infraestrutura </li> <li>Controle de vers\u00e3o </li> <li>Monitoramento e testes automatizados </li> </ul>"},{"location":"dataops/#infraestrutura-como-codigo-iac","title":"Infraestrutura como C\u00f3digo (IaC)","text":"<p>Permite gerenciar infraestrutura via c\u00f3digo, garantindo: - Consist\u00eancia - Efici\u00eancia - Automa\u00e7\u00e3o de ambientes </p>"},{"location":"dataops/#integracao-continua-ci-e-entrega-continua-cd","title":"Integra\u00e7\u00e3o Cont\u00ednua (CI) e Entrega Cont\u00ednua (CD)","text":"<p>Automatizam o desenvolvimento e entrega de software, permitindo: - Testes automatizados - Deploys r\u00e1pidos e seguros - Monitoramento cont\u00ednuo </p> <p>Na Engenharia de Dados, CI/CD \u00e9 usado para automatizar pipelines de dados e validar transforma\u00e7\u00f5es.  </p>"},{"location":"fatiamentodataframe/","title":"Fatiamento de DataFrame (Slicing)","text":""},{"location":"fatiamentodataframe/#fatiamento-do-dataframe-do-pandas-slicing","title":"Fatiamento do DataFrame do Pandas (Slicing)","text":"<p>Retornando as linhas da coluna de \u00edndice = estado2 e estado4</p> <pre><code>python\n\ndf2['estado2':'estado4']\n</code></pre> <p>out:</p> Estado Taxa Desemprego Taxa Crescimento Ano estado2 Rio de Janeiro 1.7 1.0 2005 estado3 Tocantins 1.6 2.0 2006 estado4 Bahia 2.4 3.0 2007 <p>Nesse caso, o estado4 n\u00e3o se classifica como exclusivo, ent\u00e3o, o estado4 entra! </p> <p>Retornando os valores das colunas onde a taxa desemprego for menor que 2</p> <pre><code>python\n\ndf2[ df2['Taxa Desemprego'] &lt; 2 ]\n</code></pre> <p>out:</p> Estado Taxa Desemprego Taxa Crescimento Ano estado1 Santa Catarina 1.5 0.0 2004 estado2 Rio de Janeiro 1.7 1.0 2005 estado3 Tocantins 1.6 2.0 2006 <p>Quando queremos aplicar uma regra de fatiamento, precisamos abrir colchetes 2 vezes!</p> <p></p> <p>Retornando os valores de 2 ou mais colunas!</p> <pre><code>python\n\ndf2[ ['Estado', 'Taxa Crescimento'] ]\n</code></pre> <p>out:</p> Estado Taxa Crescimento estado1 Santa Catarina 0.0 estado2 Rio de Janeiro 1.0 estado3 Tocantins 2.0 estado4 Bahia 3.0 estado5 Minas Gerais 4.0 <p>Preciso abrir dois colchetes quando eu quiser aplicar uma rera de fatiamento!!</p> <p></p>"},{"location":"filtrandostring/","title":"Filtrando com Strings","text":""},{"location":"filtrandostring/#filtrando-o-df-do-pandas-com-base-em-strings","title":"Filtrando o DF do Pandas com base em Strings","text":"<p>Mostrando o dataset que iremos manipular</p> <pre><code>python\n\ndf3.head()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 0 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-BO-10001798 Furniture Bush Somerset Collection Bookcase 261.9600 3.0 1 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-CH-10000454 Furniture Hon Deluxe Fabric Upholstered Stacking Chairs,... 731.9400 3.0 2 CA-2016-138688 2016-06-12 DV-13045 Corporate United States West OFF-LA-10000240 Office Supplies Self-Adhesive Address Labels for Typewriters b... 14.6200 2.0 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 4 US-2015-108966 2015-10-11 SO-20335 Consumer United States South OFF-ST-10000760 Office Supplies Eldon Fold 'N Roll Cart System 22.3680 2.0 <p></p> <p>buscando todas as strings, da coluna segmento, que come\u00e7a com as letras 'Con'</p> <pre><code>python\n\ndf3[ df3.Segmento.str.startswith('Con') ].head()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 0 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-BO-10001798 Furniture Bush Somerset Collection Bookcase 261.9600 3.0 1 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-CH-10000454 Furniture Hon Deluxe Fabric Upholstered Stacking Chairs,... 731.9400 3.0 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 4 US-2015-108966 2015-10-11 SO-20335 Consumer United States South OFF-ST-10000760 Office Supplies Eldon Fold 'N Roll Cart System 22.3680 2.0 5 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West FUR-FU-10001487 Furniture Eldon Expressions Wood and Plastic Desk Access... 48.8600 7.0 <p></p> <p>buscando todas as strings, da coluna segmento, que termina com as letras 'mer'</p> <pre><code>python\n\ndf3[ df3.Segmento.str.endswith('mer') ].head()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 0 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-BO-10001798 Furniture Bush Somerset Collection Bookcase 261.9600 3.0 1 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-CH-10000454 Furniture Hon Deluxe Fabric Upholstered Stacking Chairs,... 731.9400 3.0 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 4 US-2015-108966 2015-10-11 SO-20335 Consumer United States South OFF-ST-10000760 Office Supplies Eldon Fold 'N Roll Cart System 22.3680 2.0 5 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West FUR-FU-10001487 Furniture Eldon Expressions Wood and Plastic Desk Access... 48.8600 7.0 <p></p>"},{"location":"graficopandas/","title":"Constru\u00e7\u00e3o de Gr\u00e1ficos com Pandas","text":""},{"location":"graficopandas/#construcao-de-graficos-com-um-df-pandas","title":"Constru\u00e7\u00e3o de gr\u00e1ficos com um DF Pandas!","text":"<p>Apesar de ter essa funcionalidade no Pandas, n\u00e3o \u00e9 t\u00e3o recomendado, existem outras bibliotecas que fazem isso de forma melhor aprimorada!</p> <p>Instalando uma vers\u00e3o espec\u00edfica do Scikit Learn!</p> <pre><code>python\n\n!pip install scikit-learn==1.2.1\n</code></pre> <p>Importando o Scikit</p> <pre><code>python\n\nimport sklearn\nsklearn.__version__\n# A vers\u00e3o usada \u00e9 o 1.2.1\n</code></pre> <pre><code>out: '1.2.1'\n</code></pre> <p></p> <p>Vamos come\u00e7ar importando o dataset iris do scikit-learn</p> <pre><code>python\n\nfrom sklearn.datasets import load_iris\ndata = load_iris()\n</code></pre> <p>Ent\u00e3o carregamos o dataset iris como um dataframe do Pandas</p> <pre><code>python\n\ndf = pd.DataFrame(data['data'], columns = data['feature_names'])\ndf['species'] = data['target']\ndf.head()\n</code></pre> <p>out:</p> sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) species 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 <p></p> <p>Plotando o DF como um gr\u00e1fico</p> <pre><code>python\n\ndf.plot()\n</code></pre> <p>out:</p> <p></p> <p></p> <p>Vamos fazer um gr\u00e1fico de dispers\u00e3o entre duas vari\u00e1veis</p> <pre><code>python\n\ndf.plot.scatter(x = 'sepal length (cm)', y = 'sepal width (cm)')\n</code></pre> <p>out:</p> <p></p> <p></p> <p>Criando um gr\u00e1fico de \u00e1rea:</p> <pre><code>python\n\n\n# criando uma lista de t\u00edtulos de colunas\ncolumns = ['sepal length (cm)', 'petal length (cm)', 'sepal width (cm)', 'sepal width (cm)']\n\ndf[columns].plot.area()\n</code></pre> <p>out:</p> <p></p> <p></p> <p>Criando um gr\u00e1fico de barras com a m\u00e9dia de algumas colunas:</p> <pre><code>python\n\n\ndf.groupby('species').mean().plot.bar()\n</code></pre> <p>out:</p> <p></p> <p></p> <p>Ou ent\u00e3o, podemos fazer a contagem das classes da coluna species e plotamos em um gr\u00e1fico de pizza</p> <pre><code>python\n\ndf.groupby('species').count().plot.pie(y = 'sepal length (cm)')\n</code></pre> <p>out:</p> <p></p> <p></p> <p>Criando um gr\u00e1fico KDE para cada vari\u00e1vel do DF</p> <pre><code>python\n\ndf.plot.kde(subplots = True, figsize = (8,8))\n</code></pre> <p>out:</p> <p></p> <p></p>"},{"location":"indexacaonumpy/","title":"Indexa\u00e7\u00e3o em Arrays","text":""},{"location":"indexacaonumpy/#indexacao-em-arrays-numpy","title":"Indexa\u00e7\u00e3o em Arrays NumPy","text":"<p>LEMBRETE: A INDEXA\u00c7\u00c3O EM PYTHON COME\u00c7A POR 0 \u3164</p> <p>Printando os elementos da array</p> <pre><code>python\n\nprint(arr1)\n</code></pre> <pre><code>out: [10, 21, 32, 43, 48, 15, 76, 57, 89]\n</code></pre> <p>\u3164</p> <p>Para indexar um array numpy utilizamos os colchetes:</p> <pre><code>python\n\narr1[4]\n</code></pre> <pre><code>out: 48\n</code></pre> <p>\u3164</p> <p>Podemos retornar uma lista com os elementos desejados: No exemplo abaixo, o \u00edndice 4 n\u00e3o entra pois ele \u00e9 EXCLUSIVO!</p> <pre><code>python\n\narr1[1:4]\n</code></pre> <pre><code>out: array([21, 32, 43])\n</code></pre> <p>\u3164</p> <p>Caso queira que o \u00edndice 4 entre podemos fazer dessa forma:</p> <pre><code>python\n\narr1[1:4+1]\n</code></pre> <pre><code>out: array([21, 32, 43, 48])\n</code></pre> <p>\u3164</p> <p>Podemos procurar os \u00edndices de uma array atrav\u00e9s de uma lista de \u00edndices!</p> <pre><code>python\n\n# Criando uma lista de \u00edndices:\nindices = [1,2,5,6]\n\n# Procurando os \u00edndices do array a partir de uma lista de \u00edndices!\narr1[indices]\n</code></pre> <pre><code>out: array([21, 32, 15, 76])\n</code></pre> <p>\u3164</p> <p>Podemos fazer uma m\u00e1scara para verificar se os elementos de um array s\u00e3o pares</p> <pre><code>python\n\nmask = (arr1 % 2 == 0)\nprint(mask)\n\n</code></pre> <pre><code>out: array([ True, False,  True, False,  True, False,  True, False, False])\n</code></pre> <p>\u3164</p> <p>Ou ent\u00e3o, passar a m\u00e1scara como par\u00e2mentro do \u00edndice!</p> <pre><code>python\n\narr1[mask]\n</code></pre> <pre><code>out: array([10, 32, 48, 76])\n</code></pre> <p>\u3164</p> <p>Podemos alterar o valor de um elemento por um \u00edndice espec\u00edfico</p> <pre><code>python\n\narr1[0] = 100\narr1\n</code></pre> <pre><code>out: array([100,  21,  32,  43,  48,  15,  76,  57,  89])\n</code></pre> <p>\u3164</p> <p>Diferente das listas python, um array numpy n\u00e3o aceita valores diferentes, n\u00e3o tendo a din\u00e2micidade das listas python uma vez que, uma array \u00e9 de inteiros, n\u00e3o ir\u00e1 aceitar valores diferente de inteiros!</p> <pre><code>python\n\ntry:\n    arr1[0] = 'batatinha'\nexcept:\n    print('Erro! Opera\u00e7\u00e3o n\u00e3o permitida!')\n</code></pre> <pre><code>out: Erro! Opera\u00e7\u00e3o n\u00e3o permitida!\n</code></pre> <p>\u3164</p> <p>Diferente das listas python, o range n\u00e3o pode ser utilizado nas arrays, no lugar deles, usamos o arange, semelhante ao range, criamos uma progress\u00e3o aritm\u00e9tica a partir de um intervalo (start, stop, step)</p> <pre><code>python\n\narr2 = np.arange(0,50,5)\n</code></pre> <pre><code>out: 0, 5, 10, 15, 20, 25, 30, 35, 40, 45\n</code></pre> <p>\u3164</p> <p>Podemos criar um array preenchido com zeros, chamamos a fun\u00e7\u00e3o zeros e definimos quantos elementos vamos querer:</p> <pre><code>python\n\narr3 = np.zeros(10)\nprint(arr3)\n</code></pre> <pre><code>out: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n</code></pre> <p>\u3164</p> <p>As arrays tem posi\u00e7\u00f5es horizontais e verticais.  Com a fun\u00e7\u00e3o eye, podemos definir que queremos uma array, de tamanho vertical a ser determinado, contendo 0 e 1 nas diagonais dele:</p> <pre><code>\narr5 = np.eye(3)\nprint(arr5)\n</code></pre> <pre><code>out: [[1. 0. 0.]\n     [0. 1. 0.]\n     [0. 0. 1.]]\n</code></pre> <p>\u3164</p> <p>Podemos definir um array como argumento da fun\u00e7\u00e3o diagonal, e ent\u00e3o falar que iremos preencher as diagonais com valores espec\u00edficos de outro array numpy</p> <pre><code>python\n\narr6 = np.diag(np.array([1,2,3,4]))\nprint(arr6)\n</code></pre> <pre><code>out: [[1 0 0 0]\n     [0 2 0 0]\n     [0 0 3 0]\n     [0 0 0 4]]\n</code></pre> <p>\u3164</p> <p>Arrays Numpy aceitam diversos valores, como inteiros, floats, strings, booleanos...</p> <pre><code>python\n\narr7 = np.array([True, False, False, True])\nprint(arr7)\n</code></pre> <pre><code>out: [ True, False, False, True]\n</code></pre> <p>\u3164</p> <pre><code>python\n\narr8 = np.array(['Linguagem Python', 'Linguagem R', 'Linguagem Julia'])\nprint(arr8)\n</code></pre> <pre><code>out: ['Linguagem Python', 'Linguagem R', 'Linguagem Julia']\n</code></pre> <p>\u3164</p>"},{"location":"manipulandoarquivosnumpy/","title":"Manipulando Arquivos","text":""},{"location":"manipulandoarquivosnumpy/#manipulando-arquivos-com-numpy","title":"Manipulando arquivos com NumPy","text":"<p>Vamos importar a biblioteca OS para podermos manipular os arquivos:</p> <pre><code>python\n\nimport os\nfilename = os.path.join('dataset.csv')\n</code></pre> <p>\u3164</p> <p>Vamos importar o famoso dataset Iris Dataset, amplamente utilizado para aprendizado de m\u00e1quina e estat\u00edstica para classifica\u00e7\u00e3o e an\u00e1lise de dados.</p> <pre><code>python\n\n!more dataset.csv\n</code></pre> <pre><code>out: sepal_length,sepal_width,petal_length,petal_width,species\n     5.1,3.5,1.4,0.2,setosa\n     4.9,3,1.4,0.2,setosa\n     4.7,3.2,1.3,0.2,setosa\n     4.6,3.1,1.5,0.2,setosa\n     5,3.6,1.4,0.2,setosa\n     5.4,3.9,1.7,0.4,setosa\n     4.6,3.4,1.4,0.3,setosa\n     5,3.4,1.5,0.2,setosa\n     4.4,2.9,1.4,0.2,setosa\n     4.9,3.1,1.5,0.1,setosa\n     5.4,3.7,1.5,0.2,setosa\n     4.8,3.4,1.6,0.2,setosa\n     4.8,3,1.4,0.1,setosa\n     4.3,3,1.1,0.1,setosa\n     5.8,4,1.2,0.2,setosa\n     5.7,4.4,1.5,0.4,setosa\n     5.4,3.9,1.3,0.4,setosa\n     5.1,3.5,1.4,0.3,setosa\n     5.7,3.8,1.7,0.3,setosa\n     5.1,3.8,1.5,0.3,setosa\n     5.4,3.4,1.7,0.2,setosa\n     5.1,3.7,1.5,0.4,setosa\n     m--More--(14%)\n</code></pre> <p>\u3164</p> <p>Vamos carregar esse arquivo para dentro de um array, separando por v\u00edrgula, dizando que teremos 4 elmento por coluna e pulando a primeira linha do dataset pois ela \u00e9 o cabe\u00e7alho:</p> <pre><code>python\n\narr13 = np.loadtxt(filename, delimiter = ',', usecols = (0,1,2,3), skiprows = 1)\nprint(arr13)\n</code></pre> <pre><code>out: [[5.1 3.5 1.4 0.2]\n      [4.9 3.  1.4 0.2]\n      [4.7 3.2 1.3 0.2]\n      [4.6 3.1 1.5 0.2]\n      [5.  3.6 1.4 0.2]\n      [5.4 3.9 1.7 0.4]\n      [4.6 3.4 1.4 0.3]\n      [5.  3.4 1.5 0.2]\n      [4.4 2.9 1.4 0.2]\n      [4.9 3.1 1.5 0.1]\n      [5.4 3.7 1.5 0.2]\n      [4.8 3.4 1.6 0.2]\n      [4.8 3.  1.4 0.1]\n      [4.3 3.  1.1 0.1]\n      [5.8 4.  1.2 0.2]\n      [5.7 4.4 1.5 0.4]\n      [5.4 3.9 1.3 0.4]\n      [5.1 3.5 1.4 0.3]\n      [5.7 3.8 1.7 0.3]\n      [5.1 3.8 1.5 0.3]\n      [5.4 3.4 1.7 0.2]\n      [5.1 3.7 1.5 0.4]\n      [4.6 3.6 1.  0.2]\n      [5.1 3.3 1.7 0.5]\n      [4.8 3.4 1.9 0.2]\n     ...\n      [6.3 2.5 5.  1.9]\n      [6.5 3.  5.2 2. ]\n      [6.2 3.4 5.4 2.3]\n      [5.9 3.  5.1 1.8]]\n</code></pre>"},{"location":"manipulandoarquivosnumpy/#criando-um-grafico-com-numpy","title":"Criando um gr\u00e1fico com NumPy","text":"<p>Por mais que o NumPy tenha essa op\u00e7\u00e3o, n\u00e3o \u00e9 a melhor op\u00e7\u00e3o para isso, temos ferramentas que s\u00e3o mais dimensionadas para essa tarefa, mas, TUDO DEPENDE!</p> <p>Criando as vari\u00e1veis do gr\u00e1fico:</p> <pre><code>python\n\nvar1, var2 = np.loadtxt(filename, delimiter = ',', usecols = (0,1), skiprows = 1, unpack = True)\n</code></pre> <p>Criando o gr\u00e1fico de dispers\u00e3o para mostrar a rela\u00e7\u00e3o entre as duas colunas:</p> <pre><code>python\n\nimport matplotlib.pyplot as plt\nplt.show(plt.plot(var1, var2, 'o', markersize = 6, color = 'red'))\n</code></pre> <p>out:</p> <p></p>"},{"location":"manipulandoarrays/","title":"Manipula\u00e7\u00e3o Arrays","text":""},{"location":"manipulandoarrays/#manipulacao-de-arrays","title":"Manipula\u00e7\u00e3o de Arrays","text":"<p>Criando um array</p> <pre><code>python\n\narr23 = np.arange(10)\narr23\n</code></pre> <p> Buscando o elemento de menor valor em um array:</p> <pre><code>python\n\narr23.min()\n</code></pre> <pre><code>out: 0\n</code></pre> <p></p> <p>Buscando o elemento de maior valor em um array:</p> <pre><code>python\n\narr23.max()\n</code></pre> <pre><code>out: 9\n</code></pre> <p></p> <p>Atribuindo um valor em cada um dos elementos do array</p> <pre><code>python\n\nnp.array([1,2,3]) + 1.5\n</code></pre> <pre><code>out: array([2.5, 3.5, 4.5])\n</code></pre> <p></p> <p>Criando um array com valores decimais</p> <pre><code>python\n\narr24 = np.array([1.2,1.5,1.6,2.5,3.5,4.5])\n</code></pre> <p>Arredondando os valores (Acima de 0.5, o arredondamento ser\u00e1 para cima!)</p> <pre><code>python\n\narr25 = np.around(arr24)\nprint(arr25)\n</code></pre> <pre><code>out: array([1., 2., 2., 2., 4., 4.])\n</code></pre> <p></p> <p>Flatten</p> <p>Usado para criar uma c\u00f3pia unidimensional (achatada) de um array multidimensional. Basicamente: ele cria uma c\u00f3pia do array multidimensional em um novo unidimensional, contendo todos os valores do array original por\u00e9m em uma linha s\u00f3, seguindo a mesma ordem de elementos.</p> <p>Criando um array com 2 dimens\u00f5es:</p> <pre><code>python\n\narr26 = np.array(([1,2,3,4], [5,6,7,8]))\n</code></pre> <p>Deixando o array achatado:</p> <pre><code>python\n\narr27 = arr26.flatten()\narr27\n</code></pre> <pre><code>out: array([1, 2, 3, 4, 5, 6, 7, 8])\n</code></pre> <p></p> <p>Criando um array com 3 elementos</p> <pre><code>python\n\narr28 = np.array([1,2,3])\n</code></pre> <p></p> <p>Repetindo os elementos de um array determinadas vezes</p> <pre><code>python\n\nnp.repeat(arr28, 3)\n</code></pre> <pre><code>out: array([1, 1, 1, 2, 2, 2, 3, 3, 3])\n</code></pre> <p></p> <p>Criando um array:</p> <pre><code>python\n\narr29 = np.array([5,6])\n</code></pre> <p>Fazendo a c\u00f3pia de um array:</p> <pre><code>python\n\narr30 = np.copy(arr29)`\nprint(arr30)\n</code></pre> <pre><code>out: array([5,6])\n</code></pre>"},{"location":"manipulandodataframe/","title":"Manipulando DataFrames","text":""},{"location":"manipulandodataframe/#manipulando-dados-em-dataframes-do-pandas","title":"Manipulando Dados em DataFrames do Pandas","text":"<p>Criando um dicion\u00e1rio em python:</p> <pre><code>python\n\ndados = {\n    'Estado': ['Santa Catarina', 'Rio de Janeiro', 'Tocantins', 'Bahia', 'Minas Gerais'],\n    'Ano': [2004, 2005, 2006, 2007, 2008],\n    'Taxa Desemprego': [1.5, 1.7, 1.6, 2.4, 2.7]\n}\n</code></pre> <p></p> <p>Importando a classe DataFrame de dentro do pandas!</p> <pre><code>python\n\nfrom pandas import DataFrame\n</code></pre> <p></p> <p>Convertendo o dicion\u00e1rio python para um DataFrame do Pandas!</p> <pre><code>python\n\ndf = DataFrame(dados)\n</code></pre> <p></p> <p>Fazendo a visualiza\u00e7\u00e3o dos dados, criando um cabe\u00e7alho e mostrando as primeiras 5 primeiras linhas</p> <pre><code>python\n\ndf.head()\n</code></pre> <p>out:</p> Estado Ano Taxa Desemprego 0 Santa Catarina 2004 1.5 1 Rio de Janeiro 2005 1.7 2 Tocantins 2006 1.6 3 Bahia 2007 2.4 4 Minas Gerais 2008 2.7 <p>Isso \u00e9 um formato tabular, uma tabela que podemos encontrar em um BD relacional.</p> <p></p> <p>Verificando o tipo do df</p> <pre><code>python\n\ntype(df)\n</code></pre> <pre><code>out: pandas.core.frame.DataFrame\n</code></pre> <p>Ele nos diz que \u00e9 um objeto Dataframe do pandas. </p> <p>Reorganizando a ordem das colunas de forma f\u00e1cil!</p> <pre><code>python\n\nDataFrame(dados, columns = ['Estado', 'Taxa Desemprego', 'Ano'])\n</code></pre> <p>out:</p> Estado Taxa Desemprego Ano 0 Santa Catarina 1.5 2004 1 Rio de Janeiro 1.7 2005 2 Tocantins 1.6 2006 3 Bahia 2.4 2007 4 Minas Gerais 2.7 2008 <p></p> <p>Alterando o nome das palavras do \u00edndice!</p> <pre><code>python\n\ndf2 = DataFrame(dados,\n               columns = ['Estado', 'Taxa Desemprego', 'Taxa Crescimento', 'Ano'],\n               index = ['estado1', 'estado2', 'estado3', 'estado4', 'estado5'])\n</code></pre> <p>Mostando o DataFrame modificado</p> <pre><code>python\n\nprint(df2)\n</code></pre> <pre><code>out:\n                     Estado  Taxa Desemprego Taxa Crescimento   Ano\n    estado1  Santa Catarina              1.5              NaN  2004\n    estado2  Rio de Janeiro              1.7              NaN  2005\n    estado3       Tocantins              1.6              NaN  2006\n    estado4           Bahia              2.4              NaN  2007\n    estado5    Minas Gerais              2.7              NaN  2008\n\n</code></pre> <p>Como a taxa Crescimento n\u00e3o existia no meu dicion\u00e1rio, ele preenche com NaN.</p> <p></p> <p>Retornando os valores do DataFrame</p> <pre><code>python\n\ndf.values\n</code></pre> <pre><code>out:\n\narray([['Santa Catarina', 2004, 1.5],\n           ['Rio de Janeiro', 2005, 1.7],\n           ['Tocantins', 2006, 1.6],\n           ['Bahia', 2007, 2.4],\n           ['Minas Gerais', 2008, 2.7]], dtype=object)\n</code></pre> <p></p> <p>Retornando o tipo de cada coluna</p> <pre><code>python\n\ndf2.dtypes\n</code></pre> <pre><code>out:\n\n    Estado               object\n    Taxa Desemprego     float64\n    Taxa Crescimento     object\n    Ano                   int64\n    dtype: object\n</code></pre> <p>Quando o pandas n\u00e3o reconhece o conte\u00fado, ele classifica o mesmo como String</p> <p></p> <p>Retornando as colunas do DF</p> <pre><code>python\n\ndf2.columns\n</code></pre> <pre><code>out: Index(['Estado', 'Taxa Desemprego', 'Taxa Crescimento', 'Ano'], dtype='object')\n</code></pre> <p></p> <p>Imprimindo apenas uma coluna do DataFrame</p> <pre><code>python\n\ndf2['Estado']\n</code></pre> <pre><code>out:\n\n    estado1    Santa Catarina\n    estado2    Rio de Janeiro\n    estado3         Tocantins\n    estado4             Bahia\n    estado5      Minas Gerais\n    Name: Estado, dtype: object\n</code></pre> <p></p> <p>Imprimindo duas colunas do DF</p> <pre><code>python\n\n\ndf2[['Taxa Desemprego', 'Ano']]\n</code></pre> <p>out:</p> Taxa Desemprego Ano estado1 1.5 2004 estado2 1.7 2005 estado3 1.6 2006 estado4 2.4 2007 estado5 2.7 2008 <p>Quando eu estou imprimindo apenas 1 coluna, eu utilizo 1 colchete e o nome da coluna.</p> <p>J\u00e1 quando eu imprimir mais de 1 coluna, preciso passar uma lista de colunas para conseguir fazer essa opera\u00e7\u00e3o. </p> <p>Filtrando uma linha espec\u00edfica do meu DF</p> <pre><code>python\n\ndf2.filter(items = ['estado3'], axis = 0)\n</code></pre> <p>out:</p> Estado Taxa Desemprego Taxa Crescimento Ano estado3 Tocantins 1.6 NaN 2006 <p></p>"},{"location":"manipulandomatriz/","title":"Manipulando Matrizes","text":""},{"location":"manipulandomatriz/#manipulando-matrizes","title":"Manipulando Matrizes","text":"<p>Uma matriz NumPy (ou numpy.ndarray) \u00e9 uma estrutura de dados multidimensional otimizada para armazenar e operar com grandes quantidades de dados num\u00e9ricos de maneira eficiente. Ela pertence \u00e0 biblioteca NumPy, que \u00e9 amplamente utilizada em computa\u00e7\u00e3o cient\u00edfica, aprendizado de m\u00e1quina, an\u00e1lise de dados e muitas outras \u00e1reas.</p> <p>\u3164</p> <p>\u3164 Criando uma Matriz com 2 dimens\u00f5es:</p> <pre><code>python\n\narr9 = np.array([ [1,2,3], [4,5,6] ])\nprint(arr9)\n</code></pre> <pre><code>out: [[1 2 3]\n     [4 5 6]]\n</code></pre> <p>\u3164</p> <p>Verificando a forma (shape) desse array criado:</p> <pre><code>python\n\nprint(arr9.shape)\n</code></pre> <pre><code>out: (2, 3)\n</code></pre> <p>Ele nos retorna, que \u00e9, uma matriz, com 2 dimens\u00f5es e 3 valores em cada dimens\u00e3o!</p> <p>\u3164</p> <p>\u3164</p> <p>Dessa forma, eu crio uma matriz, com 2 dimens\u00f5es preenchida com o n\u00famero 1:</p> <pre><code>python\n\narr10 = np.ones((2,3))\nprint(arr10)\n</code></pre> <pre><code>out: [[1. 1. 1.]\n     [1. 1. 1.]]\n</code></pre> <p>\u3164\u3164</p> <p>Vamos criar uma listas de listas:</p> <pre><code>python\n\nlista = [[10,20,30], [90,80,100], [1,2,3]]\n</code></pre> <p>Criando uma array numpy a partir de uma lista de listas:</p> <pre><code>python\n\narr11 = np.matrix(lista)\n</code></pre> <p>Verificando a forma (shape) desse array criado:</p> <pre><code>python\n\narr11.shape\n</code></pre> <pre><code>out: (3, 3)\n</code></pre> <p>Nos retornando que ele tem 3 dimens\u00f5es, com 3 elementos em cada</p> <p>\u3164\u3164</p> <p>\u3164\u3164</p>"},{"location":"manipulandomatriz/#manipulando-os-elementos-das-matrizes","title":"Manipulando os elementos das matrizes","text":""},{"location":"manipulandomatriz/#fatiando-uma-matriz-slicing","title":"Fatiando uma matriz (SLICING)","text":"<p>antes de tudo: INDEXA\u00c7\u00c3O EM PYHTON COME\u00c7A POR ZERO!</p> <p>A indexa\u00e7\u00e3o por matrizes \u00e9 um pouco diferente, como vamos manipular uma matriz que tem 3 dimens\u00f5es, precisamos especificar, qual a dimens\u00e3o e depois qual elemento:</p> <p>[dimens\u00e3o, elemento] \u3164\u3164</p> <p>\u3164\u3164</p> <p>Vendo os valores da array a ser manipulada:</p> <pre><code>python\n\nprint(arr11)\n</code></pre> <pre><code>out: [[ 10,  20,  30]\n     [ 90,  80, 100]\n     [  1,   2,   3]]\n</code></pre> <p>\u3164\u3164</p> <p>Retornando o elemento de indice 1 da linha de indice 2:</p> <pre><code>python\n\narr11[2,1]\n</code></pre> <pre><code>out: 2\n</code></pre> <p>\u3164\u3164</p> <p>Vamos retornar das linhas de \u00edndice 0, at\u00e9 1 (Porque o \u00edndice 2 \u00e9 EXCLUSIVO), apenas os elementos de \u00edndice 2</p> <pre><code>python\n\narr11[0:2, 2]\n</code></pre> <pre><code>out: matrix([[ 30],\n            [100]])\n</code></pre> <p>\u3164\u3164</p> <p>Retornando da linha de \u00edndice 1, qualquer valor (todos valores)</p> <pre><code>python\n\narr11[1, ]\n</code></pre> <pre><code>out: matrix([[ 90,  80, 100]])\n</code></pre> <p>\u3164</p>"},{"location":"manipulandomatriz/#manipulando-os-elementos","title":"Manipulando os elementos","text":"<p>Alterando um elemento pelo \u00edndice:</p> <pre><code>\narr11[1,0] = 100 \n</code></pre> <p>\u3164</p> <p>Se n\u00e3o definirmos o tipo do dado, o numpy define ele, por\u00e9m, pode acabar cometendo erros, \u00e9 um bom ponto de aten\u00e7\u00e3o:</p> <pre><code>python\n\nx = np.array([1,2]) # o Numpy decide o tipo do dado\ny = np.array([1.0,2.0]) # o Numpy decide o tipo do dado\nz = np.array([1,2], dtype = np.float64) # Aqui foi definido o tipo de dado em particular\n\nprint(x.dtype, y.dtype, z.dtype)\n</code></pre> <pre><code>out: print(x.dtype, y.dtype, z.dtype)\n</code></pre> <p>\u3164</p> <p>Podemos definir o tipo de um array j\u00e1 na cria\u00e7\u00e3o:</p> <pre><code>python\n\narr12 = np.array([[24, 76, 92, 14], [47, 36, 89, 2]], dtype = float)\nprint(arr12)\n</code></pre> <pre><code>out: [[24. 76. 92. 14.]\n     [47. 36. 89.  2.]]\n</code></pre> <p>\u3164</p>"},{"location":"manipulandoobjetos/","title":"Manipulando Objetos 3D e 4D","text":""},{"location":"manipulandoobjetos/#manipulando-objetos-3d-e-4d-em-numpy","title":"Manipulando objetos 3D e 4D em NumPy","text":""},{"location":"manipulandoobjetos/#3-dimensoes","title":"3 Dimens\u00f5es","text":"<p>Criando um array de 3 dimens\u00f5es:</p> <pre><code>python\n\narr_3d = np.array([\n    [\n        [1, 2, 3, 4],\n        [5, 6, 7, 8],\n        [9, 10, 11, 12]\n    ],\n    [\n        [13, 14, 15, 16],\n        [17, 18, 19, 20],\n        [21, 22, 23, 24]\n    ]\n])\n\nprint(arr_3d)\n</code></pre> <pre><code>out: [[[ 1  2  3  4]\n       [ 5  6  7  8]\n       [ 9 10 11 12]]\n\n      [[13 14 15 16]\n       [17 18 19 20]\n       [21 22 23 24]]]\n</code></pre> <p>\u3164</p> <p>Vamos saber o n\u00famero de dimens\u00f5es de um objeto:</p> <pre><code>python\n\narr_3d.ndim\n</code></pre> <pre><code>out: 3\n</code></pre> <p>\u3164</p> <p>Sabendo a forma (shape) da array:</p> <pre><code>python\n\nprint(arr_3d.shape)\n</code></pre> <pre><code>out: (2, 3, 4)\n</code></pre> <p>2 elementos, com 3 linhas e 4 elementos em cada linha.</p> <p>\u3164</p>"},{"location":"manipulandoobjetos/#4-dimensoes","title":"4 Dimens\u00f5es","text":"<p>Criando um array de 4 dimens\u00f5es:</p> <pre><code>python\n\narr_4d = np.array([\n    [\n        [\n            [1, 2, 3, 4, 5],\n            [6, 7, 8, 9, 10],\n            [11, 12, 13, 14, 15],\n            [16, 17, 18, 19, 20]\n        ],\n        [\n            [21, 22, 23, 24, 25],\n            [26, 27, 28, 29, 30],\n            [31, 32, 33, 34, 35],\n            [36, 37, 38, 39, 40]\n        ],\n          [\n            [1, 2, 3, 4, 5],\n            [6, 7, 8, 9, 10],\n            [11, 12, 13, 14, 15],\n            [16, 17, 18, 19, 20]\n        ]\n    ],\n    [\n        [\n            [41, 42, 43, 44, 45],\n            [46, 47, 48, 49, 50],\n            [51, 52, 53, 54, 55],\n            [56, 57, 58, 59, 60]\n        ],\n        [\n            [61, 62, 63, 64, 65],\n            [66, 67, 68, 69, 70],\n            [71, 72, 73, 74, 75],\n            [76, 77, 78, 79, 80]\n        ],\n          [\n            [1, 2, 3, 4, 5],\n            [6, 7, 8, 9, 10],\n            [11, 12, 13, 14, 15],\n            [16, 17, 18, 19, 20]\n        ]\n    ]\n])\n\nprint(arr_4d)\n</code></pre> <pre><code>out: [[[[ 1  2  3  4  5]\n        [ 6  7  8  9 10]\n        [11 12 13 14 15]\n        [16 17 18 19 20]]\n\n       [[21 22 23 24 25]\n        [26 27 28 29 30]\n        [31 32 33 34 35]\n        [36 37 38 39 40]]\n\n       [[ 1  2  3  4  5]\n        [ 6  7  8  9 10]\n        [11 12 13 14 15]\n        [16 17 18 19 20]]]\n\n\n      [[[41 42 43 44 45]\n        [46 47 48 49 50]\n        [51 52 53 54 55]\n        [56 57 58 59 60]]\n\n       [[61 62 63 64 65]\n        [66 67 68 69 70]\n        [71 72 73 74 75]\n        [76 77 78 79 80]]\n\n       [[ 1  2  3  4  5]\n        [ 6  7  8  9 10]\n        [11 12 13 14 15]\n        [16 17 18 19 20]]]]\n</code></pre> <p>\u3164</p> <p>Sabendo o n\u00famero de dimens\u00f5es do array:</p> <pre><code>python\n\narr_4d.ndim\n</code></pre> <pre><code>out: 4\n</code></pre> <p>\u3164</p> <p>Sabendo a forma (shape) da array</p> <pre><code>python\n\nprint(arr_4d.shape)\n</code></pre> <pre><code>out: (2, 3, 4, 5)\n</code></pre> <p>Ele est\u00e1 nos dizendo que \u00e9:</p> <pre><code>2 blocos:\n    com 3 estruturas cada um:\n        com 4 linhas em cada estrutura:\n             com 5 elementos em cada linha.\n</code></pre> <p>\u3164</p>"},{"location":"manipulandoobjetos/#fatiamento-de-um-array-de-4-dimensoes-slicing","title":"Fatiamento de um Array de 4 Dimens\u00f5es (SLICING)","text":"<p>Como estamos manipulando um elemento de 4 dimens\u00f5es, precisamos defiir qual bloco, qual estrutura, qual linha e qual elemento</p> <p>[bloco, estrutura, linha, elemento]</p> <p>\u3164</p> <p>Retornando o elemento, do bloco de \u00edndice 0, na estrutura de \u00edndice 2, na linha de \u00edndice 1, todos os elementos (Como n\u00e3o foi espec\u00edficado o elemento, ele retorna a linha inteira!)</p> <pre><code>python\n\narr_4d[0,2,1]\n</code></pre> <pre><code>out: arr_4d[0,2,1,4]\n</code></pre> <p>\u3164</p> <p>Retornando o elemento de bloco de \u00edndice 0, na estrutura de \u00edndice 2, na linha de \u00edndice 1, o elemento de \u00edndice 4</p> <pre><code>python\n\narr_4d[0,2,1,4]\n</code></pre> <pre><code>out: 10\n</code></pre> <p>\u3164</p>"},{"location":"modelagemdados/","title":"\ud83d\udcca Modelagem de Dados","text":""},{"location":"modelagemdados/#modelagem-de-dados","title":"Modelagem de Dados","text":""},{"location":"modelagemdados/#dados-definicao","title":"Dados - Defini\u00e7\u00e3o","text":"<p>Dados s\u00e3o valores, observa\u00e7\u00f5es ou resultados armazenados em um sistema ou base de dados. Os dados por si s\u00f3 n\u00e3o t\u00eam tanto valor, mas quando convertidos em informa\u00e7\u00f5es, tornam-se extremamente valiosos.  </p>"},{"location":"modelagemdados/#modelagem-de-dados-definicao","title":"Modelagem de Dados - Defini\u00e7\u00e3o","text":"<p>A modelagem de dados \u00e9 o processo de projetar e criar modelos e estruturas l\u00f3gicas que representam como os dados ser\u00e3o armazenados, relacionados e utilizados.  </p>"},{"location":"modelagemdados/#modelagem-relacional","title":"Modelagem Relacional","text":"<ul> <li>Baseada em rela\u00e7\u00f5es entre entidades, com tabelas e campos  </li> <li>Inclui modelos 1:1, 1:N e N:N  </li> <li>Utilizada em bancos de dados relacionais transacionais  </li> </ul>"},{"location":"modelagemdados/#modelagem-dimensional","title":"Modelagem Dimensional","text":"<ul> <li>Utilizada em BI e DW  </li> <li>Facilita a an\u00e1lise multidimensional de dados  </li> <li>Constru\u00edda a partir de Fatos (tabelas de medidas) e Dimens\u00f5es (tabelas de contexto)  </li> </ul>"},{"location":"modelagemdados/#modelagem-de-data-lakes","title":"Modelagem de Data Lakes","text":"<ul> <li>Projetada para armazenar dados n\u00e3o estruturados  </li> <li>Flex\u00edvel e menos estruturada que a modelagem relacional  </li> </ul>"},{"location":"modelagemdados/#esquema-em-modelagem-de-dados","title":"Esquema em Modelagem de Dados","text":"<ul> <li>DW e bancos transacionais: Esquema obrigat\u00f3rio  </li> <li>Data Lakes: N\u00e3o possuem esquema pr\u00e9-definido, mas requerem organiza\u00e7\u00e3o  </li> </ul>"},{"location":"modelagemdados/#constraints","title":"Constraints","text":"<p>Regras aplicadas a um banco de dados para garantir a integridade dos dados, como: - Valores \u00fanicos - Restri\u00e7\u00f5es de valor nulo - Regras de valida\u00e7\u00e3o  </p>"},{"location":"modelagemdados/#formas-normais","title":"Formas Normais","text":"<p>Regras para estruturar bancos de dados transacionais: - 1\u00aa Forma Normal (1FN): Todos os valores devem ser indivis\u00edveis - 2\u00aa Forma Normal (2FN): Todos os atributos n\u00e3o-chave devem depender da chave prim\u00e1ria - 3\u00aa Forma Normal (3FN): Evita depend\u00eancias transitivas entre atributos  </p>"},{"location":"modelagemdados/#projeto-de-indices","title":"Projeto de \u00cdndices","text":"<p>Os \u00edndices melhoram a performance de consultas, devendo ser bem planejados para: - Identificar colunas mais utilizadas - Escolher o tipo adequado de \u00edndice - Criar \u00edndices apenas em tabelas grandes - Monitorar e otimizar regularmente  </p>"},{"location":"modelagemdados/#particionamento","title":"Particionamento","text":"<p>T\u00e9cnica que divide grandes tabelas em partes menores, melhorando: - Desempenho - Manuten\u00e7\u00e3o - Escalabilidade  </p> <p>\"O Arquiteto de Dados planeja e projeta. O Engenheiro de Dados executa e mant\u00e9m.\"</p>"},{"location":"modelagemdados/#granularidade","title":"Granularidade","text":"<p>Refere-se ao n\u00edvel de detalhe dos dados armazenados. Quanto maior a granularidade, mais detalhados os dados ser\u00e3o.  </p>"},{"location":"mtpl/","title":"MatPlotLib","text":""},{"location":"mtpl/#matplotlib","title":"Matplotlib","text":"<p>\u00c9 um pacote python que nos permite criar gr\u00e1ficos, por\u00e9m, eles ser\u00e3o criados via c\u00f3digo python! \u00c9 poss\u00edvel criar dashboards inteiras apenas com essa biblioteca.</p> <p>Vamos instalar as depend\u00eancias do matplotlib</p> <pre><code>python\n\n# !pip install matplotlib==3.7.1\n</code></pre> <p>Importando o MatPlotLib para utiliza\u00e7\u00e3o do mesmo</p> <pre><code>python\n\nimport matplotlib as mpl\nmpl.__version__\n</code></pre> <pre><code>out: '3.7.1'\n</code></pre> <p>Talvez seja preciso dar um downgrade na sua vers\u00e3o do numpy!</p> <p>Caso seja preciso, fa\u00e7a isso:</p> <pre><code>python\n\n# !pip install \"numpy&lt;2\"\n</code></pre> <p>Vamos importar o pacote do pyplot da biblioteca do matplotlib!</p> <pre><code>python\n\n# O pyplot \u00e9 um pacote dentro do matplotlib!\nimport matplotlib.pyplot as plt\n%matplotlib inline\n</code></pre> <p></p>"},{"location":"mtpl/#grafico-de-linha","title":"Gr\u00e1fico de Linha","text":"<p>O m\u00e9todo plot define os eixos do gr\u00e1fico</p> <pre><code>python\n\n\nplt.plot([1,3,5], [2,4,7])\nplt.show()\n</code></pre> <p></p> <p>com apenas 2 linhas de c\u00f3digo \u00e9 poss\u00edvel criar um gr\u00e1fico de forma pr\u00e1tica</p> <p></p> <p>Mais um gr\u00e1fico de linha</p> <pre><code>python\n\nx = [2,3,5]\ny = [3,5,7]\n\n# passamos como par\u00e2metro as listas\nplt.plot(x,y)\n\n# Damos um t\u00edtulo pro eixo X\nplt.xlabel('Vari\u00e1vel 1')\n\n# Damos um t\u00edtulo pro eixo Y\nplt.ylabel('Vari\u00e1vel 2')\n\n# Damos um t\u00edtulo pro Gr\u00e1fico em si\nplt.title('Teste Plot')\n\n# Exibir o gr\u00e1fico\nplt.show()\n</code></pre> <p></p> <p></p>"},{"location":"mtpl/#grafico-de-barras","title":"Gr\u00e1fico de Barras","text":"<p>Criando um gr\u00e1fico de barras</p> <pre><code>python\n\nx1 = [2,4,6,8,10]\ny1 = [6,7,8,2,4]\n\n# Para criar o gr\u00e1fico de barras, \u00e9 preciso declarar o '.bar'\nplt.bar(x1,y1, label = 'Barras', color = 'green')\nplt.legend()\nplt.show()\n</code></pre> <p></p> <p></p> <p>Criando dois gr\u00e1ficos de barras na mesma \u00e1rea de plotagem</p> <pre><code>python\n\nx2 = [1,3,5,7,9]\ny2 = [7,8,2,4,2]\n\nplt.bar(x1,y1, label = 'Listas1', color = 'blue')\nplt.bar(x2,y2, label = 'Listas2', color = 'red')\nplt.legend()\nplt.show()\n</code></pre> <p></p> <p>Como chamamos o m\u00e9todo bar duas vezes, ele cria dois gr\u00e1ficos na mesma \u00e1rea de plotagem! Pode parecer que \u00e9 apenas 1 gr\u00e1fico, mas s\u00e3o dois que est\u00e3o se combinando!</p> <p></p> <p>Criando um gr\u00e1fico de barras com os \u00edndices criados a partir de um range a partir da lista de valores</p> <pre><code>python\n\nidades = [22, 65, 45, 55, 21, 22, 34, 42, 41, 4, 99, 101, 120, 122, 130, 111, 115, 80, 75, 54, 44, 64, 13, 18, 48]\n\n# Criando um intervalo de valores com os \u00edndices da lista\nids = [x for x in range(len(idades))]\n\nplt.bar(ids, idades)\nplt.show()\n</code></pre> <p> </p> <p>Criando um histograma de barras:</p> <pre><code>python\n\nbins = [0,10,20,30,40,50,60,70,80,90,100,110,120,130]\n\n# Se parece com um gr\u00e1fico de barra, mas n\u00e3o \u00e9!\n# o rwidth define a largura de cada barra.\nplt.hist(idades, bins, histtype = 'bar', rwidth = 0.5)\nplt.show()\n</code></pre> <p></p> <p></p> <p>Criando um gr\u00e1fico de barras com as barras preenchidas umas com as outras</p> <pre><code>python\n\n# Com o stefilled, as barras ficaram preenchidas umas com as outras.\nplt.hist(idades, bins, histtype = 'stepfilled', rwidth = 0.8)\nplt.show()\n</code></pre> <p></p> <p></p> <p>Essa biblioteca nos permite customizar os gr\u00e1ficos com diversas op\u00e7\u00f5es! Importante sempre consultar a documenta\u00e7\u00e3o para estudo.</p> <p>URL: https://matplotlib.org/</p>"},{"location":"mtpl/#grafico-de-dispersao-scatter-plot","title":"Gr\u00e1fico de Dispers\u00e3o (Scatter Plot)","text":"<p>Criando um gr\u00e1fico de dispers\u00e3o</p> <pre><code>python\n\nx = [1,2,3,4,5,6,7,8]\ny = [5,2,4,5,6,8,4,8]\n\n# Para chamarmos esse gr\u00e1fico, utilizamos o 'scatter'\n# Esse marker \u00e9 como os pontos ir\u00e3o ser plotados no gr\u00e1fico, pode ser *, um X, entre outros.\nplt.scatter(x,y, label = 'Pontos', color = 'black', marker = 'o')\nplt.legend()\nplt.show()\n</code></pre> <p></p> <p></p>"},{"location":"mtpl/#grafico-de-area-empilhada","title":"Gr\u00e1fico de \u00c1rea Empilhada","text":"<p>Basicamente um gr\u00e1fico de \u00e1rea, mas na mesma \u00e1rea de plotagem</p> <p>Criando um gr\u00e1fico de \u00e1rea empilhada</p> <pre><code>python\n\nimport matplotlib.pyplot as plt\n\n# Dados\ndias = [1, 2, 3, 4, 5]\ndormir = [7, 8, 6, 7, 7]\ncomer = [2, 3, 4, 5, 3]\ntrabalhar = [7, 8, 7, 2, 2]\npassear = [8, 5, 7, 8, 13]\n\n# Criando o gr\u00e1fico de \u00e1reas empilhadas\nplt.stackplot(dias, dormir, comer, trabalhar, passear, colors=['m', 'c', 'r', 'k', 'b'], labels=['Dormir', 'Comer', 'Trabalhar', 'Passear'])\n\n# Adicionando legenda e t\u00edtulo\nplt.legend(loc='upper left')\nplt.title('Distribui\u00e7\u00e3o de Atividades ao Longo dos Dias')\nplt.xlabel('Dias')\nplt.ylabel('Horas')\n\n# Exibir o gr\u00e1fico\nplt.show()\n</code></pre> <p></p> <p></p>"},{"location":"mtpl/#grafico-de-pizza-pie-plot","title":"Gr\u00e1fico de Pizza (Pie Plot)","text":"<p>Criando um gr\u00e1fico de pizza</p> <pre><code>python\n\n# Aqui eu coloco os valores\nfatias = [7,2,2,13]\n\n# Aqui eu coloco os labels, ou seja, as fatias\natividades = ['dormir', 'comer', 'passear', 'trabalhar']\n\n# crio uma lista de cores\ncores = ['olive', 'lime', 'violet', 'royalblue']\n\n# crio o pieplot, colocando os valores, as fatias, as cores, defino um \u00e2ngulo para come\u00e7ar, \n# coloco uma sombra para estilizar e ent\u00e3o defino que  a fatia comer ir\u00e1 ter o efeito de sendo retirada.\nplt.pie(fatias, labels = atividades, colors = cores, startangle = 90, shadow = True, explode = (0,0.2,0,0))\nplt.show()\n</code></pre> <p></p> <p></p>"},{"location":"mtpl_sb/","title":"Gr\u00e1ficos com Matplotlib e Seaborn - Python","text":""},{"location":"mtpl_sb/#por-que-criar-graficos-via-programacao-em-python-se-podemos-usar-powerbi-tableau-ou-locker-studio","title":"Por que criar gr\u00e1ficos via programa\u00e7\u00e3o em python se podemos usar PowerBI, Tableau ou Locker Studio?","text":"<ul> <li> <p>As ferramentas lowcode (PowerBI, Tableau e Locker Studio), s\u00e3o \u00f3timas ferramentas e alternativas para criar gr\u00e1ficos b\u00e1sicos rapidamente, mas oferecem pouca flexibilidade.</p> </li> <li> <p>Essas ferramentas s\u00e3o propriet\u00e1rias e n\u00e3o \u00e9 poss\u00edvel modificar o padr\u00e3o que eles oferecem.</p> </li> <li> <p>As solu\u00e7\u00e3os open-source como Matplotlib e Seaborn (Linguagem Python), s\u00e3o gratuitas, totalmente customiz\u00e1veis e flex\u00edveis.</p> </li> <li> <p>A linguagem python \u00e9 amplamente usada em Ci\u00eancia de Dados e oferecem um ambiente completo, incluindo a cria\u00e7\u00e3o de gr\u00e1ficos.</p> </li> </ul>"},{"location":"numpycompandas/","title":"Utilizando NumPy com Pandas","text":""},{"location":"numpycompandas/#usando-numpy-e-pandas-para-manipulacao-de-dados","title":"Usando NumPy e Pandas para Manipula\u00e7\u00e3o de Dados!","text":"<p>Imprimindo o DataFrame que ser\u00e1 manipulado</p> <pre><code>python\n\ndf2.head()\n</code></pre> <p>out:</p> Estado Taxa Desemprego Taxa Crescimento Ano estado1 Santa Catarina 1.5 NaN 2004 estado2 Rio de Janeiro 1.7 NaN 2005 estado3 Tocantins 1.6 NaN 2006 estado4 Bahia 2.4 NaN 2007 estado5 Minas Gerais 2.7 NaN 2008 <p></p> <p>Imprimindo um resumo estat\u00edstico do meu DF das colunas do tipo num\u00e9rico!</p> <pre><code>python\n\ndf2.describe()\n</code></pre> <p>out:</p> Taxa Desemprego Ano count 5.000000 5.000000 mean 1.980000 2006.000000 std 0.535724 1.581139 min 1.500000 2004.000000 25% 1.600000 2005.000000 50% 1.700000 2006.000000 75% 2.400000 2007.000000 max 2.700000 2008.000000 <p></p> <p>Retornando True para as colunas com valor ausente!</p> <pre><code>python\n\ndf2.isna()\n</code></pre> <p>out:</p> Estado Taxa Desemprego Taxa Crescimento Ano estado1 False False True False estado2 False False True False estado3 False False True False estado4 False False True False estado5 False False True False <p></p> <p>Olhando uma coluna espec\u00edfica para verificar se h\u00e1 valores ausentes.</p> <pre><code>python\n\ndf2['Taxa Crescimento'].isna()\n</code></pre> <pre><code>out:\n\n    estado1    True\n    estado2    True\n    estado3    True\n    estado4    True\n    estado5    True\n    Name: Taxa Crescimento, dtype: bool\n</code></pre> <p></p> <p>Importando o NumPy para nos auxiliar na manipula\u00e7\u00e3o</p> <pre><code>python\n\nimport numpy as np\n</code></pre> <p></p> <p>Usando o numpy para preencher uma das colunas do df!</p> <pre><code>python\n\ndf2['Taxa Crescimento'] = np.arange(5.)\ndf2\n</code></pre> <p>out:</p> Estado Taxa Desemprego Taxa Crescimento Ano estado1 Santa Catarina 1.5 0.0 2004 estado2 Rio de Janeiro 1.7 1.0 2005 estado3 Tocantins 1.6 2.0 2006 estado4 Bahia 2.4 3.0 2007 estado5 Minas Gerais 2.7 4.0 2008 <p></p> <p>Agora, verificando se ainda h\u00e1 valores ausentes no DF</p> <pre><code>python\n\ndf2['Taxa Crescimento'].isna()\n</code></pre> <pre><code>out:\n\n    estado1    False\n    estado2    False\n    estado3    False\n    estado4    False\n    estado5    False\n    Name: Taxa Crescimento, dtype: bool\n</code></pre> <p></p>"},{"location":"operacoesmatematicas/","title":"Opera\u00e7\u00f5es Matem\u00e1ticas","text":""},{"location":"operacoesmatematicas/#operacoes-matematicas-com-numpy","title":"Opera\u00e7\u00f5es Matem\u00e1ticas com Numpy","text":"<p>Criando o Array para manipularmos</p> <pre><code>python\n\narr15 = np.arange(1,10)\narr15\n</code></pre> <p>\u3164</p> <p>Somando todos os elementos dentro de uma array:</p> <pre><code>python\n\nnp.sum(arr15)\n</code></pre> <pre><code>out: 45\n</code></pre> <p>\u3164</p> <p>Retornando o produto da array:</p> <pre><code>python\n\nnp.prod(arr15)\n</code></pre> <pre><code>out: 362880\n</code></pre> <p>\u3164</p> <p>Retornando a soma acumulada</p> <pre><code>python\n\nnp.cumsum(arr15)\n</code></pre> <pre><code>out: array([ 1,  3,  6, 10, 15, 21, 28, 36, 45])\n</code></pre> <p>\u3164</p> <p>Criando dois arrays</p> <pre><code>python\n\narr16 = np.array([3,2,1])\narr17 = np.array([1,2,3])\n</code></pre> <p>Somando os elementos dos dois arrays:</p> <pre><code>python\n\narr18 = np.add(arr16,arr17)\nprint(arr18)\n</code></pre> <pre><code>out: [4 4 4]\n</code></pre>"},{"location":"operacoesmatematicas/#multiplicacao-entre-matrizes","title":"Multiplica\u00e7\u00e3o entre matrizes","text":"<p>Para isso, podemos usar a fun\u00e7\u00e3o dot() ou o operador @, ambos, conseguem executar uma multiplica\u00e7\u00e3o matricial.</p> <p>PONTO IMPORTANTE: O n\u00famero de colunas da primeira matriz deve ser obrigatoriamente igual ao n\u00famero de linhas da segunda matriz.</p> <p>Criando as arrays para manipula\u00e7\u00e3o:</p> <pre><code>python\n\narr19 = np.array(([1,2], [3,4]))\narr20 = np.array(([5,6], [7,8]))\n</code></pre> <pre><code>python\n\n# As duas formas est\u00e3o corretas!\narr21 = np.dot(arr19, arr20)\narr23 = arr19 @ arr20\nprint(arr21)\n</code></pre> <pre><code>out: [[19 22]\n      [43 50]]\n</code></pre> <p></p>"},{"location":"operadoreslogicos/","title":"Operadores L\u00f3gicos","text":""},{"location":"operadoreslogicos/#operadores-logicos-para-manipulacao-de-dados-com-pandas","title":"Operadores L\u00f3gicos para manipula\u00e7\u00e3o de dados com Pandas","text":"<p>Filtrando as vendas que ocorreram no segmento Home Office E na regi\u00e3o South</p> <pre><code>python\n\n# Nesse caso, as duas condi\u00e7\u00f5es precisam necessariamente ser verdadeiras para serem retornadas!\ndf3[ (df3.Segmento == 'Home Office') &amp; (df3.Regiao == 'South') ].head()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 182 CA-2014-158274 2014-11-19 RM-19675 Home Office United States South TEC-PH-10003273 Technology AT&amp;T TR1909W 503.9600 4.0 183 CA-2014-158274 2014-11-19 RM-19675 Home Office United States South TEC-PH-10004896 Technology Nokia Lumia 521 (T-Mobile) 149.9500 5.0 184 CA-2014-158274 2014-11-19 RM-19675 Home Office United States South TEC-AC-10002345 Technology HP Standard 104 key PS/2 Keyboard 29.0000 2.0 231 US-2017-100930 2017-04-07 CS-12400 Home Office United States South FUR-TA-10001705 Furniture Bush Advantage Collection Round Conference Table 233.8600 2.0 232 US-2017-100930 2017-04-07 CS-12400 Home Office United States South FUR-TA-10003473 Furniture Bretford Rectangular Conference Table Tops 620.6145 3.0 <p></p> <p>Filtrando as vendas que ocorreram no segmento Home Office OU na regi\u00e3o South</p> <p>Mas agora eu estou vendo os \u00faltimos valores, estou vendo o 'Tail', a cauda do DF.</p> <pre><code>python\n\n# Nesse caso, Apenas uma das condi\u00e7\u00f5es precisa ser verdadeira para o valor ser retornado!\ndf3[ (df3.Segmento == 'Home Office') | (df3.Regiao == 'South') ].tail()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 9979 US-2016-103674 2016-12-06 AP-10720 Home Office United States West OFF-BI-10002026 Office Supplies Ibico Recycled Linen-Style Covers 437.472 14.0 9980 US-2015-151435 2015-09-06 SW-20455 Consumer United States South FUR-TA-10001029 Furniture KI Adjustable-Height Table 85.980 1.0 9987 CA-2017-163629 2017-11-17 RA-19885 Corporate United States South TEC-AC-10001539 Technology Logitech G430 Surround Sound Gaming Headset wi... 79.990 1.0 9988 CA-2017-163629 2017-11-17 RA-19885 Corporate United States South TEC-PH-10004006 Technology Panasonic KX - TS880B Telephone 206.100 5.0 9989 CA-2014-110422 2014-01-21 TB-21400 Consumer United States South FUR-FU-10001889 Furniture Ultra Door Pull Handle 25.248 3.0 <p></p> <p>Filtrando as vendas que n\u00e3o ocorreram no segmento Home Office e n\u00e3o ocorreram na regi\u00e3o South</p> <p>Agora, estou vendo uma amostra de 5 valores, ou seja, 'Sample' de 5 valores de forma aleat\u00f3ria!!!</p> <pre><code>python\n\n# Nesse caso, as duas condi\u00e7\u00f5es precisam ser verdadeiras para o valor ser retornado!\ndf3[ (df3.Segmento != 'Home Office') &amp; (df3.Regiao != 'South') ].sample(5)\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 5215 CA-2016-145898 2016-09-26 CM-12445 Consumer United States West OFF-PA-10001667 Office Supplies Great White Multi-Use Recycled Paper (20Lb. an... 29.900 5.0 3150 CA-2015-147830 2015-12-15 NF-18385 Consumer United States East TEC-AC-10002049 Technology Plantronics Savi W720 Multi-Device Wireless He... 2025.360 6.0 9352 CA-2017-148411 2017-09-24 RO-19780 Consumer United States Central FUR-CH-10003973 Furniture GuestStacker Chair with Chrome Finish Legs 520.464 2.0 1985 CA-2014-164721 2014-11-25 LW-16825 Corporate United States West OFF-PA-10000575 Office Supplies Wirebound Message Books, Four 2 3/4 x 5 White ... 26.760 4.0 3675 CA-2017-154109 2017-11-06 ML-17410 Consumer United States East OFF-PA-10000157 Office Supplies Xerox 191 47.952 3.0 <p></p>"},{"location":"oqeengenharia/","title":"Fundamentos da Engenharia de Dados","text":""},{"location":"oqeengenharia/#o-que-e-engenharia-de-dados","title":"O que \u00e9 Engenharia de Dados?","text":"<p>O conjunto de processos de pegar um dado no processo bruto e entregar eles num estado utiliz\u00e1vel para os Analistas e Cientistas de Dados e Engenheiros de IA para algum tipo de an\u00e1lise.</p> <p>\u00c9 a tarefa complexa de pegar dados brutos e transformar eles em dados mais \u00fateis e acess\u00edveis para quem ir\u00e1 consumir. Raramente, os dados estar\u00e3o prontos para uso na fonte de captura deles, ent\u00e3o o papel do engenheiro se faz totalmente importante! Tamb\u00e9m envolve um trabalho de assegurar a qualidade daqueles dados tratados.</p> <p>Os dados s\u00e3o a parte mais importante do neg\u00f3cio, permitindo tomar a\u00e7\u00f5es, previs\u00f5es entre outras an\u00e1lises.</p> <p>A Engenharia de Dados \u00e9 a base para a Ci\u00eancia de Dados. Sem base, sem fundamentos, n\u00e3o conseguimos chegar na parte de maior valor, que s\u00e3o a obten\u00e7\u00e3o de analytics, Machine Learning e IA. Ent\u00e3o, a engenharia \u00e9 a parte mais importante desse processo.</p>"},{"location":"oqeengenharia/#diferencas-entre-engenheiro-de-dados-e-cientista-de-dados","title":"Diferen\u00e7as entre Engenheiro de Dados e Cientista de Dados","text":"<ul> <li> <p>O Cientista de Dados desenvolve modelos e an\u00e1lises usando matem\u00e1tica, estat\u00edsticas e programa\u00e7\u00e3o, prevendo comportamentos complexos e resolvendo problemas de neg\u00f3cio do mundo real.</p> </li> <li> <p>J\u00e1 o Engenheiro de Dados trabalha em um n\u00edvel mais baixo, construindo arquitetura de dados e pipelines para coletar, tratar e processar os dados, muitas vezes em aplica\u00e7\u00f5es de grande escala (Big Data).</p> </li> </ul> <p>Os cientistas est\u00e3o preocupados com o processo de an\u00e1lise dos dados e transform\u00e1-los em Machine Learning, enquanto os engenheiros est\u00e3o preocupados com o fluxo desses dados e a entrega deles para serem consumidos de uma forma melhor.</p>"},{"location":"oqeengenharia/#diferencas-entre-engenheiro-de-dados-e-arquiteto-de-dados","title":"Diferen\u00e7as entre Engenheiro de Dados e Arquiteto de Dados","text":"<p>Embora existam algumas similaridades entre os dois, cada um exerce um papel de import\u00e2ncia e fun\u00e7\u00f5es diferentes.</p> <ul> <li> <p>O Arquiteto de Dados leva em conta todas as fontes de dados relativas \u00e0s opera\u00e7\u00f5es de neg\u00f3cios e descreve um projeto para integrar, centralizar e manter os dados.</p> </li> <li> <p>O Engenheiro de Dados \u00e9 respons\u00e1vel por construir e testar arquiteturas de dados para a organiza\u00e7\u00e3o, a fim de facilitar a busca e recupera\u00e7\u00e3o de dados.</p> </li> </ul> <p>Os Arquitetos de Dados trabalham em estreita colabora\u00e7\u00e3o com os Engenheiros de Dados para criar uma arquitetura de dados s\u00f3lida.</p> <p>\u27a1\ufe0f Resumindo: O Arquiteto projeta e o Engenheiro executa.</p>"},{"location":"pandas/","title":"Pandas - Python","text":"<p>Pandas \u00e9 uma biblioteca de c\u00f3digo aberto do Python voltada para manipula\u00e7\u00e3o e an\u00e1lise de dados. Ele fornece estruturas de dados eficientes, como DataFrame e Series, que facilitam a organiza\u00e7\u00e3o, limpeza, transforma\u00e7\u00e3o e an\u00e1lise de grandes conjuntos de dados.</p> <p>Instalando a biblioteca pandas:</p> <pre><code>python\n\n!pip install --force-reinstall pandas==1.5.3\n</code></pre> <p></p> <p>Importando a biblioteca pandas para utiliza\u00e7\u00e3o:</p> <pre><code>python\n\nimport pandas as pd\n</code></pre> <p></p> <p>Para sabermos a vers\u00e3o utilizada:</p> <pre><code>python\n\npd.__version__\n# A vers\u00e3o utilizada foi a 1.5.3\n</code></pre> <pre><code>out: '1.5.3'\n</code></pre> <p></p>"},{"location":"pandassql/","title":"Utilizando o Pandas para trabalhar com Linguagem SQL","text":""},{"location":"pandassql/#aplicando-linguagem-sql-na-sintaxe-do-pandas-com-linguagem-python","title":"Aplicando Linguagem SQL na sintaxe do Pandas com Linguagem Python","text":"<p>Criando a conex\u00e3o com o banco de dados</p> <pre><code>python\n\n# Conectando no banco de dados\ncon = sqlite3.connect('cap12_dsa.db')\n</code></pre> <p>Abrindo um cursor </p> <pre><code>python\n\n# Abre um cursor para percorrer os dados no banco de dados\ncursor = con.cursor()\n</code></pre> <p></p> <p>A query abaixo retorna todas as linhas e todas as colunas da tabela</p> <p>Criando a instru\u00e7\u00e3o SQL</p> <pre><code>python\n\n# Cria uma instru\u00e7\u00e3o SQL\nquery = 'SELECT * FROM tb_vendas_dsa'\n</code></pre> <p>Executando a instru\u00e7\u00e3o</p> <pre><code>python\n\n# Executa a query no banco de dados\ncursor.execute(query)\n</code></pre> <pre><code>out:\n\n&lt;sqlite3.Cursor at 0x7f4679b00030&gt;\n</code></pre> <p></p> <p>Armazenando o resultado do cursor em uma vari\u00e1vel</p> <pre><code>python\n\n# Armazenando os dados do fetch em uma vari\u00e1vel\ndados = cursor.fetchall()\n</code></pre> <p>Visualizando os dados armazenados na vari\u00e1vel</p> <pre><code>python\n\n# Visualizando os dados\nprint(dados)\n</code></pre> <pre><code>out:\n\n[(1, 63, 'Produto_38', 154.03, 7, 92.42), (2, 49, 'Produto_8', 171.52, 5, 102.91), (3, 83, 'Produto_39', 28.97, 13, 17.38), (4, 37, 'Produto_2', 104.55, 4, 62.73), (5, 19, 'Produto_1', 77.21, 19, 46.33), (6, 87, 'Produto_36', 161.97, 13, 97.18), (7, 59, 'Produto_24', 101.17, 7, 60.7), (8, 48, 'Produto_31', 92.03, 9, 55.22), (9, 73, 'Produto_4', 116.57, 6, 69.94), (10, 98, 'Produto_45', 46.16, 4, 27.7), (11, 86, 'Produto_30', 135.55, 12, 81.33), (12, 89, 'Produto_45', 119.4, 11, 71.64), (13, 96, 'Produto_11', 96.63, 13, 57.98), (14, 29, 'Produto_50', 191.3, 10, 114.78), (15, 63, 'Produto_21', 191.28, 14, 114.77), (16, 30, 'Produto_22', 67.58, 17, 40.55), (17, 5, 'Produto_41', 33.22, 2, 19.93), (18, 97, 'Produto_33', 67.77, 12, 40.66), (19, 19, 'Produto_18', 160.68, 15, 96.41), (20, 7, 'Produto_17', 34.37, 13, 20.62), (21, 79, 'Produto_1', 161.33, 15, 96.8), (22, 36, 'Produto_45', 184.7, 11, 110.82), (23, 94, 'Produto_21', 11.57, 1, 6.94), (24, 51, 'Produto_16', 103.49, 4, 62.09), (25, 37, 'Produto_32', 29.49, 17, 17.69), (26, 78, 'Produto_5', 86.93, 6, 52.16), (27, 78, 'Produto_24', 118.14, 1, 70.88), (28, 87, 'Produto_6', 38.12, 4, 22.87), (29, 88, 'Produto_7', 145.76, 13, 87.46), (30, 31, 'Produto_1', 85.55, 19, 51.33), (31, 2, 'Produto_37', 43.93, 11, 26.36), (32, 80, 'Produto_34', 167.69, 1, 100.61), (33, 76, 'Produto_2', 36.25, 13, 21.75), (34, 89, 'Produto_6', 163.48, 9, 98.09), (35, 61, 'Produto_34', 26.27, 17, 15.76), (36, 20, 'Produto_24', 171.27, 9, 102.76), (37, 64, 'Produto_32', 194.29, 6, 116.57), (38, 12, 'Produto_45', 137.65, 15, 82.59), (39, 45, 'Produto_14', 150.07, 10, 90.04), (40, 32, 'Produto_32', 169.94, 19, 101.96), (41, 55, 'Produto_25', 32.62, 14, 19.57), (42, 37, 'Produto_1', 109.69, 1, 65.81), (43, 72, 'Produto_39', 199.78, 16, 119.87), (44, 76, 'Produto_50', 164.47, 17, 98.68), (45, 88, 'Produto_11', 68.66, 16, 41.2), (46, 50, 'Produto_8', 25.03, 13, 15.02), (47, 23, 'Produto_25', 123.85, 20, 74.31), (48, 91, 'Produto_28', 26.14, 6, 15.68), (49, 9, 'Produto_31', 46.27, 3, 27.76), (50, 18, 'Produto_6', 155.63, 12, 93.38), (51, 80, 'Produto_7', 56.15, 11, 33.69), (52, 59, 'Produto_13', 124.63, 6, 74.78), (53, 88, 'Produto_22', 92.03, 4, 55.22), (54, 62, 'Produto_50', 154.84, 5, 92.9), (55, 39, 'Produto_27', 10.31, 5, 6.19), (56, 90, 'Produto_16', 30.1, 5, 18.06), (57, 19, 'Produto_18', 170.95, 20, 102.57), (58, 75, 'Produto_16', 104.94, 8, 62.96), (59, 4, 'Produto_49', 119.61, 17, 71.77), (60, 24, 'Produto_5', 102.72, 11, 61.63), (61, 36, 'Produto_48', 84.9, 19, 50.94), (62, 85, 'Produto_28', 51.01, 3, 30.61), (63, 9, 'Produto_8', 31.4, 3, 18.84), (64, 34, 'Produto_49', 37.23, 9, 22.34), (65, 54, 'Produto_32', 60.6, 2, 36.36), (66, 23, 'Produto_20', 194.8, 8, 116.88), (67, 14, 'Produto_42', 90.96, 18, 54.58), (68, 44, 'Produto_10', 191.3, 10, 114.78), (69, 85, 'Produto_43', 24.79, 12, 14.87), (70, 49, 'Produto_15', 47.9, 11, 28.74), (71, 78, 'Produto_28', 45.76, 8, 27.46), (72, 30, 'Produto_30', 91.74, 4, 55.04), (73, 56, 'Produto_34', 142.24, 6, 85.34), (74, 6, 'Produto_5', 125.28, 13, 75.17), (75, 36, 'Produto_20', 36.46, 1, 21.88), (76, 43, 'Produto_26', 98.92, 12, 59.35), (77, 37, 'Produto_11', 116.83, 20, 70.1), (78, 24, 'Produto_50', 25.82, 10, 15.49), (79, 98, 'Produto_36', 138.52, 17, 83.11), (80, 3, 'Produto_25', 198.07, 6, 118.84), (81, 96, 'Produto_23', 15.36, 11, 9.22), (82, 52, 'Produto_44', 55.17, 8, 33.1), (83, 50, 'Produto_4', 62.59, 17, 37.55), (84, 45, 'Produto_17', 199.62, 14, 119.77), (85, 69, 'Produto_22', 66.9, 20, 40.14), (86, 20, 'Produto_45', 152.84, 7, 91.7), (87, 91, 'Produto_28', 47.58, 11, 28.55), (88, 21, 'Produto_47', 146.07, 18, 87.64), (89, 66, 'Produto_43', 37.75, 5, 22.65), (90, 86, 'Produto_35', 72.53, 2, 43.52), (91, 20, 'Produto_3', 164.55, 20, 98.73), (92, 2, 'Produto_22', 86.69, 11, 52.01), (93, 67, 'Produto_41', 72.9, 14, 43.74), (94, 4, 'Produto_16', 38.61, 13, 23.17), (95, 89, 'Produto_29', 110.76, 12, 66.46), (96, 57, 'Produto_46', 190.45, 10, 114.27), (97, 60, 'Produto_4', 180.91, 16, 108.55), (98, 92, 'Produto_9', 64.0, 17, 38.4), (99, 59, 'Produto_6', 73.64, 16, 44.18), (100, 5, 'Produto_18', 33.03, 20, 19.82), (101, 59, 'Produto_27', 169.36, 13, 101.62), (102, 87, 'Produto_49', 163.09, 11, 97.85), (103, 14, 'Produto_17', 63.25, 17, 37.95), (104, 21, 'Produto_17', 17.27, 5, 10.36), (105, 20, 'Produto_2', 12.68, 4, 7.61), (106, 60, 'Produto_3', 90.23, 20, 54.14), (107, 25, 'Produto_14', 38.42, 3, 23.05), (108, 85, 'Produto_47', 71.75, 18, 43.05), (109, 14, 'Produto_37', 197.77, 14, 118.66), (110, 47, 'Produto_8', 36.92, 11, 22.15), (111, 61, 'Produto_25', 21.03, 7, 12.62), (112, 31, 'Produto_24', 149.85, 18, 89.91), (113, 70, 'Produto_24', 81.9, 15, 49.14), (114, 27, 'Produto_20', 163.77, 5, 98.26), (115, 94, 'Produto_31', 143.05, 5, 85.83), (116, 67, 'Produto_6', 191.16, 2, 114.7), (117, 99, 'Produto_31', 194.36, 13, 116.62), (118, 76, 'Produto_46', 151.54, 19, 90.92), (119, 1, 'Produto_15', 13.12, 7, 7.87), (120, 54, 'Produto_24', 139.93, 18, 83.96), (121, 28, 'Produto_34', 57.6, 18, 34.56), (122, 13, 'Produto_19', 46.08, 6, 27.65), (123, 84, 'Produto_12', 197.18, 15, 118.31), (124, 67, 'Produto_20', 173.43, 4, 104.06), (125, 57, 'Produto_19', 32.09, 8, 19.25), (126, 78, 'Produto_7', 25.64, 12, 15.38), (127, 12, 'Produto_43', 36.3, 4, 21.78), (128, 63, 'Produto_4', 186.5, 5, 111.9), (129, 46, 'Produto_38', 36.09, 4, 21.65), (130, 71, 'Produto_23', 136.71, 19, 82.03), (131, 87, 'Produto_32', 98.13, 14, 58.88), (132, 20, 'Produto_2', 81.85, 13, 49.11), (133, 87, 'Produto_27', 96.42, 8, 57.85), (134, 59, 'Produto_19', 18.39, 4, 11.03), (135, 64, 'Produto_42', 172.8, 15, 103.68), (136, 98, 'Produto_30', 75.19, 1, 45.11), (137, 26, 'Produto_18', 147.01, 1, 88.21), (138, 57, 'Produto_12', 128.0, 17, 76.8), (139, 14, 'Produto_42', 151.81, 5, 91.09), (140, 50, 'Produto_10', 131.38, 13, 78.83), (141, 37, 'Produto_23', 59.52, 16, 35.71), (142, 10, 'Produto_46', 111.6, 19, 66.96), (143, 46, 'Produto_1', 31.64, 7, 18.98), (144, 44, 'Produto_18', 148.22, 15, 88.93), (145, 3, 'Produto_1', 92.3, 6, 55.38), (146, 47, 'Produto_33', 102.3, 13, 61.38), (147, 18, 'Produto_47', 133.77, 3, 80.26), (148, 81, 'Produto_26', 91.64, 20, 54.98), (149, 45, 'Produto_33', 52.55, 20, 31.53), (150, 57, 'Produto_1', 135.48, 1, 81.29), (151, 52, 'Produto_28', 15.77, 15, 9.46), (152, 74, 'Produto_41', 128.05, 18, 76.83), (153, 74, 'Produto_8', 106.01, 6, 63.61), (154, 15, 'Produto_26', 158.71, 16, 95.23), (155, 22, 'Produto_31', 64.36, 10, 38.62), (156, 52, 'Produto_19', 89.42, 8, 53.65), (157, 22, 'Produto_15', 199.24, 8, 119.54), (158, 97, 'Produto_3', 23.01, 6, 13.81), (159, 38, 'Produto_39', 39.84, 16, 23.9), (160, 32, 'Produto_15', 37.74, 19, 22.64), (161, 79, 'Produto_44', 155.45, 12, 93.27), (162, 56, 'Produto_8', 33.42, 15, 20.05), (163, 45, 'Produto_18', 151.89, 12, 91.13), (164, 65, 'Produto_11', 105.63, 19, 63.38), (165, 41, 'Produto_30', 17.76, 10, 10.66), (166, 7, 'Produto_8', 100.81, 19, 60.49), (167, 35, 'Produto_42', 28.34, 7, 17.0), (168, 24, 'Produto_34', 37.89, 17, 22.73), (169, 41, 'Produto_29', 27.34, 12, 16.4), (170, 84, 'Produto_13', 184.2, 5, 110.52), (171, 84, 'Produto_12', 24.93, 7, 14.96), (172, 47, 'Produto_4', 28.03, 12, 16.82), (173, 77, 'Produto_39', 188.52, 19, 113.11), (174, 58, 'Produto_8', 103.24, 17, 61.94), (175, 42, 'Produto_11', 88.9, 20, 53.34), (176, 38, 'Produto_31', 93.94, 2, 56.36), (177, 85, 'Produto_46', 21.13, 17, 12.68), (178, 13, 'Produto_7', 183.36, 8, 110.02), (179, 21, 'Produto_9', 166.11, 2, 99.67), (180, 9, 'Produto_32', 141.85, 18, 85.11), (181, 54, 'Produto_2', 163.44, 3, 98.06), (182, 96, 'Produto_26', 105.53, 15, 63.32), (183, 39, 'Produto_41', 136.76, 15, 82.06), (184, 68, 'Produto_10', 122.17, 19, 73.3), (185, 34, 'Produto_30', 139.21, 15, 83.53), (186, 76, 'Produto_48', 195.24, 14, 117.14), (187, 77, 'Produto_20', 117.97, 4, 70.78), (188, 96, 'Produto_21', 55.59, 8, 33.35), (189, 15, 'Produto_4', 57.91, 1, 34.75), (190, 67, 'Produto_11', 123.17, 19, 73.9), (191, 28, 'Produto_35', 33.25, 9, 19.95), (192, 69, 'Produto_21', 194.8, 12, 116.88), (193, 54, 'Produto_8', 185.3, 3, 111.18), (194, 57, 'Produto_23', 26.6, 1, 15.96), (195, 70, 'Produto_9', 72.53, 4, 43.52), (196, 74, 'Produto_42', 194.13, 12, 116.48), (197, 8, 'Produto_10', 178.27, 13, 106.96), (198, 15, 'Produto_14', 39.89, 9, 23.93), (199, 67, 'Produto_32', 27.57, 12, 16.54), (200, 10, 'Produto_3', 57.05, 6, 34.23), (201, 49, 'Produto_7', 196.13, 20, 117.68), (202, 69, 'Produto_28', 13.59, 18, 8.15), (203, 31, 'Produto_24', 179.2, 15, 107.52), (204, 11, 'Produto_15', 57.46, 6, 34.48), (205, 69, 'Produto_16', 135.56, 9, 81.34), (206, 53, 'Produto_25', 84.87, 18, 50.92), (207, 34, 'Produto_33', 176.65, 14, 105.99), (208, 67, 'Produto_40', 104.03, 11, 62.42), (209, 6, 'Produto_27', 57.23, 15, 34.34), (210, 53, 'Produto_16', 80.74, 2, 48.44), (211, 67, 'Produto_18', 135.98, 13, 81.59), (212, 49, 'Produto_32', 183.56, 12, 110.14), (213, 64, 'Produto_16', 10.76, 11, 6.46), (214, 95, 'Produto_49', 105.74, 19, 63.44), (215, 28, 'Produto_32', 143.99, 7, 86.39), (216, 12, 'Produto_50', 119.96, 15, 71.98), (217, 18, 'Produto_41', 98.14, 14, 58.88), (218, 93, 'Produto_34', 95.91, 2, 57.55), (219, 10, 'Produto_23', 170.09, 13, 102.05), (220, 66, 'Produto_1', 71.92, 15, 43.15), (221, 75, 'Produto_47', 20.84, 6, 12.5), (222, 10, 'Produto_6', 167.62, 17, 100.57), (223, 8, 'Produto_16', 76.0, 4, 45.6), (224, 77, 'Produto_33', 18.36, 10, 11.02), (225, 36, 'Produto_45', 15.91, 5, 9.55), (226, 34, 'Produto_7', 38.07, 4, 22.84), (227, 76, 'Produto_7', 146.11, 20, 87.67), (228, 74, 'Produto_16', 45.61, 4, 27.37), (229, 95, 'Produto_32', 36.61, 6, 21.97), (230, 100, 'Produto_26', 65.84, 3, 39.5), (231, 8, 'Produto_10', 30.18, 1, 18.11), (232, 2, 'Produto_15', 13.74, 3, 8.24), (233, 40, 'Produto_25', 156.4, 1, 93.84), (234, 74, 'Produto_39', 28.19, 9, 16.91), (235, 4, 'Produto_16', 86.21, 2, 51.73), (236, 27, 'Produto_20', 89.4, 14, 53.64), (237, 61, 'Produto_2', 43.56, 6, 26.14), (238, 54, 'Produto_3', 134.81, 7, 80.89), (239, 96, 'Produto_43', 194.33, 18, 116.6), (240, 62, 'Produto_31', 31.42, 3, 18.85), (241, 41, 'Produto_2', 131.85, 11, 79.11), (242, 10, 'Produto_8', 135.85, 20, 81.51), (243, 49, 'Produto_42', 134.6, 4, 80.76), (244, 5, 'Produto_5', 83.92, 5, 50.35), (245, 91, 'Produto_7', 178.77, 18, 107.26), (246, 21, 'Produto_24', 20.25, 12, 12.15), (247, 83, 'Produto_37', 198.96, 5, 119.38), (248, 77, 'Produto_28', 180.7, 7, 108.42), (249, 29, 'Produto_22', 106.38, 13, 63.83), (250, 36, 'Produto_25', 23.28, 10, 13.97), (251, 11, 'Produto_43', 146.55, 14, 87.93), (252, 34, 'Produto_7', 133.92, 18, 80.35), (253, 62, 'Produto_30', 72.61, 12, 43.57), (254, 46, 'Produto_11', 199.05, 1, 119.43), (255, 67, 'Produto_38', 130.09, 18, 78.05), (256, 40, 'Produto_48', 143.96, 8, 86.38), (257, 97, 'Produto_47', 42.45, 8, 25.47), (258, 89, 'Produto_32', 163.93, 19, 98.36), (259, 73, 'Produto_42', 169.11, 5, 101.47), (260, 100, 'Produto_1', 171.46, 6, 102.88), (261, 30, 'Produto_19', 151.51, 18, 90.91), (262, 60, 'Produto_50', 187.45, 10, 112.47), (263, 72, 'Produto_36', 139.34, 1, 83.6), (264, 34, 'Produto_28', 92.44, 4, 55.46), (265, 97, 'Produto_9', 153.97, 5, 92.38), (266, 58, 'Produto_31', 84.84, 18, 50.9), (267, 70, 'Produto_6', 59.07, 14, 35.44), (268, 73, 'Produto_45', 72.7, 1, 43.62), (269, 84, 'Produto_12', 91.54, 8, 54.92), (270, 81, 'Produto_39', 137.27, 8, 82.36), (271, 13, 'Produto_15', 91.25, 13, 54.75), (272, 17, 'Produto_44', 39.07, 5, 23.44), (273, 64, 'Produto_29', 198.8, 14, 119.28), (274, 70, 'Produto_13', 156.31, 2, 93.79), (275, 39, 'Produto_12', 129.06, 5, 77.44), (276, 62, 'Produto_40', 92.07, 9, 55.24), (277, 47, 'Produto_6', 23.37, 16, 14.02), (278, 72, 'Produto_4', 172.24, 11, 103.34), (279, 80, 'Produto_37', 145.13, 15, 87.08), (280, 42, 'Produto_31', 177.5, 1, 106.5), (281, 97, 'Produto_15', 183.21, 13, 109.93), (282, 22, 'Produto_34', 42.6, 16, 25.56), (283, 76, 'Produto_7', 54.93, 7, 32.96), (284, 5, 'Produto_40', 138.96, 1, 83.38), (285, 51, 'Produto_47', 88.6, 20, 53.16), (286, 8, 'Produto_4', 58.4, 5, 35.04), (287, 17, 'Produto_49', 116.06, 4, 69.64), (288, 55, 'Produto_29', 192.91, 4, 115.75), (289, 91, 'Produto_21', 159.18, 17, 95.51), (290, 38, 'Produto_32', 60.74, 11, 36.44), (291, 65, 'Produto_4', 105.22, 18, 63.13), (292, 21, 'Produto_39', 144.53, 15, 86.72), (293, 1, 'Produto_50', 133.05, 6, 79.83), (294, 62, 'Produto_36', 18.69, 16, 11.21), (295, 5, 'Produto_9', 54.07, 12, 32.44), (296, 66, 'Produto_40', 100.63, 18, 60.38), (297, 42, 'Produto_38', 86.18, 18, 51.71), (298, 99, 'Produto_16', 36.91, 4, 22.15), (299, 22, 'Produto_15', 92.67, 1, 55.6), (300, 45, 'Produto_28', 170.35, 10, 102.21), (301, 86, 'Produto_19', 182.79, 15, 109.67), (302, 16, 'Produto_30', 128.32, 14, 76.99), (303, 18, 'Produto_2', 111.71, 20, 67.03), (304, 99, 'Produto_50', 160.25, 9, 96.15), (305, 29, 'Produto_12', 85.76, 10, 51.46), (306, 19, 'Produto_30', 78.09, 9, 46.85), (307, 98, 'Produto_6', 150.28, 14, 90.17), (308, 50, 'Produto_30', 145.46, 10, 87.28), (309, 82, 'Produto_36', 141.76, 2, 85.06), (310, 28, 'Produto_15', 46.93, 14, 28.16), (311, 84, 'Produto_37', 106.29, 8, 63.77), (312, 56, 'Produto_24', 168.72, 14, 101.23), (313, 92, 'Produto_6', 36.89, 13, 22.13), (314, 20, 'Produto_1', 169.55, 18, 101.73), (315, 43, 'Produto_40', 142.55, 4, 85.53), (316, 50, 'Produto_29', 144.62, 15, 86.77), (317, 100, 'Produto_9', 31.4, 6, 18.84), (318, 97, 'Produto_1', 60.35, 20, 36.21), (319, 84, 'Produto_49', 177.64, 14, 106.58), (320, 88, 'Produto_27', 133.11, 6, 79.87), (321, 27, 'Produto_11', 162.31, 15, 97.39), (322, 82, 'Produto_30', 179.53, 6, 107.72), (323, 60, 'Produto_38', 66.98, 11, 40.19), (324, 64, 'Produto_31', 198.14, 15, 118.88), (325, 33, 'Produto_38', 90.19, 4, 54.11), (326, 51, 'Produto_33', 187.18, 4, 112.31), (327, 90, 'Produto_23', 197.39, 20, 118.43), (328, 3, 'Produto_39', 94.29, 13, 56.57), (329, 8, 'Produto_21', 22.06, 9, 13.24), (330, 10, 'Produto_30', 85.67, 3, 51.4), (331, 41, 'Produto_9', 171.23, 2, 102.74), (332, 52, 'Produto_25', 46.42, 14, 27.85), (333, 34, 'Produto_39', 66.0, 13, 39.6), (334, 53, 'Produto_36', 155.8, 2, 93.48), (335, 4, 'Produto_27', 109.8, 5, 65.88), (336, 72, 'Produto_41', 115.82, 1, 69.49), (337, 86, 'Produto_29', 143.29, 12, 85.97), (338, 63, 'Produto_13', 68.34, 12, 41.0), (339, 96, 'Produto_8', 20.54, 4, 12.32), (340, 86, 'Produto_20', 19.92, 6, 11.95), (341, 61, 'Produto_27', 150.62, 19, 90.37), (342, 23, 'Produto_40', 170.5, 2, 102.3), (343, 30, 'Produto_14', 142.28, 11, 85.37), (344, 15, 'Produto_30', 48.98, 11, 29.39), (345, 64, 'Produto_35', 89.72, 6, 53.83), (346, 56, 'Produto_9', 72.42, 5, 43.45), (347, 86, 'Produto_22', 175.04, 16, 105.02), (348, 25, 'Produto_22', 119.63, 20, 71.78), (349, 17, 'Produto_8', 63.6, 17, 38.16), (350, 61, 'Produto_16', 90.42, 1, 54.25), (351, 72, 'Produto_13', 20.88, 5, 12.53), (352, 28, 'Produto_12', 66.24, 6, 39.74), (353, 3, 'Produto_7', 47.0, 13, 28.2), (354, 97, 'Produto_26', 21.68, 4, 13.01), (355, 87, 'Produto_18', 166.68, 4, 100.01), (356, 26, 'Produto_7', 193.51, 17, 116.11), (357, 99, 'Produto_12', 112.02, 1, 67.21), (358, 82, 'Produto_17', 113.71, 12, 68.23), (359, 70, 'Produto_15', 65.39, 17, 39.23), (360, 74, 'Produto_27', 55.59, 18, 33.35), (361, 36, 'Produto_16', 84.18, 17, 50.51), (362, 39, 'Produto_38', 178.92, 8, 107.35), (363, 20, 'Produto_36', 136.61, 4, 81.97), (364, 41, 'Produto_22', 148.69, 20, 89.21), (365, 10, 'Produto_23', 11.65, 1, 6.99), (366, 60, 'Produto_8', 142.23, 16, 85.34), (367, 9, 'Produto_36', 184.02, 17, 110.41), (368, 21, 'Produto_3', 170.4, 4, 102.24), (369, 70, 'Produto_1', 88.27, 10, 52.96), (370, 1, 'Produto_10', 99.81, 12, 59.89), (371, 86, 'Produto_22', 122.09, 6, 73.25), (372, 32, 'Produto_22', 33.57, 18, 20.14), (373, 77, 'Produto_46', 159.33, 3, 95.6), (374, 36, 'Produto_25', 144.74, 8, 86.84), (375, 35, 'Produto_16', 74.49, 16, 44.69), (376, 4, 'Produto_3', 64.11, 8, 38.47), (377, 82, 'Produto_34', 112.96, 2, 67.78), (378, 20, 'Produto_16', 167.92, 13, 100.75), (379, 99, 'Produto_12', 21.49, 3, 12.89), (380, 94, 'Produto_36', 119.95, 4, 71.97), (381, 8, 'Produto_42', 182.49, 9, 109.49), (382, 61, 'Produto_7', 38.8, 20, 23.28), (383, 29, 'Produto_19', 198.77, 3, 119.26), (384, 25, 'Produto_19', 165.93, 13, 99.56), (385, 35, 'Produto_23', 138.9, 2, 83.34), (386, 23, 'Produto_26', 80.81, 1, 48.49), (387, 54, 'Produto_25', 25.68, 7, 15.41), (388, 93, 'Produto_14', 72.82, 20, 43.69), (389, 53, 'Produto_50', 175.41, 2, 105.25), (390, 94, 'Produto_42', 141.78, 11, 85.07), (391, 33, 'Produto_30', 161.44, 14, 96.86), (392, 56, 'Produto_3', 14.38, 8, 8.63), (393, 67, 'Produto_7', 74.3, 17, 44.58), (394, 50, 'Produto_26', 63.7, 13, 38.22), (395, 7, 'Produto_36', 162.04, 4, 97.22), (396, 61, 'Produto_38', 127.95, 19, 76.77), (397, 96, 'Produto_27', 52.5, 8, 31.5), (398, 27, 'Produto_9', 35.08, 11, 21.05), (399, 100, 'Produto_22', 162.06, 18, 97.24), (400, 31, 'Produto_16', 86.64, 19, 51.98), (401, 50, 'Produto_23', 52.41, 11, 31.45), (402, 65, 'Produto_20', 199.1, 7, 119.46), (403, 86, 'Produto_19', 174.39, 9, 104.63), (404, 85, 'Produto_41', 39.97, 19, 23.98), (405, 43, 'Produto_45', 71.63, 17, 42.98), (406, 89, 'Produto_22', 69.84, 16, 41.9), (407, 87, 'Produto_12', 29.86, 11, 17.92), (408, 47, 'Produto_10', 11.92, 16, 7.15), (409, 10, 'Produto_22', 194.26, 13, 116.56), (410, 17, 'Produto_4', 149.57, 4, 89.74), (411, 94, 'Produto_1', 121.02, 10, 72.61), (412, 30, 'Produto_14', 26.83, 2, 16.1), (413, 98, 'Produto_32', 10.03, 12, 6.02), (414, 67, 'Produto_29', 177.0, 6, 106.2), (415, 24, 'Produto_15', 104.37, 5, 62.62), (416, 54, 'Produto_29', 89.13, 17, 53.48), (417, 19, 'Produto_49', 68.44, 10, 41.06), (418, 68, 'Produto_25', 112.45, 2, 67.47), (419, 30, 'Produto_29', 58.53, 12, 35.12), (420, 61, 'Produto_36', 102.1, 20, 61.26), (421, 27, 'Produto_42', 83.37, 7, 50.02), (422, 8, 'Produto_18', 141.13, 15, 84.68), (423, 84, 'Produto_9', 13.04, 8, 7.82), (424, 100, 'Produto_24', 83.31, 18, 49.99), (425, 18, 'Produto_10', 15.95, 2, 9.57), (426, 3, 'Produto_34', 15.58, 1, 9.35), (427, 9, 'Produto_25', 61.58, 14, 36.95), (428, 61, 'Produto_10', 45.74, 4, 27.44), (429, 39, 'Produto_20', 48.31, 19, 28.99), (430, 99, 'Produto_46', 67.19, 3, 40.31), (431, 72, 'Produto_27', 134.35, 14, 80.61), (432, 83, 'Produto_44', 150.01, 3, 90.01), (433, 37, 'Produto_47', 177.32, 1, 106.39), (434, 87, 'Produto_3', 187.7, 1, 112.62), (435, 10, 'Produto_39', 107.65, 7, 64.59), (436, 43, 'Produto_43', 113.81, 13, 68.29), (437, 60, 'Produto_29', 98.56, 7, 59.14), (438, 85, 'Produto_50', 55.8, 16, 33.48), (439, 31, 'Produto_11', 148.32, 13, 88.99), (440, 59, 'Produto_22', 34.45, 12, 20.67), (441, 83, 'Produto_25', 168.0, 3, 100.8), (442, 91, 'Produto_42', 85.87, 20, 51.52), (443, 24, 'Produto_22', 63.03, 6, 37.82), (444, 20, 'Produto_6', 194.99, 15, 116.99), (445, 41, 'Produto_46', 52.96, 14, 31.78), (446, 10, 'Produto_4', 118.24, 15, 70.94), (447, 47, 'Produto_3', 111.78, 9, 67.07), (448, 72, 'Produto_24', 107.87, 8, 64.72), (449, 75, 'Produto_12', 181.36, 13, 108.82), (450, 91, 'Produto_11', 60.73, 8, 36.44), (451, 48, 'Produto_1', 18.44, 20, 11.06), (452, 12, 'Produto_28', 120.85, 8, 72.51), (453, 68, 'Produto_40', 167.29, 1, 100.37), (454, 60, 'Produto_30', 54.72, 12, 32.83), (455, 25, 'Produto_29', 110.63, 1, 66.38), (456, 22, 'Produto_12', 35.94, 18, 21.56), (457, 82, 'Produto_26', 134.73, 3, 80.84), (458, 98, 'Produto_4', 101.6, 17, 60.96), (459, 79, 'Produto_37', 95.52, 6, 57.31), (460, 93, 'Produto_40', 151.36, 12, 90.82), (461, 88, 'Produto_48', 154.02, 15, 92.41), (462, 54, 'Produto_17', 30.36, 7, 18.22), (463, 18, 'Produto_18', 40.89, 19, 24.53), (464, 7, 'Produto_4', 165.3, 18, 99.18), (465, 31, 'Produto_11', 16.06, 12, 9.64), (466, 50, 'Produto_37', 66.55, 20, 39.93), (467, 11, 'Produto_29', 186.75, 4, 112.05), (468, 57, 'Produto_30', 190.73, 5, 114.44), (469, 32, 'Produto_10', 40.43, 5, 24.26), (470, 56, 'Produto_49', 60.78, 11, 36.47), (471, 57, 'Produto_19', 147.38, 18, 88.43), (472, 79, 'Produto_23', 112.01, 19, 67.21), (473, 43, 'Produto_38', 154.74, 20, 92.84), (474, 76, 'Produto_19', 160.12, 5, 96.07), (475, 83, 'Produto_38', 92.49, 19, 55.49), (476, 84, 'Produto_3', 192.7, 9, 115.62), (477, 76, 'Produto_18', 19.22, 5, 11.53), (478, 97, 'Produto_44', 193.39, 8, 116.03), (479, 39, 'Produto_34', 162.33, 1, 97.4), (480, 98, 'Produto_22', 85.19, 9, 51.11), (481, 3, 'Produto_39', 33.03, 6, 19.82), (482, 33, 'Produto_33', 63.61, 13, 38.17), (483, 84, 'Produto_5', 170.45, 16, 102.27), (484, 9, 'Produto_30', 103.85, 20, 62.31), (485, 35, 'Produto_8', 198.35, 6, 119.01), (486, 16, 'Produto_7', 24.02, 16, 14.41), (487, 87, 'Produto_35', 47.53, 19, 28.52), (488, 75, 'Produto_29', 184.54, 10, 110.72), (489, 58, 'Produto_7', 62.24, 3, 37.34), (490, 70, 'Produto_26', 124.03, 7, 74.42), (491, 97, 'Produto_39', 150.94, 17, 90.56), (492, 82, 'Produto_18', 178.03, 18, 106.82), (493, 45, 'Produto_37', 157.59, 9, 94.55), (494, 65, 'Produto_17', 73.05, 14, 43.83), (495, 53, 'Produto_26', 97.69, 9, 58.61), (496, 27, 'Produto_12', 155.02, 1, 93.01), (497, 32, 'Produto_23', 71.04, 6, 42.62), (498, 80, 'Produto_1', 67.83, 13, 40.7), (499, 13, 'Produto_50', 187.89, 16, 112.73), (500, 46, 'Produto_21', 82.81, 11, 49.69)]\n</code></pre> <p></p> <p>Visualizando o tipo da vari\u00e1vel que armazenou o resultado do cursor</p> <pre><code>python\n\n\ntype(dados)\n</code></pre> <pre><code>out:\n\nlist\n</code></pre> <p>O fetch nos retorna uma lista de tuplas!</p> <p>Por\u00e9m, sabemos que manipular uma lista de tuplas \u00e9 mais complicado, temos que fazer mais filtros, mais trabalho de indexa\u00e7\u00e3o, etc. </p> <p>Ent\u00e3o \u00e9 pra isso que iremos usar o pandas!</p> <p> </p> <p>Criando um Dataframe do Pandas a partir da vari\u00e1vel dados</p> <pre><code>python\n\ndf = pd.DataFrame(dados, columns = ['ID_Pedido',\n                                    'ID_Cliente',\n                                    'Nome_Produto',\n                                    'Valor_Unitario',\n                                    'Unidades_Vendidas',\n                                    'Custo'])\n</code></pre> <p>Visualizando os dados</p> <pre><code>python\n\ndf.head()\n</code></pre> <p>out:</p> ID_Pedido ID_Cliente Nome_Produto Valor_Unitario Unidades_Vendidas Custo 0 1 63 Produto_38 154.03 7 92.42 1 2 49 Produto_8 171.52 5 102.91 2 3 83 Produto_39 28.97 13 17.38 3 4 37 Produto_2 104.55 4 62.73 4 5 19 Produto_1 77.21 19 46.33 <p>PRONTO! Agora temos um dataframe com os dados do banco de dados!</p> <p>J\u00e1 que temos um DF com os dados, n\u00e3o se faz mais necess\u00e1rio manter a conex\u00e3o e o cursor aberto, podemos fechar o mesmo</p> <p></p> <p>Fechando o cursor e encerrando a conex\u00e3o com o banco de dados</p> <pre><code>python\n\n# Fecha o cursor e encerra a conex\u00e3o\n\ncursor.close()\ncon.close()\n</code></pre> <p>J\u00e1 que temos o nosso Banco de Dados dentro de um DF do pandas, n\u00e3o se faz mais necess\u00e1rio manter a conex\u00e3o com o BD e o cursor abertos!</p> <p></p> <p>A query abaixo retorna a m\u00e9dia de unidades vendidas:</p> <pre><code>python\n\n# Calcula a m\u00e9dia de unidades vendidas\nmedia_unidades_vendidas = df['Unidades_Vendidas'].mean()\nprint(media_unidades_vendidas)\n</code></pre> <pre><code>out:\n\n10.506\n</code></pre> <p></p> <p>A query abaixo retorna a m\u00e9dia de unidades vendidas por produto:</p> <pre><code>python\n\nmedia_unidades_vendidas_por_produto = df.groupby('Nome_Produto')['Unidades_Vendidas'].mean()\n# Interessante ressaltar,\n# A coluna pela qual eu quero agrupar fica entre par\u00eanteses!\n# E a coluna que eu quero calcular a m\u00e9dia, vai entre colchetes!!!\n\nprint(media_unidades_vendidas_por_produto.head(10))\n</code></pre> <pre><code>out:\n\nNome_Produto\nProduto_1     12.000000\nProduto_10     9.500000\nProduto_11    14.181818\nProduto_12     8.846154\nProduto_13     6.000000\nProduto_14     9.166667\nProduto_15     9.750000\nProduto_16     8.250000\nProduto_17    11.714286\nProduto_18    13.083333\nName: Unidades_Vendidas, dtype: float64\n</code></pre> <p></p> <p>A query abaixo retorna a m\u00e9dia de unidades vendidas por produto se o valor unit\u00e1rio for maior que 199:</p> <pre><code>python\n\ndf[df['Valor_Unitario'] &gt; 199].groupby('Nome_Produto')['Unidades_Vendidas'].mean()\n</code></pre> <pre><code>out:\n\nNome_Produto\nProduto_11     1.0\nProduto_15     8.0\nProduto_17    14.0\nProduto_20     7.0\nProduto_39    16.0\nName: Unidades_Vendidas, dtype: float64\n</code></pre> <p></p> <p>A query abaixo retorna a m\u00e9dia de unidades vendidas por produto se o valor unit\u00e1rio for maior que 199 e somente se a m\u00e9dia de unidades vendidas for maior do que 10:</p> <pre><code>python\n\ndf[df['Valor_Unitario'] &gt; 199].groupby('Nome_Produto') \\\n                              .filter(lambda x: x['Unidades_Vendidas'].mean() &gt; 10) \\\n                              .groupby('Nome_Produto')['Unidades_Vendidas'].mean()\n</code></pre> <pre><code>out:\n\nNome_Produto\nProduto_17    14.0\nProduto_39    16.0\nName: Unidades_Vendidas, dtype: float64\n</code></pre> <p></p>"},{"location":"pipelinedados/","title":"\ud83d\ude80 Pipeline de Dados","text":""},{"location":"pipelinedados/#pipeline-de-dados","title":"Pipeline de Dados","text":""},{"location":"pipelinedados/#o-que-e-uma-pipeline-de-dados","title":"O que \u00e9 uma Pipeline de Dados?","text":"<p>\u00c9 um meio de mover dados do local de origem para um destino. Durante esse caminho, os dados s\u00e3o transformados e otimizados para chegar em um estado onde possam ser analisados e usados para desenvolver insights de neg\u00f3cios.</p> <p>Normalmente, o pipeline carrega os dados brutos em uma tabela de prepara\u00e7\u00e3o (Staging Area), onde ser\u00e3o transformados, limpos, etc. Ap\u00f3s esse processo, os dados s\u00e3o inseridos no destino.</p> <p>Resumidamente, uma pipeline de dados passa por tr\u00eas etapas principais: 1. Origem: Onde os dados s\u00e3o coletados. 2. Processamento: Onde os dados s\u00e3o transformados, alterados e preparados. 3. Destino: Onde os dados ser\u00e3o armazenados ou utilizados.</p>"},{"location":"pipelinedados/#pipeline-de-dados-vs-pipeline-etl","title":"Pipeline de Dados vs Pipeline ETL","text":"<p>Os sistemas de ETL s\u00e3o um tipo de pipeline, mas ETL \u00e9 apenas um subprocesso dentro de uma pipeline de dados. Antigamente, o processo era bem menos complexo, e o termo ETL era mais utilizado.  </p> <p>\u2705 Dizer que um Pipeline ETL \u00e9 um Pipeline de Dados \u00e9 correto. \u274c Mas dizer que um Pipeline de Dados \u00e9 apenas um Pipeline ETL est\u00e1 errado!  </p> <p>Um Pipeline de Dados realiza diversas outras fun\u00e7\u00f5es al\u00e9m do ETL.</p>"},{"location":"pipelinedados/#como-iniciar-um-projeto-de-pipeline-de-dados","title":"Como iniciar um projeto de Pipeline de Dados?","text":"<p>A melhor forma de come\u00e7ar \u00e9 pela compreens\u00e3o dos requisitos de neg\u00f3cio e o que se espera do uso dos dados no dia a dia.</p>"},{"location":"pipelinedados/#principal-funcao-do-engenheiro-de-dados","title":"Principal fun\u00e7\u00e3o do Engenheiro de Dados:","text":"<ul> <li>Auxiliar a empresa a alcan\u00e7ar seus requisitos de neg\u00f3cios.</li> <li>Ajudar a empresa a gerar lucro e reduzir custos.</li> </ul> <p>A arquitetura da Pipeline de Dados define como os componentes ir\u00e3o se comportar dentro da plataforma de dados.</p>"},{"location":"pipelinedados/#poc-prova-de-conceito","title":"PoC (Prova de Conceito)","text":"<p>\u00c9 um laborat\u00f3rio para simular cen\u00e1rios, validar requisitos de neg\u00f3cio, testar ferramentas e auxiliar em previs\u00f5es de custos.</p>"},{"location":"poo/","title":"POO (Programa\u00e7\u00e3o Orientada a Objeto) - Python","text":""},{"location":"poo/#classes","title":"Classes","text":"<p>Em POO (Programa\u00e7\u00e3o Orientada a Objeto), classe \u00e9 a estrutura que descreve um objeto, contendo valores, atributos e comportamentos. Cada objeto criado a partir da mesma classe ter\u00e1 os mesmos atributos e comportamentos.</p> <p>Para criar uma Classe, utiliza-se a palavra reservada <code>class</code>. \u00c9 uma conven\u00e7\u00e3o usar a primeira letra mai\u00fascula em cada palavra no nome da classe!</p> <pre><code>python\n\n# Criando a classe\nclass Livro():\n\n    # quando voc\u00ea ver o nome __init__, \u00e9 um m\u00e9todo Construtor, usado para inicializar os atributos de uma classe.\n    def __init__(self, titulo, isbn):\n        self.titulo = titulo\n        self.isbn = isbn\n        print(\"Seu construtor foi criado!\")\n\n    def imprime(self, titulo, isbn):\n        print(f\"Foi criado o livro {titulo} com ISBN {isbn}\")\n</code></pre> <p>Em Python, a palavra reservada <code>self</code> \u00e9 uma refer\u00eancia ao objeto atual da classe. Quando um objeto \u00e9 criado a partir de uma classe, <code>self</code> se refere a esse objeto espec\u00edfico.</p> <pre><code>python\n\n# Criando um objeto a partir da classe\nmeu_livro = Livro(\"Python para Iniciantes\", \"1234567890\")\nmeu_livro.imprime(meu_livro.titulo, meu_livro.isbn)\n</code></pre>"},{"location":"poo/#heranca","title":"Heran\u00e7a","text":"<p>A heran\u00e7a permite que uma classe herde atributos e m\u00e9todos de outra classe, promovendo a reutiliza\u00e7\u00e3o de c\u00f3digo.</p> <pre><code>python\n\n# Criando uma classe que herda de Livro\nclass Ebook(Livro):\n    def __init__(self, titulo, isbn, formato):\n        super().__init__(titulo, isbn)\n        self.formato = formato\n\n    def imprime_formato(self):\n        print(f\"O eBook est\u00e1 no formato {self.formato}\")\n</code></pre> <pre><code>python\n\n# Criando um objeto da classe Ebook\nmeu_ebook = Ebook(\"Python Avan\u00e7ado\", \"9876543210\", \"PDF\")\nmeu_ebook.imprime(meu_ebook.titulo, meu_ebook.isbn)\nmeu_ebook.imprime_formato()\n</code></pre>"},{"location":"poo/#polimorfismo","title":"Polimorfismo","text":"<p>\u00c9 o conceito que permite que objetos de diferentes classes possam ser tratados de forma uniforme. Significa que um objeto pode ser tratado como se fosse um objeto de uma superclasse, mesmo que ele seja de uma subclasse.</p> <pre><code>python\n\nclass Impressora():\n    def imprimir(self):\n        print(\"Imprimindo um documento gen\u00e9rico...\")\n\nclass ImpressoraLaser(Impressora):\n    def imprimir(self):\n        print(\"Imprimindo um documento com qualidade laser...\")\n\nclass ImpressoraJatoDeTinta(Impressora):\n    def imprimir(self):\n        print(\"Imprimindo um documento com qualidade jato de tinta...\")\n</code></pre> <pre><code>python\n\n# Criando objetos das classes\nimpressora1 = ImpressoraLaser()\nimpressora2 = ImpressoraJatoDeTinta()\n\n# Chamando o m\u00e9todo imprimir, cada classe tem um comportamento diferente\nimpressora1.imprimir()\nimpressora2.imprimir()\n</code></pre> <p>Com o polimorfismo, podemos usar o \u00fanico nome do m\u00e9todo, para que ele tenha comportamentos diferentes no objeto!</p>"},{"location":"pylab/","title":"PyLab","text":""},{"location":"pylab/#pylab","title":"Pylab","text":"<p>Criando gr\u00e1ficos customizados com PyLab</p> <p>Importando o pylab para utiliza\u00e7\u00e3o</p> <pre><code>python\n\nfrom pylab import *\n%matplotlib inline\n</code></pre>"},{"location":"pylab/#grafico-de-linha","title":"Gr\u00e1fico de Linha","text":"<p>Criando o gr\u00e1fico de linha</p> <pre><code>python\n\n\n# Dados\nx = linspace(0,5,10)\ny = x ** 2\n\n# Cria a figura, ou seja a \u00e1rea de plotagem\nfig = plt.figure()\n\n# Definindo a escala dos eixos\naxes= fig.add_axes([0,0,0.8,0.8])\n\n# Cria o plot\naxes.plot(x,y,'r')\n\n# Definindo labels e t\u00edtulo\naxes.set_xlabel('x')\naxes.set_ylabel('y')\naxes.set_title('Gr\u00e1fico de Linha')\n</code></pre> <p></p>"},{"location":"pylab/#grafico-de-linha-com-2-figuras","title":"Gr\u00e1fico de Linha com 2 figuras","text":"<p>Criando um gr\u00e1fico de linha com duas figuras na mesma \u00e1rea de plotagem</p> <pre><code>python\n\n# Gr\u00e1ficos de linha com 2 figuras\n\n# Dados\nx = linspace(0, 5, 10)\ny = x ** 2\n\n# Cria a figura\nfig = plt.figure()\n\n# Cria os eixos\naxes1 = fig.add_axes([0.1, 0.1, 0.8, 0.8])  # eixos da figura principal\naxes2 = fig.add_axes([0.2, 0.5, 0.4, 0.3])  # eixos da figura secund\u00e1ria\n\n# Figura principal, \u00e1rea de plotagem\naxes1.plot(x, y, 'r')\naxes1.set_xlabel('x')\naxes1.set_ylabel('y')\naxes1.set_title('Figura Principal')\n\n# Figura secund\u00e1ria, segunda \u00e1rea de plotagem\naxes2.plot(y, x, 'g')\naxes2.set_xlabel('y')\naxes2.set_ylabel('x')\naxes2.set_title('Figura Secund\u00e1ria')\n\n</code></pre> <p></p> <p></p>"},{"location":"pylab/#grafico-de-linha-em-paralelo","title":"Gr\u00e1fico de linha em Paralelo","text":"<p>Criando um gr\u00e1fico de linha com outro em paralelo na mesma \u00e1rea de plotagem</p> <pre><code>python\n\n# Dados\nx = linspace(0,5,10)\ny = x ** 2\n\n# Dividindo a \u00e1rea de plotagem em subplots\nfig, axes = plt.subplots(nrows = 1, ncols = 2)\n\n# Loop pelos eixos para criar cada plot\nfor ax in axes:\n    ax.plot(x,y,'r')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')    \n    ax.set_title('T\u00edtulo')\n\n# Ajusta o layout\nfig.tight_layout()\n</code></pre> <p></p> <p></p>"},{"location":"pylab/#grafico-de-linha-com-diferentes-escalas","title":"Gr\u00e1fico de Linha com diferentes escalas","text":"<p>Criando um gr\u00e1fico de linha com outro em paralelo com escala diferente</p> <pre><code>python\n\n# Dados\nx = linspace(0,5,10)\ny = x ** 2\n\n# Dividindo a \u00e1rea de plotagem em subplots\nfig, axes = plt.subplots(1,2,figsize=(10,4))\n\n#Criando o plot1\naxes[0].plot(x,x**2,x, exp(x))\naxes[0].set_title('Escala Padr\u00e3o')\n\n# Cria o plot2\naxes[1].plot(x,x**2,x, exp(x))\naxes[1].set_yscale(\"log\")\naxes[1].set_title(\"Escala Logaritmica (y)\");\n</code></pre> <p></p> <p></p>"},{"location":"pylab/#grafico-de-linha-com-grid","title":"Gr\u00e1fico de Linha com Grid","text":"<p>Criando um gr\u00e1fico de linha com o grid no fundo</p> <pre><code>python\n\n# Dados\nx = linspace(0,5,10)\ny = x ** 2\n\n# Criando os subplots\nfig, axes = plt.subplots(1,2, figsize = (10,3))\n\n# Grid padr\u00e3o\naxes[0].plot(x, x**2, x, x**3, lw=2)\naxes[0].grid(True)\n\n# Grid customizado\naxes[1].plot(x, x**2, x, x**3, lw=2)\naxes[1].grid(color = 'b', alpha=0.7, linestyle = 'dashed', linewidth = 0.8)\n</code></pre> <p></p> <p></p>"},{"location":"pylab/#diferentes-estilos-de-plot-na-mesma-area","title":"Diferentes Estilos de Plot na mesma \u00c1rea","text":"<p>Criando 4 gr\u00e1ficos de estilos diferentes na mesma \u00e1rea de plotagem</p> <pre><code>python\n\n# Dados\nxx = np.linspace(-0.75, 1., 100)\nn = np.array([0,1,2,3,4,5])\n\n# Subplots\nfig, axes = plt.subplots(1, 4, figsize=(12,3))\n\n# Plot 1\naxes[0].scatter(xx, xx + 0.25 * randn(len(xx)), color=\"black\")\naxes[0].set_title(\"scatter\")\n\n# Plot 2\naxes[1].step(n, n ** 2, lw=2, color=\"blue\")\naxes[1].set_title(\"step\")\n\n# Plot 3\naxes[2].bar(n, n ** 2, align=\"center\", width=0.5, alpha=0.5, color=\"magenta\")\naxes[2].set_title(\"bar\")\n\n# Plot 4\naxes[3].fill_between(x, x ** 2, x ** 3, alpha=0.5, color=\"green\")\naxes[3].set_title(\"fill_between\")\n\n</code></pre> <p></p> <p></p>"},{"location":"pylab/#histogramas","title":"Histogramas","text":"<p>Criando dois histogramas na mesma \u00e1rea de plotagem</p> <pre><code>python\n\n# Dados\nn = np.random.randn(100000)\n\n# cria os subplots\nfig, axes = plt.subplots(1,2,figsize=(12,4))\n\n# Plot 1\naxes[0].hist(n)\naxes[0].set_title('Histograma Padr\u00e3o')\naxes[0].set_xlim((min(n), max(n)))\n\n# Plot 2\naxes[1].hist(n, cumulative = True, bins = 50)\naxes[1].set_title('Histograma Cumulativo')\naxes[1].set_xlim((min(n), max(n)))\n</code></pre> <p></p> <p></p>"},{"location":"pylab/#graficos-3d","title":"Gr\u00e1ficos 3D","text":"<p>Importando o pacote toolkits Axes3D para utiliza\u00e7\u00e3o</p> <pre><code>python\n\nfrom mpl_toolkits.mplot3d.axes3d import Axes3D\n</code></pre> <p>Criando a fun\u00e7\u00e3o para mapear as cores e os dados</p> <pre><code>python\n\n# Dados \nalpha = 0.7\nphi_ext = 2 * np.pi * 0.5\n\n# Fun\u00e7\u00e3o para um mapa de cores\ndef ColorMap(phi_m, phi_p):\n    return (+ alpha - 2 * np.cos(phi_p)*cos(phi_m) - alpha * np.cos(phi_ext - 2*phi_p))\n\n# Mais dados\nphi_m = np.linspace(0,2*np.pi,100)\nphi_p = np.linspace(0,2*np.pi,100)\nX,Y = np.meshgrid(phi_p,phi_m)\nZ = ColorMap(X,Y).T\n</code></pre> <p>Criando a figura de plotagem</p> <pre><code>python\n\n# Cria a figura\nfig = plt.figure(figsize=(14,6))\n\n# Adiciona o subplot 1 com proje\u00e7\u00e3o 3d\nax = fig.add_subplot(1, 2, 1, projection='3d')\np = ax.plot_surface(X, Y, Z, rstride=4, cstride=4, linewidth=0)\n\n# Adiciona o subplot 2 com proje\u00e7\u00e3o 3d\nax = fig.add_subplot(1, 2, 2, projection='3d')\np = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n\n# Cria a barra de cores como legenda\ncb = fig.colorbar(p, shrink=0.5)\n\n</code></pre> <p></p> <p>\u00c9 um gr\u00e1fico visualmente atrativo, por\u00e9m, para a an\u00e1lise do mesmo se torna um pouco mais dif\u00edcil. Mas para uma apresenta\u00e7\u00e3o dos dados, \u00e9 uma boa op\u00e7\u00e3o, como foi dito, TUDO DEPENDE! </p> <p></p>"},{"location":"python/","title":"Conceitos B\u00e1sicos - Python","text":""},{"location":"python/#primeiros-exemplo","title":"Primeiros Exemplo","text":"<pre><code>print('Primeiro programa')\n1 \\\n  + 2\n\n# o Python ele se importa com quebras de linha, diferentes de outras linguagens!!!\n</code></pre>"},{"location":"python/#tipos","title":"TIPOS","text":""},{"location":"python/#tipos-basicos","title":"Tipos B\u00e1sicos!","text":"<pre><code>python\n\nprint(True)   # Booleano (Verdadeiro)\nprint(False)  # Booleano (Falso)\nprint(1.2 + 1)  # N\u00famero decimal (float)\nprint(\"Texto\")  # String\nprint('Voc\u00ea \u00e9 ' + 3 * 'muito ' + 'legal!')  # Concatena\u00e7\u00e3o de strings\n</code></pre> <p>\ud83d\udccc Python \u00e9 uma linguagem dinamicamente tipada, ou seja, voc\u00ea n\u00e3o precisa declarar o tipo de uma vari\u00e1vel explicitamente.</p> <p> </p>"},{"location":"python/#variaveis","title":"V\u00e1riaveis","text":"<p>As vari\u00e1veis armazenam valores e podem ser utilizadas ao longo do c\u00f3digo:</p> <pre><code>python\n\na = 10\nb = 5.2\n\nprint(a + b)  # Soma dos valores\n</code></pre> <pre><code>out: 15.2\n</code></pre>"},{"location":"python/#listas","title":"Listas","text":"<p>Listas s\u00e3o cole\u00e7\u00f5es ordenadas de elementos.</p> <pre><code>python\n\nnumeros = [1, 2, 3, 4, 5]\nprint(numeros[0])  # Primeiro elemento -&gt; 1\n</code></pre> <pre><code>out: 1\n</code></pre> <p>Manipula\u00e7\u00e3o de listas: As listas s\u00e3o cole\u00e7\u00f5es ordenadas e mut\u00e1veis.</p> <pre><code>numeros.append(6)  # Adiciona o n\u00famero 6\nprint(numeros)\n</code></pre> <pre><code>out: [1,2,3,4,5,6]\n</code></pre> <p> </p>"},{"location":"python/#dicionarios","title":"Dicion\u00e1rios","text":"<p>Dicion\u00e1rios armazenam pares de chave-valor.</p> <pre><code>python\n\npessoa = {\"nome\": \"Jo\u00e3o\", \"idade\": 20}\nprint(pessoa[\"nome\"])  \n</code></pre> <pre><code>out: [\"Jo\u00e3o\"]\n</code></pre> <p></p> <p>Adicionando novos valores:</p> <pre><code>python\n\npessoa[\"cidade\"] = \"S\u00e3o Paulo\"\nprint(pessoa)\n</code></pre> <pre><code>out: {\"nome\": \"Jo\u00e3o\", \"idade\": 20, \"cidade\": \"S\u00e3o Paulo\"}\n</code></pre> <p> </p>"},{"location":"python/#conjuntos","title":"Conjuntos","text":"<p>Conjuntos armazenam elementos \u00fanicos e n\u00e3o ordenados.</p> <pre><code>python\n\nnumeros = {1, 2, 3, 4, 5}\nnumeros.add(6)\nprint(numeros)\n</code></pre> <pre><code>out: {1,2,3,4,5,6}\n</code></pre> <p> </p>"},{"location":"python/#tuplas","title":"Tuplas","text":"<p>Tuplas s\u00e3o similares a listas, mas s\u00e3o imut\u00e1veis.</p> <pre><code>python\n\ntupla = (1, 2, 3)\nprint(tupla[0])  \n</code></pre> <pre><code>out: 1\n</code></pre> <p> </p>"},{"location":"python/#comentarios","title":"Coment\u00e1rios","text":"<p>Coment\u00e1rios s\u00e3o trechos de c\u00f3digo ignorados pelo interpretador.</p> <pre><code>python\n\n# Vari\u00e1veis de exemplo\nsalario = 3450.45\ndespesas = 2456\n\n\"\"\"\nEste \u00e9 um coment\u00e1rio de v\u00e1rias linhas.\nAqui podemos documentar o c\u00f3digo de forma mais detalhada.\n\"\"\"\n\nprint(\"Chegou ao Fim!\")\n</code></pre> <p> </p>"},{"location":"python/#operadores","title":"OPERADORES","text":""},{"location":"python/#operadores-aritmeticos","title":"Operadores Aritm\u00e9ticos","text":"<pre><code>python\n\nprint(2 + 3)  # Soma\nprint(4 - 7)  # Subtra\u00e7\u00e3o\nprint(2 * 5.3)  # Multiplica\u00e7\u00e3o\nprint(9.4 / 3)  # Divis\u00e3o\nprint(9.4 // 3)  # Divis\u00e3o inteira\nprint(2 ** 8)  # Exponencia\u00e7\u00e3o\nprint(10 % 8)  # M\u00f3dulo (resto da divis\u00e3o)\n</code></pre>"},{"location":"python/#operadores-de-comparacao","title":"Operadores de Compara\u00e7\u00e3o","text":"<p>Os operadores de compara\u00e7\u00e3o s\u00e3o usados para comparar valores.</p> <pre><code>python\n\nx = 10\ny = 5\n\nprint(x == y)  # Igual a -&gt; False\nprint(x != y)  # Diferente de -&gt; True\nprint(x &gt; y)   # Maior que -&gt; True\nprint(x &lt; y)   # Menor que -&gt; False\nprint(x &gt;= y)  # Maior ou igual a -&gt; True\nprint(x &lt;= y)  # Menor ou igual a -&gt; False\n</code></pre> <p> </p>"},{"location":"python/#operadores-logicos","title":"Operadores L\u00f3gicos","text":"<p>Os operadores l\u00f3gicos s\u00e3o usados para combinar express\u00f5es booleanas.</p> <pre><code>python\n\ncond1 = True\ncond2 = False\n\nprint(cond1 and cond2)  # AND -&gt; False\nprint(cond1 or cond2)   # OR -&gt; True\nprint(not cond1)        # NOT -&gt; False\n</code></pre> <p> </p>"},{"location":"python/#controle","title":"CONTROLE","text":""},{"location":"python/#estruturas-condicionais","title":"Estruturas Condicionais","text":"<p>As estruturas condicionais permitem que o c\u00f3digo tome decis\u00f5es com base em condi\u00e7\u00f5es.</p> <pre><code>python\n\nidade = 18\nif idade &gt;= 18:\n    print(\"Maior de idade\")\nelse:\n    print(\"Menor de idade\")\n</code></pre> <pre><code>out: \"Maior de idade\"\n</code></pre> <p></p> <p>Tamb\u00e9m podemos usar a estrutura <code>elif</code> para m\u00faltiplas condi\u00e7\u00f5es:</p> <pre><code>python\n\nnota = 7\nif nota &gt;= 9:\n    print(\"Excelente\")\nelif nota &gt;= 7:\n    print(\"Bom\")\nelif nota &gt;= 5:\n    print(\"Regular\")\nelse:\n    print(\"Reprovado\")\n</code></pre> <pre><code>out: \"Bom\"\n</code></pre> <p> </p>"},{"location":"python/#estruturas-de-repeticao","title":"Estruturas de Repeti\u00e7\u00e3o","text":"<p>As estruturas de repeti\u00e7\u00e3o permitem executar um bloco de c\u00f3digo v\u00e1rias vezes.</p>"},{"location":"python/#loop-for","title":"Loop <code>for</code>","text":"<pre><code>for i in range(5):  # Itera de 0 a 4\n    print(i)\n</code></pre> <p>Percorrendo listas:</p> <pre><code>nomes = [\"Alpha\", \"Bravo\", \"Charlie\"]\nfor nome in nomes:\n    print(nome)\n</code></pre> <pre><code>out:    Alpha\n        Bravo\n        Charlie \n</code></pre> <p> </p>"},{"location":"python/#loop-while","title":"Loop <code>while</code>","text":"<pre><code>python\n\ncontador = 0\nwhile contador &lt; 5:\n    print(contador)\n    contador += 1\n</code></pre> <pre><code>out: 0\n     1\n     2\n     3\n     4\n</code></pre>"},{"location":"python/#funcoes","title":"Fun\u00e7\u00f5es","text":"<p>As fun\u00e7\u00f5es permitem reutilizar blocos de c\u00f3digo.</p> <pre><code>python\n\ndef saudacao(nome):\n    return f\"Ol\u00e1, {nome}!\"\n\nprint(saudacao(\"Camila\"))\n</code></pre> <pre><code>out: \"Ol\u00e1, Camila!\"\n</code></pre> <p></p> <p>Fun\u00e7\u00e3o com m\u00faltiplos argumentos:</p> <pre><code>python\n\ndef soma(a, b):\n    return a + b\n\nprint(soma(3, 4)) \n</code></pre> <pre><code>out: 7\n</code></pre> <p> </p>"},{"location":"python/#manipulacao-de-strings","title":"Manipula\u00e7\u00e3o de Strings","text":"<pre><code>python\n\ntexto = \"Python \u00e9 incr\u00edvel!\"\nprint(texto.upper())  # Transforma em mai\u00fasculas\nprint(texto.lower())  # Transforma em min\u00fasculas\nprint(texto.split())  # Divide a string em uma lista\n</code></pre> <pre><code>out: PYTHON \u00c9 INCR\u00cdVEL!\n     python \u00e9 incr\u00edvel!\n     ['Python', '\u00e9', 'incr\u00edvel!']\n</code></pre>"},{"location":"python/#entrada-e-saida","title":"Entrada e Sa\u00edda","text":"<pre><code>python\n\nnome = input(\"Digite seu nome: \")\nprint(f\"Bem-vindo, {nome}!\")\n</code></pre>"},{"location":"python/#tratamento-de-excecoes","title":"Tratamento de Exce\u00e7\u00f5es","text":"<pre><code>python\n\ntry:\n    resultado = 10 / 0\nexcept ZeroDivisionError:\n    print(\"Erro: divis\u00e3o por zero n\u00e3o permitida\")\n</code></pre> <pre><code>out: \"Erro: divis\u00e3o por zero n\u00e3o permitida\"\n</code></pre>"},{"location":"pythonsql/","title":"Utilizando Python para trabalhar com Linguagem SQL","text":""},{"location":"pythonsql/#utilizando-python-para-trabalhar-com-linguagem-sql","title":"Utilizando Python para trabalhar com linguagem SQL","text":"<pre><code>python\n\n# Importando  os pacotes necess\u00e1rios\nimport sqlite3\nprint(\"A vers\u00e3o do sqlite \u00e9: \" + sqlite3.sqlite_version)\n\nimport pandas as pd\nprint(\"A vers\u00e3o do pandas \u00e9: \" + pd.__version__)\n</code></pre> <pre><code>out:\n\nA vers\u00e3o do sqlite \u00e9: 3.39.3\nA vers\u00e3o do pandas \u00e9: 1.5.3\n</code></pre>"},{"location":"pythonsql/#conectando-no-banco-de-dados-com-linguagem-python","title":"Conectando no Banco de Dados com Linguagem Python","text":"<p>Conectando no Banco de Dados</p> <pre><code>python\n\n# Conecta no banco de dados:\ncon = sqlite3.connect('cap12_dsa.db')\n</code></pre> <p></p> <p>Abrindo um cursor que ir\u00e1 percorrer os dados e as linhas no banco de dados</p> <pre><code>python\n\ncursor = con.cursor()\n</code></pre> <p></p> <p>APENAS criando a query de consulta</p> <pre><code>python\n\n# Query (consulta) SQL para extrair os nomes das colunas no banco de dados\n# APENAS cria a query.\nsql_query  = \"\"\"SELECT name FROM sqlite_master WHERE type = 'table';\"\"\"\n</code></pre> <p></p> <p>Executado a query de consulta</p> <pre><code>python\n\n# Executa a query SQL\ncursor.execute(sql_query)\n</code></pre> <pre><code>out:\n&lt;sqlite3.Cursor at 0x7f467af08b90&gt;\n</code></pre> <p>Ele nos retorna o objeto do cursor!</p> <p></p> <p>Agora, vamos visualizar o que resultado da consulta, verificando o que o cursor encontrou dentro do BD</p> <pre><code>python\n\n# Visualiza o resultado da consulta\nprint(cursor.fetchall())\n</code></pre> <pre><code>out:\n[('tb_vendas_dsa',)]\n</code></pre> <p></p> <p>Criando uma instru\u00e7\u00e3o SQL</p> <pre><code>python\n\n# Cria uma instru\u00e7\u00e3o SQL\nquery1 = 'SELECT * FROM tb_vendas_dsa'\n</code></pre> <p>Executando a query no BD</p> <pre><code>python\n\n# Executa a query no banco de dados\ncursor.execute(query1)\n</code></pre> <pre><code>out:\n&lt;sqlite3.Cursor at 0x7f467af08b90&gt;\n</code></pre> <p></p> <p>Criando um List Comprehension afim de visualizarmos os nomes das colunas</p> <pre><code>python\n\n# List Comprehension para visualizar os nomes das colunas\nnomes_colunas = [description[0] for description in cursor.description]\n</code></pre> <p></p> <p>Visualizando o nome das colunas</p> <pre><code>python\n\n# Visualizando os nomes das colunas\nprint(nomes_colunas)\n\n# Os nomes das colunas s\u00e3o METADADOS, pois \u00e9 um dado sobre o dado, \n# E ent\u00e3o dentro da tabela est\u00e3o os dados\n</code></pre> <pre><code>out:\n['ID_Pedido', 'ID_Cliente', 'Nome_Produto', 'Valor_Unitario', 'Unidades_Vendidas', 'Custo']\n</code></pre> <p>Recebendo os dados da execu\u00e7\u00e3o da query e armazenando em uma vari\u00e1vel</p> <pre><code>python\n\n# Retorna os dados da execu\u00e7\u00e3o da query\ndados = cursor.fetchall()\n</code></pre> <p>Visualizando os dados da vari\u00e1vel:</p> <pre><code>python\n\ndados\n</code></pre> <pre><code>out:\n\n[(1, 63, 'Produto_38', 154.03, 7, 92.42),\n (2, 49, 'Produto_8', 171.52, 5, 102.91),\n (3, 83, 'Produto_39', 28.97, 13, 17.38),\n (4, 37, 'Produto_2', 104.55, 4, 62.73),\n (5, 19, 'Produto_1', 77.21, 19, 46.33),\n (6, 87, 'Produto_36', 161.97, 13, 97.18),\n (7, 59, 'Produto_24', 101.17, 7, 60.7),\n (8, 48, 'Produto_31', 92.03, 9, 55.22),\n (9, 73, 'Produto_4', 116.57, 6, 69.94),\n (10, 98, 'Produto_45', 46.16, 4, 27.7),\n (11, 86, 'Produto_30', 135.55, 12, 81.33),\n (12, 89, 'Produto_45', 119.4, 11, 71.64),\n (13, 96, 'Produto_11', 96.63, 13, 57.98),\n (14, 29, 'Produto_50', 191.3, 10, 114.78),\n (15, 63, 'Produto_21', 191.28, 14, 114.77),\n (16, 30, 'Produto_22', 67.58, 17, 40.55),\n (17, 5, 'Produto_41', 33.22, 2, 19.93),\n (18, 97, 'Produto_33', 67.77, 12, 40.66),\n (19, 19, 'Produto_18', 160.68, 15, 96.41),\n (20, 7, 'Produto_17', 34.37, 13, 20.62),\n\n [...]\n\n (490, 70, 'Produto_26', 124.03, 7, 74.42),\n (491, 97, 'Produto_39', 150.94, 17, 90.56),\n (492, 82, 'Produto_18', 178.03, 18, 106.82),\n (493, 45, 'Produto_37', 157.59, 9, 94.55),\n (494, 65, 'Produto_17', 73.05, 14, 43.83),\n (495, 53, 'Produto_26', 97.69, 9, 58.61),\n (496, 27, 'Produto_12', 155.02, 1, 93.01),\n (497, 32, 'Produto_23', 71.04, 6, 42.62),\n (498, 80, 'Produto_1', 67.83, 13, 40.7),\n (499, 13, 'Produto_50', 187.89, 16, 112.73),\n (500, 46, 'Produto_21', 82.81, 11, 49.69)]\n</code></pre> <p></p>"},{"location":"pythonsql/#aplicando-linguagem-sql-direto-no-banco-de-dados-com-linguagem-python","title":"Aplicando Linguagem SQL direto no Banco de Dados com linguagem Python","text":"<p>A query abaixo retorna a m\u00e9dia de unidades vendidas por produto:</p> <p>Criando uma instru\u00e7\u00e3o SQL</p> <pre><code>python\n\n# Cria uma instru\u00e7\u00e3o para calcular a m\u00e9dia de unidades vendidas por produto\nquery3 = 'SELECT Nome_Produto as \"Nome do Produto\", AVG(Unidades_Vendidas) as \"M\u00e9dia das Unidades\" FROM tb_vendas_dsa GROUP BY Nome_Produto'\n</code></pre> <p></p> <p>Executando a instru\u00e7\u00e3o no BD</p> <pre><code>python\n\n# Executa a query no banco de dados\ncursor.execute(query3)\n</code></pre> <pre><code>out:\n\n&lt;sqlite3.Cursor at 0x7f467af08b90&gt;\n</code></pre> <p></p> <p>Visualizando o resultado da query</p> <pre><code>python\n\n# Visualizando os dados\ncursor.fetchall()\n</code></pre> <pre><code>out:\n\n[('Produto_1', 12.0),\n ('Produto_10', 9.5),\n ('Produto_11', 14.181818181818182),\n ('Produto_12', 8.846153846153847),\n ('Produto_13', 6.0),\n ('Produto_14', 9.166666666666666),\n ('Produto_15', 9.75),\n ('Produto_16', 8.25),\n ('Produto_17', 11.714285714285714),\n ('Produto_18', 13.083333333333334),\n ('Produto_19', 9.727272727272727),\n ('Produto_2', 9.25),\n ('Produto_20', 7.555555555555555),\n ('Produto_21', 10.285714285714286),\n ('Produto_22', 13.6875),\n ('Produto_23', 10.818181818181818),\n ('Produto_24', 12.272727272727273),\n ('Produto_25', 9.538461538461538),\n ('Produto_26', 9.363636363636363),\n ('Produto_27', 11.1),\n ('Produto_28', 9.0),\n ('Produto_29', 9.692307692307692),\n ('Produto_3', 8.909090909090908),\n ('Produto_30', 9.875),\n ('Produto_31', 7.9),\n ('Produto_32', 11.923076923076923),\n ('Produto_33', 12.285714285714286),\n ('Produto_34', 8.1),\n ('Produto_35', 9.0),\n ('Produto_36', 9.090909090909092),\n ('Produto_37', 11.0),\n ('Produto_38', 12.8),\n ('Produto_39', 12.666666666666666),\n ('Produto_4', 11.153846153846153),\n ('Produto_40', 7.25),\n ('Produto_41', 11.857142857142858),\n ('Produto_42', 10.272727272727273),\n ('Produto_43', 11.0),\n ('Produto_44', 7.2),\n ('Produto_45', 8.875),\n ('Produto_46', 12.142857142857142),\n ('Produto_47', 10.571428571428571),\n ('Produto_48', 14.0),\n ('Produto_49', 11.875),\n ('Produto_5', 10.2),\n ('Produto_50', 10.545454545454545),\n ('Produto_6', 12.0),\n ('Produto_7', 13.5625),\n ('Produto_8', 11.071428571428571),\n ('Produto_9', 7.2)]\n</code></pre> <p> </p> <p>A query abaixo retorna a m\u00e9dia de unidades vendidas por produto se o valor unit\u00e1rip for maior que 199:</p> <p>Criando a instru\u00e7\u00e3o SQL</p> <pre><code>python\n\n# Cria uma instru\u00e7\u00e3o para calcular a m\u00e9dia de unidades vendidas por produto,\n# quando o valor unit\u00e1rio for maior que 199\n\nquery4 = \"\"\"\n            SELECT Nome_Produto, AVG(Unidades_Vendidas)\n            FROM tb_vendas_dsa\n            WHERE Valor_Unitario &gt; 199\n            GROUP BY Nome_Produto\n        \"\"\"\n</code></pre> <p>Execuntando a instru\u00e7\u00e3o</p> <pre><code>python\n\n# Executando a query no banco de dados\ncursor.execute(query4)\n</code></pre> <pre><code>out:\n\n&lt;sqlite3.Cursor at 0x7f467af08b90&gt;\n</code></pre> <p></p> <p>Recebendo resultado do cursor</p> <pre><code>python\n\ncursor.fetchall()\n</code></pre> <pre><code>out:\n\n[('Produto_11', 1.0),\n ('Produto_15', 8.0),\n ('Produto_17', 14.0),\n ('Produto_20', 7.0),\n ('Produto_39', 16.0)]\n</code></pre> <p> </p> <p>A query abaixo retorna a m\u00e9dia de unidades vendidas por produto se o valor unit\u00e1rio for maior que 199 e somente se a m\u00e9dia de unidades vendidas for maior que 10:</p> <p>FORMA ERRADA</p> <pre><code>python\n\n# Cria uma instru\u00e7\u00e3o para calcular a m\u00e9dia de unidades vendidas por produto,\n# quando o valor unit\u00e1rio for maior que 199\n\nquery5 = \"\"\"\n            SELECT Nome_Produto, AVG(Unidades_Vendidas)\n            FROM tb_vendas_dsa\n            WHERE Valor_Unitario &gt; 199 and AVG(Unidades_Vendidas) &gt; 10\n            GROUP BY Nome_Produto\n        \"\"\"\n</code></pre> <p>Essa instru\u00e7\u00e3o dar\u00e1 erro!!!</p> <p>ERROR: misuse or agregate: AVG()</p> <p>ERRO: USO INDEVIDO DA AGREGA\u00c7\u00c3O AVG()</p> <p> </p> <p>A instru\u00e7\u00e3o SQL exige uma ordem de execu\u00e7\u00e3o das cl\u00e1usulas:</p> <p>PRIMEIRO, ser\u00e1 executado o FROM, para buscar os dados da tabela,</p> <p>EM SEGUIDA, ir\u00e1 ser aplicado o WHERE, para buscar as colunas fazendo o agrupamento,</p> <p></p> <p>Ent\u00e3o, em qual momento ele ir\u00e1 aplicar o AVG? </p> <p>SOMENTE DEPOIS do GROUP BY!!!</p> <p>Na linha \"AVG(Unidades_Vendidas) &gt; 10\" estamos tendando usar a m\u00e9dia antes do group by,</p> <p>ele ainda n\u00e3o fez o agrupamento, ent\u00e3o n\u00e3o podemos usar!</p> <p></p> <p>FORMA CORRETA:</p> <pre><code>python\n\n# Cria uma instru\u00e7\u00e3o para calcular a m\u00e9dia de unidades vendidas por produto,\n# quando o valor unit\u00e1rio for maior que 199\n\nquery5 = \"\"\"\n            SELECT Nome_Produto, AVG(Unidades_Vendidas)\n            FROM tb_vendas_dsa\n            WHERE Valor_Unitario &gt; 199 \n            GROUP BY Nome_Produto\n            HAVING AVG(Unidades_Vendidas) &gt; 10\n        \"\"\"\n</code></pre> <p>FORMA CORRETA</p> <p>A utiliza\u00e7\u00e3o da cl\u00e1usula HAVING \u00e9 usada para usar o filtro DEPOIS do GROUP BY</p> <p> </p> <p>Executando a query</p> <pre><code>python\n\ncursor.execute(query5)\n</code></pre> <pre><code>out:\n\n&lt;sqlite3.Cursor at 0x7f467af08b90&gt;\n</code></pre> <p></p> <p>Visualizando os dados do cursor</p> <pre><code>python\n\ncursor.fetchall()\n</code></pre> <pre><code>out:\n\n[('Produto_17', 14.0), ('Produto_39', 16.0)]\n</code></pre> <p></p> <p>Fechando o cursor e encerrando a conex\u00e3o com o banco de dados</p> <pre><code>python\n\n# Fecha o cursor e encerra a conex\u00e3o\ncursor.close()\ncon.close()\n</code></pre> <p>IMPORTANTE!!!</p> <p>Sempre lembrar de encerrar a conex\u00e3o depois de terminar a utiliza\u00e7\u00e3o do banco de dados!</p> <p>Deixar de fechar o cursor e a conex\u00e3o com o DB pode ocasionar diversos problemas, como:</p> <ul> <li>Ocasionar falhas de seguran\u00e7a,</li> <li>Consumir Recursos de forma desnecess\u00e1ria,</li> <li>Travar a conex\u00e3o com o banco de dados.</li> </ul> <p> </p>"},{"location":"querypandas/","title":"Query's em DataFrame Pandas","text":""},{"location":"querypandas/#query-consulta-de-dados-no-dataframe-do-pandas","title":"Query (Consulta) de Dados no DataFrame do Pandas","text":"<p>Com o pandas, podemos criar dataframes que s\u00e3o essencialmente tabelas. Como tamb\u00e9m podemos fazer consultas, ou simplesmente queries. Utilizando o m\u00e9todo query():</p> <p>Fazendo uma consulta a partir de uma coluna espec\u00edfica</p> <pre><code>python\n\ndf3.Valor_Venda.describe()\n</code></pre> <pre><code>out:\n\n    count     9994.000000\n    mean       229.858001\n    std        623.245101\n    min          0.444000\n    25%         17.280000\n    50%         54.490000\n    75%        209.940000\n    max      22638.480000\n    Name: Valor_Venda, dtype: float64\n</code></pre> <p></p> <p>Criando um novo DF com o intervalo de vendas entre 229 e 10000</p> <pre><code>python\n\ndf2 = df3.query('229 &lt; Valor_Venda &lt; 10000')\n</code></pre> <p>Utilizando o describe no novo DF criado</p> <pre><code>python\n\ndf2.Valor_Venda.describe()\n</code></pre> <pre><code>out:\n\n    count    2357.000000\n    mean      766.679142\n    std       856.315136\n    min       229.544000\n    25%       323.100000\n    50%       490.320000\n    75%       859.200000\n    max      9892.740000\n    Name: Valor_Venda, dtype: float64\n</code></pre> <p>Podemos ver que a m\u00e9dia de valores \u00e9 766 </p> <p>Criando um novo dataframe com os valores acima da m\u00e9dia!</p> <pre><code>python\n\ndf4 = df3.query('Valor_Venda &gt; 766')\n</code></pre> <p>Visualizando o DF criado</p> <pre><code>python\n\ndf4.head()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 7 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West TEC-PH-10002275 Technology Mitel 5320 IP Phone VoIP phone 907.1520 6.0 10 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West FUR-TA-10001539 Furniture Chromcraft Rectangular Conference Tables 1706.1840 9.0 11 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West TEC-PH-10002033 Technology Konftel 250 Conference\u00a0phone\u00a0- Charcoal black 911.4240 4.0 24 CA-2015-106320 2015-09-25 EB-13870 Consumer United States West FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 1044.6300 3.0 <p></p>"},{"location":"replacedf/","title":"Replace de Strings","text":""},{"location":"replacedf/#replace-de-strings-em-df","title":"Replace de Strings em DF","text":"<p>Substituimos os caracteres CG por AX na coluna 'ID_CLiente'</p> <pre><code>python\n\ndf3['ID_Cliente'] = df3['ID_Cliente'].str.replace('CG', 'AX')\n</code></pre> <p>Visualizando as altera\u00e7\u00f5es</p> <pre><code>python\n\ndf3.head()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade Ano 0 CA-2016-152156 2016-11-08 AX-12520 Consumer United States South FUR-BO-10001798 Furniture Bush Somerset Collection Bookcase 261.9600 3.0 2016 1 CA-2016-152156 2016-11-08 AX-12520 Consumer United States South FUR-CH-10000454 Furniture Hon Deluxe Fabric Upholstered Stacking Chairs,... 731.9400 3.0 2016 2 CA-2016-138688 2016-06-12 DV-13045 Corporate United States West OFF-LA-10000240 Office Supplies Self-Adhesive Address Labels for Typewriters b... 14.6200 2.0 2016 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 2015 4 US-2015-108966 2015-10-11 SO-20335 Consumer United States South OFF-ST-10000760 Office Supplies Eldon Fold 'N Roll Cart System 22.3680 2.0 2015 <p></p>"},{"location":"seaborn/","title":"SeaBorn","text":""},{"location":"seaborn/#seaborn","title":"Seaborn","text":"<p>O Seaborn \u00e9 uma biblioteca de visualiza\u00e7\u00e3o de dados para Python baseada no Matplotlib e integrada ao Pandas. Ele facilita a cria\u00e7\u00e3o de gr\u00e1ficos estat\u00edsticos bonitos e informativos com poucas linhas de c\u00f3digo.</p> <p>URL: https://seaborn.pydata.org/</p> <p>Instalando os pacotes necess\u00e1rios</p> <pre><code>python\n\n!pip install seaborn==0.12.2\n</code></pre> <p>Importando as bibliotecas que ser\u00e3o utilizadas</p> <pre><code>python\n\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mat\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sea\n%matplotlib inline\n</code></pre> <p></p>"},{"location":"seaborn/#criando-os-graficos-com-seaborn","title":"Criando os gr\u00e1ficos com Seaborn","text":"<p>Carregando um dos datasets que vem com o seaborn para estudo</p> <pre><code>python\n\ndados = sea.load_dataset(\"tips\")\n\ndados.head()\n</code></pre> <p>out:</p> total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 <p></p> <p>Criando gr\u00e1ficos bivariados e univariados na mesma \u00e1rea de plotagem</p> <pre><code>python\n\n# O m\u00e9todo joinplot cria plot de 2 vari\u00e1veis com gr\u00e1ficos bivariados e univariados\nsea.jointplot(data = dados, x = 'total_bill', y = 'tip', kind = 'reg')\n</code></pre> <p></p> <p>Ele retorna um gr\u00e1fico que diz: Os pontos s\u00e3o a rela\u00e7\u00e3o entre valor da conta e gorjeta, a linha azul diagonal \u00e9 o modelo de regress\u00e3o, a \u00e1rea sombreada entre ela \u00e9 o intervalo sendo a margem de erro, temos o histograma da vari\u00e1vel total_bill e o gr\u00e1fico de densidade! Tanta coisa em apenas 1 gr\u00e1fico! </p> <p>Criando um gr\u00e1fico que cont\u00e9m modelos de regress\u00e3o</p> <pre><code>python\n\n# O m\u00e9todo lmplot() cria a plot com dados e modelos de regress\u00e3o\nsea.lmplot(data = dados, x = 'total_bill', y = 'tip', col = 'smoker')\n</code></pre> <p></p> <p>Temos a linha de regress\u00e3o entre total_bill e tip, isso quando, o cliente era fumante ou n\u00e3o (Smoker True ou False)</p> <p></p> <p>Vamos criar um DF vazio</p> <pre><code>python\n\n# Criando um dataframe vazio\ndf = pd.DataFrame()\n</code></pre> <p>Vamos preencher o DF com valores vazios</p> <pre><code>python\n\n# Alimentando o dataframe com valores aleat\u00f3rios\ndf['idade'] = random.sample(range(20, 100), 30)\ndf['peso'] = random.sample(range(55, 150), 30)\n</code></pre> <p>Verificando a forma do  DF</p> <pre><code>python\n\ndf.shape\n</code></pre> <pre><code>out: (30, 2)\n</code></pre> <p></p> <p>Visualizando os dados com pandas:</p> <pre><code>python\n\ndf.head()\n</code></pre> <p>out:</p> idade peso 0 24 58 1 81 68 2 86 133 3 48 69 4 58 97 <p></p>"},{"location":"seaborn/#grafico-de-dispersao","title":"Gr\u00e1fico de dispers\u00e3o","text":"<p>Criando um gr\u00e1fico de dispers\u00e3o com um modelo de regress\u00e3o na mesma \u00e1rea de plotagem</p> <pre><code>python\n\n# O fit_reg nos retorna um modelo de regress\u00e3o\nsea.lmplot(data = df, x = 'idade', y = 'peso', fit_reg = True)\n</code></pre> <p></p> <p></p>"},{"location":"seaborn/#grafico-de-densidade","title":"Gr\u00e1fico de densidade","text":"<p>Criando um gr\u00e1fico de densidade</p> <pre><code>python\n\n# Gr\u00e1fico de densidade\nsea.kdeplot(df.idade)\n</code></pre> <p></p> <p></p>"},{"location":"seaborn/#grafico-de-densidade-com-histograma","title":"Gr\u00e1fico de densidade com histograma","text":"<p>Criando um gr\u00e1fico de densidade com um histograma na mesma \u00e1rea de plotagem</p> <pre><code>python\n\nsea.distplot(df.peso)\n</code></pre> <p></p> <p></p>"},{"location":"seaborn/#histograma","title":"Histograma","text":"<p>Criando um histograma com um rugplot incluso</p> <pre><code>python\n\n# Utilizando o histograma do matplotlib, com o rugplot do seaborn\nplt.hist(df.idade, alpha = .3)\nsea.rugplot(df.idade)\n</code></pre> <p></p> <p></p>"},{"location":"seaborn/#boxplot","title":"BoxPlot","text":"<p>Criando um gr\u00e1fico boxplot</p> <pre><code>python\n\nsea.boxplot(df.idade, color = 'm')\n</code></pre> <p></p>"},{"location":"seaborn/#violin-plot","title":"Violin Plot","text":"<p>Criando um gr\u00e1fico Violin</p> <pre><code>python\n\nsea.violinplot(df.peso, color = 'cyan')\n</code></pre> <p></p>"},{"location":"seaborn/#cluster-map","title":"Cluster Map","text":"<p>Criando um Gr\u00e1fico Cluster Map</p> <pre><code>python\n\nsea.clustermap(df)\n</code></pre> <p></p> <p></p>"},{"location":"sintaxepysql/","title":"Sintaxe SQL X Sintaxe Pandas","text":""},{"location":"sintaxepysql/#sintaxe-sql-x-sintaxe-pandas","title":"Sintaxe SQL X Sintaxe Pandas","text":"<p>As duas instru\u00e7\u00f5es abaixo retornam o mesmo resultado:</p>"},{"location":"sintaxepysql/#sintaxe-sql","title":"Sintaxe SQL","text":"<pre><code>python\n\n# Sintaxe SQL\n\nquery5 = \"\"\"SELECT Nome_Produto, AVG(Unidades_Vendidas)\n            FROM tb_vendas_dsa\n            WHERE Valor_Unitario &gt; 199\n            GROUP BY Nome_Produto\n            HAVING AVG(Unidades_Vendidas) &gt; 10\"\"\"\n</code></pre> <p>Observando essa sintaxe:</p> <p>PROS: </p> <ul> <li>Com essa mesma sintaxe, podemos utilizar em QUALQUER SGBD! (MYSql, Oracle, Microsoft SQL SERVER, DB2, SQLite, entre outros), ou seja, aprendemos uma vez e podemos aplicar em qualquer SGBD.</li> <li>Linguagem mais simples e mais clara, n\u00e3o sendo t\u00e3o necess\u00e1rio conhecimento de programa\u00e7\u00e3o pr\u00e9vio.</li> </ul> <p>CONTRAS:</p> <ul> <li>Menos flex\u00edvel em termos de programa\u00e7\u00e3o, ficando restrito \u00e0 apenas comandos SQL.</li> <li>Por ser necess\u00e1rio estar conectado \u00e0 um banco de dados, a performance \u00e9 afetada em quest\u00f5es de conex\u00e3o de rede, em larga escala, isso tem um impacto significativo.</li> </ul> <p></p>"},{"location":"sintaxepysql/#sintaxe-pandas","title":"Sintaxe Pandas","text":"<pre><code>python\n\n# Sintaxe Pandas\n\ndf[df['Valor_Unitario'] &gt; 199].groupby('Nome_Produto') \\\n    .filter(lambda x: x['Unidades_Vendidas'].mean() &gt; 10) \\\n    .groupby('Nome_Produto')['Unidades_Vendidas'].mean()\n</code></pre> <pre><code>out:\n\nNome_Produto\nProduto_17    14.0\nProduto_39    16.0\nName: Unidades_Vendidas, dtype: float64\n</code></pre> <p>Observando essa sintaxe: PROS:</p> <ul> <li>Isso que fazemos com pandas \u00e9 programa\u00e7\u00e3o, ou seja, podemos aplicar esse c\u00f3digo em um loop, podemos usar vari\u00e1veis, ent\u00e3o, em termos de flexibilidade de programa\u00e7\u00e3o, o pandas \u00e9 mais din\u00e2mico.</li> <li>Melhor performance, pois os dados j\u00e1 estar\u00e3o no ambiente com o pandas!</li> </ul> <p>CONTRAS: </p> <ul> <li>A sintaxe do Pandas, \u00e9 exclusivamente e somente, do pandas! Temos que utilizar a linguagem python, transformar em um DF do pandas para utilizar ela.</li> <li>Linguagem mais complexa exigindo um certo conhecimento de programa\u00e7\u00e3o.</li> </ul> <p></p> <p>CONCLUS\u00c3O:</p> <p>N\u00c3O EXISTE FERRAMENTA PERFEITA! \u00c9 nosso dever analisar e ver qual \u00e9 a melhor ferramenta para cada caso em espec\u00edfico, TUDO DEPENDE!!</p>"},{"location":"sistemasdistribuidos/","title":"\ud83c\udf0d Sistemas Distribu\u00eddos","text":""},{"location":"sistemasdistribuidos/#sistemas-distribuidos","title":"Sistemas Distribu\u00eddos","text":"<p>Uma rede de computadores que trabalham juntos para armazenamento e processamento.</p>"},{"location":"sistemasdistribuidos/#processamento-distribuido","title":"Processamento Distribu\u00eddo","text":"<p>\ud83d\udccc Vantagens: - Escalabilidade - Confiabilidade - Melhor desempenho - Flexibilidade  </p> <p>\ud83d\udccc Desvantagens: - Complexidade - Sobrecarga de comunica\u00e7\u00e3o - Riscos de seguran\u00e7a - Custo elevado  </p>"},{"location":"sobre/","title":"Sobre mim","text":""},{"location":"sobre/#quem-eu-sou","title":"Quem eu sou?","text":"<p>Me chamo Jo\u00e3o Vitor Luz Campos, tenho 20 anos, moro na capital de S\u00e3o Paulo, sou estudante de an\u00e1lise e desenvolvimento de sistemas, atualmente trabalho na Stefanini Consulting dentro da c\u00e9lula do Banco do Brasil, atuando na \u00e1rea de Business Intelligence &amp; Analytics. </p> <p></p>"},{"location":"sobre/#hobbies","title":"\ud83c\udfaf Hobbies","text":""},{"location":"sobre/#corrida","title":"\ud83c\udfc3\u200d\u2642\ufe0f Corrida","text":"<p>Meu gosto pela corrida come\u00e7ou durante o servi\u00e7o militar e se tornou um h\u00e1bito essencial na minha rotina. J\u00e1 completei uma meia maratona e sigo focado em evoluir ainda mais nesse esporte!</p> <p></p>"},{"location":"sobre/#bateria","title":"\ud83e\udd41 Bateria","text":"<p>A m\u00fasica sempre fez parte da minha vida! Estudei bateria por 6 anos e, hoje, costumo tocar em casamentos, missas na minha par\u00f3quia matriz e diversos eventos. Al\u00e9m de ser um hobby, \u00e9 uma forma incr\u00edvel de express\u00e3o e conex\u00e3o com as pessoas.</p> <p></p>"},{"location":"sobre/#minha-trajetoria-profissional","title":"Minha Trajet\u00f3ria Profissional","text":"<p>Bom, antes de atuar na \u00e1rea de tecnologia, j\u00e1 tive experi\u00eancias em outros setores do mercado.</p>"},{"location":"sobre/#primeiras-experiencias-profissionais","title":"\ud83d\udccc Primeiras experi\u00eancias profissionais","text":"<p>Aos 15 anos, tive meu primeiro emprego com registro em carteira, trabalhando como auxiliar gr\u00e1fico. Apesar do cargo, atuei em diversos setores da empresa, desde a cria\u00e7\u00e3o de artes at\u00e9 a produ\u00e7\u00e3o do produto final. Essa experi\u00eancia ampliou minha capacidade de resolver problemas e me permitiu enxergar diferentes etapas do processo produtivo.  </p> <p>Aos 16 anos, ingressei em uma empresa de Consultoria de Planos de Sa\u00fade, atuando no setor administrativo. Essa consultoria possu\u00eda um p\u00f3s-venda diferenciado, e eu era respons\u00e1vel pela parte de documenta\u00e7\u00e3o do cliente. Al\u00e9m disso, tive a oportunidade de atuar tamb\u00e9m na \u00e1rea de vendas. Diferente do convencional, n\u00e3o \u00e9ramos n\u00f3s que entr\u00e1vamos em contato com os clientes, mas sim eles que vinham at\u00e9 n\u00f3s. Essa din\u00e2mica me permitiu aprimorar meu entendimento sobre neg\u00f3cios, compreender as dores dos clientes e oferecer a melhor solu\u00e7\u00e3o para cada caso.  </p>"},{"location":"sobre/#empreendedorismo-e-gestao","title":"\ud83d\udccc Empreendedorismo e gest\u00e3o","text":"<p>Aos 18 anos, tornei-me s\u00f3cio do meu pai em uma empresa de m\u00f3veis planejados, onde atuei em diversas frentes, incluindo:  </p> <ul> <li>Vendas e or\u00e7amentos </li> <li>Planos de corte e projetos </li> <li>Confec\u00e7\u00e3o do produto final </li> </ul> <p>Essa experi\u00eancia foi essencial para expandir meu mindset, melhorar minha comunica\u00e7\u00e3o e aprimorar minha capacidade de resolver problemas. Al\u00e9m disso, compreendi a import\u00e2ncia de gerar confian\u00e7a no cliente e garantir a continuidade do neg\u00f3cio.  </p>"},{"location":"sobre/#servico-militar-e-experiencia-com-seguranca","title":"\ud83d\udccc Servi\u00e7o militar e experi\u00eancia com seguran\u00e7a","text":"<p>Aos 19 anos, fui chamado para servir nas For\u00e7as Armadas, no 8\u00ba Batalh\u00e3o de Pol\u00edcia do Ex\u00e9rcito, como Soldado Policial do Ex\u00e9rcito. Durante esse per\u00edodo, atuei em miss\u00f5es de seguran\u00e7a de autoridades, patrulhamento ostensivo e garantia da lei e da ordem.  </p> <p>Dentro do batalh\u00e3o, tive a honra de atuar na 3\u00aa Se\u00e7\u00e3o de Pol\u00edcia do Ex\u00e9rcito, respons\u00e1vel pelo planejamento de miss\u00f5es. Algumas das minhas principais experi\u00eancias foram:  </p> <p>\u2705 Miss\u00f5es de seguran\u00e7a para o Presidente da Rep\u00fablica (Luiz In\u00e1cio Lula da Silva) \u2705 Atua\u00e7\u00e3o como Agente de Seguran\u00e7a Aproximada do Vice-Presidente (Geraldo Alckmin) \u2705 Apoio \u00e0s enchentes no Rio Grande do Sul </p> <p>Ao final do servi\u00e7o, fui reconhecido com uma refer\u00eancia elogiosa publicada no Boletim Militar e um certificado de Honra ao M\u00e9rito por minha boa conduta e servi\u00e7os prestados. Essa experi\u00eancia expandiu meu repert\u00f3rio, fortaleceu minha resili\u00eancia e me desenvolveu em diversas \u00e1reas de compet\u00eancia.  </p>"},{"location":"sobre/#foco-na-tecnologia-e-carreira-atual","title":"\ud83d\udccc Foco na tecnologia e carreira atual","text":"<p>Aos 20 anos, ap\u00f3s deixar as For\u00e7as Armadas, decidi focar na \u00e1rea de tecnologia, iniciando minha faculdade em An\u00e1lise e Desenvolvimento de Sistemas. Esse curso me permite atuar no desenvolvimento de projetos que resolvem problemas reais de neg\u00f3cios por meio da programa\u00e7\u00e3o.  </p> <p>Atualmente, trabalho na Stefanini, na \u00e1rea de BI &amp; Analytics, dentro da c\u00e9lula do Banco do Brasil. Nessa fun\u00e7\u00e3o, estou expandindo meus conhecimentos em:  </p> <p>\ud83d\udcca Big Data \ud83d\udccc Fundamentos de Engenharia de Dados \ud83d\udee0\ufe0f An\u00e1lise de dados e intelig\u00eancia de neg\u00f3cios </p> <p>Essa trajet\u00f3ria me permitiu construir uma base s\u00f3lida e desenvolver habilidades essenciais para atuar no mercado de tecnologia! \ud83d\ude80  </p>"},{"location":"splitstrings/","title":"Slipt de Strings","text":""},{"location":"splitstrings/#split-de-strings-em-dfs","title":"Split de Strings em DFs","text":"<p>Filtrando uma coluna espec\u00edfica do DF</p> <pre><code>python\n\ndf3['ID_Pedido'].head()\n</code></pre> <pre><code>out:\n\n    0    CA-2016-152156\n    1    CA-2016-152156\n    2    CA-2016-138688\n    3    US-2015-108966\n    4    US-2015-108966\n    Name: ID_Pedido, dtype: object\n</code></pre> <p>Essa coluna de Id, nos retorna: o Pa\u00eds, o ano e o ID do pedido, vamos extrair esses dados e gravar em uma nova coluna!</p> <p></p> <p>Separando os dados dos ID com base no '-'</p> <pre><code>python\n\ndf3['ID_Pedido'].str.split('-')\n</code></pre> <pre><code>out:\n\n    0       [CA, 2016, 152156]\n    1       [CA, 2016, 152156]\n    2       [CA, 2016, 138688]\n    3       [US, 2015, 108966]\n    4       [US, 2015, 108966]\n                   ...        \n    9989    [CA, 2014, 110422]\n    9990    [CA, 2017, 121258]\n    9991    [CA, 2017, 121258]\n    9992    [CA, 2017, 121258]\n    9993    [CA, 2017, 119914]\n    Name: ID_Pedido, Length: 9994, dtype: object\n</code></pre> <p>Ele est\u00e1 nos retornando uma lista em cada ID</p> <p></p> <p>O Split ele divide os valores e nos retorna eles em uma lista por cada ID separadamente</p> <p></p> <p>Separando os dados, por\u00e9m, retornando apenas o valor de \u00edndice 1, ou seja, o ano</p> <pre><code>python\n\ndf3['ID_Pedido'].str.split('-').str[1].head\n</code></pre> <pre><code>out:\n\n    &lt;bound method NDFrame.head of 0       2016\n    1       2016\n    2       2016\n    3       2015\n    4       2015\n            ... \n    9989    2014\n    9990    2017\n    9991    2017\n    9992    2017\n    9993    2017\n    Name: ID_Pedido, Length: 9994, dtype: object&gt;\n</code></pre> <p></p> <p>Agora, estamos fazendo o split, separando os valores e armazenando em uma coluna espec\u00edfica</p> <pre><code>python\n\ndf3['Ano'] = df3['ID_Pedido'].str.split('-').str[1]\n</code></pre> <p>Visualizando as altera\u00e7\u00f5es!</p> <pre><code>python\n\ndf3.head()\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade Ano 0 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-BO-10001798 Furniture Bush Somerset Collection Bookcase 261.9600 3.0 2016 1 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-CH-10000454 Furniture Hon Deluxe Fabric Upholstered Stacking Chairs,... 731.9400 3.0 2016 2 CA-2016-138688 2016-06-12 DV-13045 Corporate United States West OFF-LA-10000240 Office Supplies Self-Adhesive Address Labels for Typewriters b... 14.6200 2.0 2016 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 2015 4 US-2015-108966 2015-10-11 SO-20335 Consumer United States South OFF-ST-10000760 Office Supplies Eldon Fold 'N Roll Cart System 22.3680 2.0 2015 <p></p>"},{"location":"sql/","title":"SQL com Python","text":""},{"location":"sql/#sql","title":"SQL","text":""},{"location":"sql/#linguagem-sql","title":"Linguagem SQL","text":"<p>O que \u00e9?     SQL (Structured Query Language), \u00e9 uma linguagem de programa\u00e7\u00e3o usada para gerenciar e manipular banco de dados relacionais, permitindo que os usu\u00e1rios possam acessar, inserir e excluir dados, como gerenciar tabelas e estruturas de banco de dados.</p> <p>A Linguagem SQL consiste em v\u00e1rias instru\u00e7\u00f5es, que podem ser agrupadas nas seguintes categorias:</p> <ul> <li> <p>1 - DDL (Data Definition Language) - define e gerencia a estrutura de tabelas e objetos do banco de dados:</p> <ul> <li>Create: cria uma nova tabela ou objeto no banco de dados;</li> <li>Alter: modifica uma tabela ou objeto existente;</li> <li>Drop: exclui uma tabela ou objeto existente.</li> </ul> </li> <li> <p>2 - DML (Data Manipulation Language) - manipula os dados armazenados nas tabelas:</p> <ul> <li>SELECT: recupera dados de uma ou mais tabelas;</li> <li>INSERT: insere novos registros em uma tabela;</li> <li>UPDATE: atualiza registros existentes em uma tabela;</li> <li>DELETE: exclui registros de uma tabela.</li> </ul> </li> <li> <p>3 - DCL (Data Control Language) - gerencia permiss\u00f5es e controle de acesso aos objetos do banco de dados:</p> <ul> <li>GRANT: concede permiss\u00f5es a usu\u00e1rios ou grupos para acessar e manipular objetos do banco de dados;</li> <li>REVOKE: remove permiss\u00f5es concedidas anteriormente.</li> </ul> </li> <li> <p>4 - TCL (Transaction Control Language) - gerencia transa\u00e7\u00f5es no banco de dados:</p> <ul> <li>BEGIN TRANSACTION: inicia uma nova transa\u00e7\u00e3o;</li> <li>COMMIT: salva todas as altera\u00e7\u00f5es feitas na transa\u00e7\u00e3o atual;</li> <li>ROLLBACK: desfaz as altera\u00e7\u00f5es feitas na transa\u00e7\u00e3o atual;</li> <li>SAVEPOINT:  cria  um  ponto  de  salvamento  na  transa\u00e7\u00e3o  atual,  permitindo  que  voc\u00ea reverta para esse ponto, se necess\u00e1rio.</li> </ul> </li> </ul>"},{"location":"sql/#sgbd-sistema-gerenciador-de-banco-de-dados","title":"SGBD (Sistema Gerenciador de Banco de Dados):","text":"<p>O que \u00e9? Um  Sistema  Gerenciador  de  Banco  de  Dados  (SGBD)  \u00e9  um  software  projetado  para gerenciar,  armazenar,  manipular  e  consultar  dados  em  um  banco  de  dados.  SGBDs  s\u00e3o fundamentais  para  o  gerenciamento  eficiente  e  seguro  de  grandes  quantidades  de  dados  em aplica\u00e7\u00f5es e sistemas de informa\u00e7\u00e3o.</p>"},{"location":"sql/#por-que-a-linguagem-sql-e-fundamental-para-profissionais-de-dados","title":"Por que a Linguagem SQL \u00e9 fundamental para profissionais de dados?","text":"<p>A Linguagem SQL (Structured Query Language) \u00e9 fundamental para profissionais de dados por v\u00e1rias raz\u00f5es:</p> <ul> <li> <p>Padr\u00e3o Universal: SQL \u00e9 uma linguagem padr\u00e3o e amplamente aceita para gerenciamento e consulta de bancos de dados relacionais. Independentemente do sistema gerenciador de banco de dados (SGBD) utilizado, SQL \u00e9 a linguagem comum para realizar consultas e manipula\u00e7\u00f5es de dados.</p> </li> <li> <p>Flexibilidade: SQL permite criar consultas complexas e personalizadas, combinando dados de v\u00e1rias tabelas, filtrando informa\u00e7\u00f5es e realizando opera\u00e7\u00f5es de agrega\u00e7\u00e3o e ordena\u00e7\u00e3o. Isso permite que os profissionais de dados extraiam informa\u00e7\u00f5es valiosas a partir dos dados armazenados.</p> </li> <li> <p>Manipula\u00e7\u00e3o de Dados: Al\u00e9m das consultas, SQL permite a inser\u00e7\u00e3o, atualiza\u00e7\u00e3o e exclus\u00e3o de dados, bem como a defini\u00e7\u00e3o de esquemas e gerenciamento de objetos de banco de dados, como tabelas, \u00edndices e vis\u00f5es.</p> </li> <li> <p>Controle de Acesso e Seguran\u00e7a: SQL tamb\u00e9m oferece recursos para gerenciar o acesso e a seguran\u00e7a dos dados, permitindo aos profissionais de dados controlar quem pode acessar, modificar ou excluir informa\u00e7\u00f5es no banco de dados.</p> </li> <li> <p>Alta Demanda no Mercado: Profissionais de dados com habilidades em SQL est\u00e3o em alta demanda, j\u00e1 que a linguagem \u00e9 amplamente usada em v\u00e1rias \u00e1reas e setores. O conhecimento em SQL \u00e9 uma habilidade essencial para cargos como Analista de Dados, Cientista de Dados, Engenheiro de Dados e Administrador de Banco de Dados.</p> </li> <li> <p>Integra\u00e7\u00e3o com Outras Ferramentas e Tecnologias: SQL se integra facilmente com outras ferramentas e linguagens de programa\u00e7\u00e3o, como Python, R, Java, entre outras. Isso permite que os profissionais de dados aproveitem o poder da Linguagem SQL em conjunto com outras tecnologias para analisar, visualizar e processar dados.</p> </li> </ul> <p></p>"},{"location":"stripdf/","title":"Strip em DFs","text":""},{"location":"stripdf/#strip-em-df-do-pandas","title":"Strip em DF do Pandas","text":"<p>Diferente do Split, o Strip remove alguns caracteres da string</p> <p>Retornando os 3 elementos da coluna 'Data_Pedido'</p> <pre><code>python\n\ndf3['Data_Pedido'].head(3)\n</code></pre> <pre><code>out:\n\n    0    2016-11-08\n    1    2016-11-08\n    2    2016-06-12\n    Name: Data_Pedido, dtype: object\n</code></pre> <p>A coluna Data pedido tem o formato YYYY-MM-DD. Imagine que seja necess\u00e1rio deixar o ano apenas com 2 d\u00edgitos sem alterar o tipo da vari\u00e1vel.</p> <p>Podemos fazer isso com a fun\u00e7\u00e3o lstrit(), ou seja, left strip, (\u00e0 esquerda).</p> <p></p> <p>Vamos remover os d\u00edgitos 2 e 0 \u00e0 esquerda do valor da vari\u00e1vel 'Data_Pedido'</p> <pre><code>python\n\ndf3['Data_Pedido'].str.lstrip('20')\n</code></pre> <pre><code>out:\n\n    0       16-11-08\n    1       16-11-08\n    2       16-06-12\n    3       15-10-11\n    4       15-10-11\n              ...   \n    9989    14-01-21\n    9990    17-02-26\n    9991    17-02-26\n    9992    17-02-26\n    9993    17-05-04\n    Name: Data_Pedido, Length: 9994, dtype: object\n</code></pre> <p>Como n\u00e3o usamos o inplace=True, a mudan\u00e7a \u00e9 feita apenas na mem\u00f3ria, n\u00e3o afetando diretamente o DF. </p> <p>Podemos ainda usar as fun\u00e7\u00f5es rstrip() (\u00c1 direita) ou strip().</p> <p></p>"},{"location":"tiposbd/","title":"\ud83c\udfd7\ufe0f Data Warehouse, Data Lake e Data Lakehouse","text":""},{"location":"tiposbd/#data-warehouse-data-lake-e-data-lakehouse","title":"Data Warehouse, Data Lake e Data Lakehouse","text":""},{"location":"tiposbd/#etapas-para-implementacao-de-um-dw","title":"Etapas para Implementa\u00e7\u00e3o de um DW:","text":"<ol> <li>Identifica\u00e7\u00e3o de Requisitos  </li> <li>Projeto e Arquitetura  </li> <li>Integra\u00e7\u00e3o  </li> <li>Constru\u00e7\u00e3o  </li> <li>Carga de Dados  </li> <li>Agendar Atualiza\u00e7\u00f5es  </li> <li>Acesso e Seguran\u00e7a  </li> <li>Monitoramento  </li> <li>Usar Data Marts  </li> <li>Manuten\u00e7\u00e3o do Modelo de Dados  </li> </ol>"},{"location":"tiposbd/#etapas-para-implementacao-de-um-dl","title":"Etapas para Implementa\u00e7\u00e3o de um DL:","text":"<ol> <li>Identifica\u00e7\u00e3o de Requisitos  </li> <li>Escolher uma plataforma  </li> <li>Integra\u00e7\u00e3o  </li> <li>Armazenamento  </li> <li>Agendamento  </li> <li>Acesso  </li> <li>Governan\u00e7a de Dados  </li> </ol>"},{"location":"tiposbd/#etapas-para-implementacao-de-um-data-lakehouse","title":"Etapas para Implementa\u00e7\u00e3o de um Data Lakehouse:","text":"<ol> <li>Identifica\u00e7\u00e3o de Requisitos  </li> <li>Escolher uma plataforma  </li> <li>Integra\u00e7\u00e3o  </li> <li>Armazenamento  </li> <li>Governan\u00e7a de Dados, Atualiza\u00e7\u00f5es e Monitoramento  </li> </ol>"},{"location":"tiposbd/#data-warehouse-dw","title":"Data Warehouse (DW)","text":"<p>Vantagens: - Dados estruturados e limpos - Performance - Governan\u00e7a de dados - Capacidade de suportar demandas de neg\u00f3cio  </p> <p>Desvantagens: - Caro e complexo - Limpeza e modelagem antes da carga - Restringe a capacidade de armazenar grandes volumes de dados n\u00e3o estruturados - Pode ser limitado para lidar com fontes din\u00e2micas n\u00e3o estruturadas  </p>"},{"location":"tiposbd/#data-lake-dl","title":"Data Lake (DL)","text":"<p>Vantagens: - Capacidade de armazenar grandes volumes de dados brutos - Flexibilidade para armazenar diferentes tipos de dados - Permite an\u00e1lise de Big Data  </p> <p>Desvantagens: - Governan\u00e7a de dados menos robusta que um DW - Performance de consultas menor - Caro e complexo - Depend\u00eancia de ferramentas adicionais para limpeza e modelagem  </p>"},{"location":"tiposbd/#data-lakehouse","title":"Data Lakehouse","text":"<p>Vantagens: - Combina as vantagens do DW e DL - Capacidade de armazenar grandes volumes n\u00e3o estruturados e semi-estruturados - Boa governan\u00e7a e performance - Flex\u00edvel e escal\u00e1vel - Permite an\u00e1lises de Big Data, Machine Learning e IA  </p> <p>Desvantagens: - Caro e complexo de implementar - Depend\u00eancia de ferramentas adicionais para limpeza e modelagem - Conceito recente no mercado, precisando de evolu\u00e7\u00e3o e maturidade  </p>"},{"location":"tiposbd/#enterprise-data-hub-edh","title":"Enterprise Data Hub (EDH)","text":"<p>O Enterprise Data Hub (EDH) \u00e9 uma arquitetura de dados que combina uma variedade de tecnologias e ferramentas para realizar a coleta, armazenamento, gerenciamento e an\u00e1lise de dados em grande escala.  </p>"},{"location":"treinamentos/","title":"\ud83d\ude80 Trilha de Desenvolvimento","text":""},{"location":"treinamentos/#engenharia-de-dados","title":"\ud83c\udfd7\ufe0f Engenharia de Dados","text":"<ul> <li>\u2705 Fundamentos da Engenharia de Dados - Data Science Academy </li> <li>\u2705 Big Data - Workover </li> <li>\u2705 Databricks Fundamentals - DataBricks </li> </ul>"},{"location":"treinamentos/#python","title":"\ud83d\udc0d Python","text":"<ul> <li>\u2705 Python 3 - COD3R </li> <li>\u2705 Fundamentos de Python para An\u00e1lise de Dados e Data Science - Data Science Academy </li> </ul>"},{"location":"treinamentos/#desenvolvimento","title":"\ud83d\udcbb Desenvolvimento","text":"<ul> <li>\u2705 Forma\u00e7\u00e3o de Desenvolvedor Front-End - Vai na Web </li> <li>\u2705 Git e GitHub - Wokorver </li> </ul>"},{"location":"treinamentos/#agilidade","title":"\u26a1 Agilidade","text":"<ul> <li>\u2705 Fundamentos do Scrum - ScrumLab </li> </ul>"},{"location":"valoresausentes/","title":"Manipulando Valores Ausentes","text":""},{"location":"valoresausentes/#preenchendo-valores-ausentes-em-dataframes-do-pandas","title":"Preenchendo valores ausentes em DataFrames do Pandas","text":"<p>Importando um DataFrame para manipula\u00e7\u00e3o</p> <pre><code>python\n\ndf3 = pd.read_csv('dataset.csv')\n</code></pre> <p></p> <p>Exibindo os valores, mostrando o cabe\u00e7alho, filtrando mostrando os 5 primeiros valores</p> <pre><code>python\n\ndf3.head(5)\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 0 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-BO-10001798 Furniture Bush Somerset Collection Bookcase 261.9600 NaN 1 CA-2016-152156 2016-11-08 CG-12520 Consumer United States South FUR-CH-10000454 Furniture Hon Deluxe Fabric Upholstered Stacking Chairs,... 731.9400 NaN 2 CA-2016-138688 2016-06-12 DV-13045 Corporate United States West OFF-LA-10000240 Office Supplies Self-Adhesive Address Labels for Typewriters b... 14.6200 2.0 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 4 US-2015-108966 2015-10-11 SO-20335 Consumer United States South OFF-ST-10000760 Office Supplies Eldon Fold 'N Roll Cart System 22.3680 2.0 <p></p> <p>Verificando se h\u00e1 valores ausentes e em qual coluna:</p> <pre><code>python\n\ndf3.isna().sum()\n</code></pre> <pre><code>out:\n\n    ID_Pedido       0\n    Data_Pedido     0\n    ID_Cliente      0\n    Segmento        0\n    Pais            0\n    Regiao          0\n    ID_Produto      0\n    Categoria       0\n    Nome_Produto    0\n    Valor_Venda     0\n    Quantidade      2\n    dtype: int64\n</code></pre> <p>Se n\u00e3o houver valores ausentes, ele retornar\u00e1 zero, por\u00e9m, se houver, ele retornar\u00e1 a quantidade de valores que est\u00e3o faltando.  </p> <p>MODA</p> <p>A moda \u00e9 uma medida de tend\u00eancia central que representa o valor mais frequente em um conjunto de dados!!</p> <p>Ela \u00e9 extremamente \u00fatil quando queremos saber qual \u00e9 o valor mais comum ou popular em um conjunto de dados!</p> <p>Extraindo a moda da coluna quantidade</p> <pre><code>python\n\nmoda = df3['Quantidade'].value_counts().index[0]\nprint(moda)\n</code></pre> <pre><code>out: 3.0 \n</code></pre> <p></p> <p>Preenchendo os valores vazios com o valor da moda</p> <pre><code>python\n\ndf3['Quantidade'].fillna(value = moda, inplace = True)\n\n# O inplace \u00e9 como se fosse para salvar as altera\u00e7\u00f5es!\n# Se eu n\u00e3o utilizar o mesmo, ele ir\u00e1 criar uma c\u00f3pia do DF e fazer a altera\u00e7\u00e3o apenas naquele escopo.\n</code></pre> <pre><code>python\n\n# Verificando se ainda h\u00e1 valores vazios!\ndf3.isna().sum()\n</code></pre> <pre><code>out:\n\n    ID_Pedido       0\n    Data_Pedido     0\n    ID_Cliente      0\n    Segmento        0\n    Pais            0\n    Regiao          0\n    ID_Produto      0\n    Categoria       0\n    Nome_Produto    0\n    Valor_Venda     0\n    Quantidade      0\n    dtype: int64\n</code></pre> <p>O nome dessa pr\u00e1tica se chama INTERPOLA\u00c7\u00c3O! Quando utilizamos uma estat\u00edstica da coluna para preencher valores ausentes! </p>"},{"location":"verificandoocorrencias/","title":"Verificando Ocorr\u00eancias de Valores","text":""},{"location":"verificandoocorrencias/#verificando-a-ocorrencia-de-diversos-valores-em-uma-coluna","title":"Verificando a ocorr\u00eancia de diversos valores em uma coluna","text":"<p>Verificando a forma (shape) do DF</p> <pre><code>python\n\ndf3.shape\n</code></pre> <pre><code>out: (9994, 11)\n</code></pre> <p>Ele nos retorna o n\u00famero de linhas, n\u00famero de colunas!</p> <p></p> <p>Aplicando um filtro que nos mostra se h\u00e1 a quantidade, 5,7,9 ou 11</p> <pre><code>python\n\ndf3[ df3['Quantidade'].isin([5,7,9, 11])] \n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 5 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West FUR-FU-10001487 Furniture Eldon Expressions Wood and Plastic Desk Access... 48.8600 7.0 9 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West OFF-AP-10002892 Office Supplies Belkin F5C206VTEL 6 Outlet Surge 114.9000 5.0 10 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West FUR-TA-10001539 Furniture Chromcraft Rectangular Conference Tables 1706.1840 9.0 14 US-2015-118983 2015-11-22 HP-14815 Home Office United States Central OFF-AP-10002311 Office Supplies Holmes Replacement Filter for HEPA Air Cleaner... 68.8100 5.0 ... ... ... ... ... ... ... ... ... ... ... ... 9974 US-2016-103674 2016-12-06 AP-10720 Home Office United States West OFF-AR-10004752 Office Supplies Blackstonian Pencils 18.6900 7.0 9977 US-2016-103674 2016-12-06 AP-10720 Home Office United States West OFF-FA-10003467 Office Supplies Alliance Big Bands Rubber Bands, 12/Pack 13.8600 7.0 9981 CA-2017-163566 2017-08-03 TB-21055 Consumer United States East OFF-LA-10004484 Office Supplies Avery 476 16.5200 5.0 9982 US-2016-157728 2016-09-22 RC-19960 Consumer United States Central OFF-PA-10002195 Office Supplies RSVP Cards &amp; Envelopes, Blank White, 8-1/2\" X ... 35.5600 7.0 9988 CA-2017-163629 2017-11-17 RA-19885 Corporate United States South TEC-PH-10004006 Technology Panasonic KX - TS880B Telephone 206.1000 5.0 <p>2128 rows \u00d7 11 columns</p> <p></p> <p>Aplicando o mesmo filtro, por\u00e9m, quero ver apenas o formato do retorno, Quantas linhas e colunas</p> <pre><code>python\n\ndf3[ df3['Quantidade'].isin([5,7,9, 11])].shape \n</code></pre> <pre><code>out: (2128, 11)\n</code></pre> <p></p> <p>Aplicando o mesmo filtro, por\u00e9m, visualizando apenas as 10 primeiras linhas!</p> <pre><code>python\n\ndf3[ df3['Quantidade'].isin([5,7,9, 11])][:10]\n</code></pre> <p>out:</p> ID_Pedido Data_Pedido ID_Cliente Segmento Pais Regiao ID_Produto Categoria Nome_Produto Valor_Venda Quantidade 3 US-2015-108966 2015-10-11 SO-20335 Consumer United States South FUR-TA-10000577 Furniture Bretford CR4500 Series Slim Rectangular Table 957.5775 5.0 5 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West FUR-FU-10001487 Furniture Eldon Expressions Wood and Plastic Desk Access... 48.8600 7.0 9 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West OFF-AP-10002892 Office Supplies Belkin F5C206VTEL 6 Outlet Surge 114.9000 5.0 10 CA-2014-115812 2014-06-09 BH-11710 Consumer United States West FUR-TA-10001539 Furniture Chromcraft Rectangular Conference Tables 1706.1840 9.0 14 US-2015-118983 2015-11-22 HP-14815 Home Office United States Central OFF-AP-10002311 Office Supplies Holmes Replacement Filter for HEPA Air Cleaner... 68.8100 5.0 21 CA-2016-137330 2016-12-09 KB-16585 Corporate United States Central OFF-AR-10000246 Office Supplies Newell 318 19.4600 7.0 22 CA-2016-137330 2016-12-09 KB-16585 Corporate United States Central OFF-AP-10001492 Office Supplies Acco Six-Outlet Power Strip, 4' Cord Length 60.3400 7.0 27 US-2015-150630 2015-09-17 TB-21520 Consumer United States East FUR-BO-10004834 Furniture Riverside Palais Royal Lawyers Bookcase, Royal... 3083.4300 7.0 35 CA-2016-117590 2016-12-08 GH-14485 Corporate United States Central TEC-PH-10004977 Technology GE 30524EE4 1097.5440 7.0 36 CA-2016-117590 2016-12-08 GH-14485 Corporate United States Central FUR-FU-10003664 Furniture Electrix Architect's Clamp-On Swing Arm Lamp, ... 190.9200 5.0 <p></p>"}]}